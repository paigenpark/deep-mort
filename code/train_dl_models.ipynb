{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Mortality Prediction (DLMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%run data_preparation/split_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "tfkl = tf.keras.layers\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_functions' from '/Users/paigepark/Desktop/deep-mort/code/training_functions.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import training_functions\n",
    "import importlib\n",
    "\n",
    "importlib.reload(training_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_training = np.loadtxt('../data/state_training.txt')\n",
    "state_test = np.loadtxt('../data/state_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_training = np.loadtxt('../data/country_training_new.txt')\n",
    "country_test = np.loadtxt('../data/country_test_new.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training = np.loadtxt('../data/combined_training_new.txt')\n",
    "combined_test = np.loadtxt('../data/combined_test_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos_key = np.load('../data/geos_key_new.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_dict = {int(code): geo for geo, code in geos_key}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single population models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I am training indiviudal models for each population. I am only saving mses rather than predictions since the prediction data would be too large to store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pop = np.unique(country_training[:, 0])\n",
    "geo_dim = int(max(n_pop) + 1)\n",
    "geo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA: False\n",
      "GPU devices: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Optional: Set memory growth to prevent over-allocation\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model AUS: Gender 0\n",
      "Epoch 1/30\n",
      "500/500 - 6s - 11ms/step - loss: 5.3503 - val_loss: 0.3670 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "500/500 - 4s - 8ms/step - loss: 0.3935 - val_loss: 0.0875 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "500/500 - 4s - 8ms/step - loss: 0.2909 - val_loss: 0.0698 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "500/500 - 5s - 11ms/step - loss: 0.2235 - val_loss: 0.0660 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "500/500 - 5s - 9ms/step - loss: 0.1803 - val_loss: 0.0719 - learning_rate: 0.0010\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m single_geo_dim \u001b[38;5;241m=\u001b[39m country_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeo_dict[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Gender \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m model_single, loss_single \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_deep_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_country_training_prepped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43msingle_country_test_prepped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43msingle_geo_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlograte\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m tc \u001b[38;5;241m=\u001b[39m single_country_test  \n\u001b[1;32m     21\u001b[0m years \u001b[38;5;241m=\u001b[39m (tc[:,\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1959\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/deep-mort/code/training_functions.py:185\u001b[0m, in \u001b[0;36mrun_deep_model\u001b[0;34m(dataset_train, dataset_test, geo_dim, epochs, steps_per_epoch, lograte)\u001b[0m\n\u001b[1;32m    181\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_model(geo_dim)\n\u001b[1;32m    183\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    184\u001b[0m                                                 min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m, cooldown\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)]\n\u001b[0;32m--> 185\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    190\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for s in range(1):\n",
    "    for j in range(0,2):\n",
    "        for i in range(50, 52):\n",
    "            country_index = i\n",
    "            gender_index = j\n",
    "            single_country_training = country_training[(country_training[:,0] == country_index) & (country_training[:,1] == gender_index)]\n",
    "            single_country_test = country_test[(country_test[:,0] == country_index) & (country_test[:,1] == gender_index)]\n",
    "\n",
    "            single_country_training_prepped = training_functions.prep_data(single_country_training, mode=\"train\", changeratetolog=True)\n",
    "            single_country_test_prepped = training_functions.prep_data(single_country_test, mode=\"test\", changeratetolog=True)\n",
    "            single_geo_dim = country_index + 1\n",
    "\n",
    "            print(f\"Running model {geo_dict[i]}: Gender {j}\")\n",
    "\n",
    "            model_single, loss_single = training_functions.run_deep_model(single_country_training_prepped, \n",
    "                                                                          single_country_test_prepped, \n",
    "                                                                          single_geo_dim, epochs=30, \n",
    "                                                                          steps_per_epoch=500, lograte=True)\n",
    "        \n",
    "            tc = single_country_test  \n",
    "            years = (tc[:,2] - 1959) / 60\n",
    "            ages  = tc[:,3]\n",
    "            geos  = tc[:,0].astype(np.int32)\n",
    "            genders = tc[:,1]\n",
    "\n",
    "            test_input_features = (\n",
    "                tf.convert_to_tensor(years, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(ages, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(geos, dtype=tf.int32),      # ensure ints\n",
    "                tf.convert_to_tensor(genders, dtype=tf.float32),\n",
    "            )\n",
    "            \n",
    "            test_predictions = model_single.predict(test_input_features)\n",
    "\n",
    "\n",
    "            inputs_test = np.delete(single_country_test, 4, axis=1)\n",
    "            test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "            geo_name = geo_dict[i]\n",
    "\n",
    "            # model_single.save(f\"../models/{geo_name}_gender_{j}.keras\")   \n",
    "\n",
    "            # np.savez_compressed(f\"../data/{geo_name}_gender_{j}_iter_{s}.npz\", test_predictions) \n",
    "\n",
    "print(f\"Finished training for {s} iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Country Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "country_train_prepped = training_functions.prep_data(country_training, mode=\"train\", changeratetolog=True)\n",
    "country_test_prepped = training_functions.prep_data(country_test, mode=\"test\", changeratetolog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(country_training[:, 0]).y\n",
    "country_geo_dim = np.array(tf.size(unique_vals)).item()\n",
    "country_geo_dim = country_geo_dim + 50\n",
    "country_geo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1405"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.ceil(len(country_training)/ 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 2.0501 - val_loss: 0.2499 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.3321 - val_loss: 0.2121 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2541 - val_loss: 0.1817 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.2135 - val_loss: 0.1808 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.2010 - val_loss: 0.1987 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.1932 - val_loss: 0.2210 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1786 - val_loss: 0.2357 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1682 - val_loss: 0.1942 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.1720 - val_loss: 0.1717 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1637 - val_loss: 0.1915 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1714 - val_loss: 0.1779 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1616 - val_loss: 0.1524 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1630 - val_loss: 0.1738 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1612 - val_loss: 0.1878 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1634 - val_loss: 0.1826 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1573 - val_loss: 0.1470 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1567 - val_loss: 0.1942 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1620 - val_loss: 0.1606 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 14s - 10ms/step - loss: 0.1569 - val_loss: 0.1953 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1545 - val_loss: 0.1677 - learning_rate: 1.5625e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 768us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step\n",
      "Iteration 1 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 14s - 10ms/step - loss: 1.9925 - val_loss: 0.2836 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.3387 - val_loss: 0.2105 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 11s - 7ms/step - loss: 0.2551 - val_loss: 0.1938 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.2211 - val_loss: 0.2003 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1960 - val_loss: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 16s - 11ms/step - loss: 0.1920 - val_loss: 0.2109 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.1713 - val_loss: 0.1771 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1757 - val_loss: 0.1850 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1689 - val_loss: 0.1958 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1637 - val_loss: 0.1498 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1646 - val_loss: 0.1859 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1639 - val_loss: 0.1631 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1687 - val_loss: 0.1686 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1574 - val_loss: 0.1715 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1592 - val_loss: 0.1778 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1596 - val_loss: 0.1657 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1585 - val_loss: 0.1686 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1610 - val_loss: 0.1658 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1573 - val_loss: 0.1692 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1577 - val_loss: 0.1676 - learning_rate: 3.9063e-06\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 756us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 602us/step\n",
      "Iteration 2 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 16s - 11ms/step - loss: 1.9587 - val_loss: 0.2350 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 13s - 10ms/step - loss: 0.3369 - val_loss: 0.2365 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.2515 - val_loss: 0.1991 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.2207 - val_loss: 0.2170 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 11s - 7ms/step - loss: 0.1984 - val_loss: 0.1997 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1900 - val_loss: 0.1811 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 14s - 10ms/step - loss: 0.1847 - val_loss: 0.1948 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1793 - val_loss: 0.2137 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.1708 - val_loss: 0.1633 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1691 - val_loss: 0.1659 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1745 - val_loss: 0.1809 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1716 - val_loss: 0.1783 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1600 - val_loss: 0.1800 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1571 - val_loss: 0.1754 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1550 - val_loss: 0.1704 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1579 - val_loss: 0.1491 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1523 - val_loss: 0.1688 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1550 - val_loss: 0.1592 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1549 - val_loss: 0.1641 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1556 - val_loss: 0.1745 - learning_rate: 1.5625e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 758us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step\n",
      "Iteration 3 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 17s - 12ms/step - loss: 2.0076 - val_loss: 0.3259 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.3307 - val_loss: 0.1950 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.2483 - val_loss: 0.2012 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2209 - val_loss: 0.2018 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2011 - val_loss: 0.2227 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1774 - val_loss: 0.1964 - learning_rate: 2.5000e-04\n",
      "Epoch 7/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.1766 - val_loss: 0.1791 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1755 - val_loss: 0.1647 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1665 - val_loss: 0.1916 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1688 - val_loss: 0.1461 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1704 - val_loss: 0.1749 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1710 - val_loss: 0.1902 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1679 - val_loss: 0.1696 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1656 - val_loss: 0.1688 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1590 - val_loss: 0.1837 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1602 - val_loss: 0.1666 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1585 - val_loss: 0.1470 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1600 - val_loss: 0.1559 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1630 - val_loss: 0.1590 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1635 - val_loss: 0.1790 - learning_rate: 3.9063e-06\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 738us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 593us/step\n",
      "Iteration 4 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 17s - 12ms/step - loss: 2.0672 - val_loss: 0.2633 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.3351 - val_loss: 0.2479 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2524 - val_loss: 0.2085 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.2216 - val_loss: 0.1839 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.2027 - val_loss: 0.2189 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1888 - val_loss: 0.1722 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1861 - val_loss: 0.1786 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1752 - val_loss: 0.2629 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1766 - val_loss: 0.1940 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1626 - val_loss: 0.1846 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1586 - val_loss: 0.1642 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1631 - val_loss: 0.1692 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1556 - val_loss: 0.1597 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1649 - val_loss: 0.1603 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1544 - val_loss: 0.1756 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1586 - val_loss: 0.1719 - learning_rate: 2.5000e-04\n",
      "Epoch 17/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1522 - val_loss: 0.1749 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1569 - val_loss: 0.1595 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1592 - val_loss: 0.1515 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1542 - val_loss: 0.1746 - learning_rate: 6.2500e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 662us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518us/step\n",
      "Iteration 5 complete\n"
     ]
    }
   ],
   "source": [
    "# run country model\n",
    "for i in range(1,6):\n",
    "\n",
    "    model_country, loss_info_country = training_functions.run_deep_model(country_train_prepped, country_test_prepped, country_geo_dim, \n",
    "                                                                         epochs=20, steps_per_epoch=1405, lograte=True)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((country_training[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(country_training[:,3], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(country_training[:,0], dtype=tf.float32),  # Geography\n",
    "                            tf.convert_to_tensor(country_training[:,1], dtype=tf.float32))  # Gender\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((country_test[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(country_test[:,3], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(country_test[:,0], dtype=tf.float32),  # Geography\n",
    "                        tf.convert_to_tensor(country_test[:,1], dtype=tf.float32))  # Gender\n",
    "\n",
    "    training_predictions = model_country.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_country.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(country_training, 4, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(country_test, 4, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_country.save(f\"../models/dl_country_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/dl_country_forecast{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/dl_country_forecast{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined (all country / all state) DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert combined data to tensors and other prep\n",
    "combined_train_prepped = training_functions.prep_data(combined_training, mode=\"train\", changeratetolog=True)\n",
    "combined_test_prepped = training_functions.prep_data(combined_test, mode=\"test\", changeratetolog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(combined_training[:, 0]).y\n",
    "combined_geo_dim = np.array(tf.size(unique_vals)).item()\n",
    "print(combined_geo_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2000/2000 - 19s - 9ms/step - loss: 1.5262 - val_loss: 0.2362 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.2855 - val_loss: 0.2518 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.2300 - val_loss: 0.2428 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2115 - val_loss: 0.2219 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1956 - val_loss: 0.2163 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1900 - val_loss: 0.1822 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1857 - val_loss: 0.1922 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "2000/2000 - 22s - 11ms/step - loss: 0.1839 - val_loss: 0.1892 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "2000/2000 - 18s - 9ms/step - loss: 0.1836 - val_loss: 0.2220 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1757 - val_loss: 0.1742 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1757 - val_loss: 0.1960 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1752 - val_loss: 0.1854 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1728 - val_loss: 0.1851 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1710 - val_loss: 0.1745 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1687 - val_loss: 0.1960 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1746 - val_loss: 0.2115 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 18s - 9ms/step - loss: 0.1729 - val_loss: 0.1988 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1696 - val_loss: 0.1894 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.1723 - val_loss: 0.1905 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1678 - val_loss: 0.2066 - learning_rate: 3.9063e-06\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 705us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 726us/step\n",
      "Iteration 1 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 21s - 10ms/step - loss: 1.5445 - val_loss: 0.2285 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2897 - val_loss: 0.2927 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2345 - val_loss: 0.2145 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.2094 - val_loss: 0.2166 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.1963 - val_loss: 0.2417 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1911 - val_loss: 0.2202 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1810 - val_loss: 0.2264 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1778 - val_loss: 0.1833 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1811 - val_loss: 0.1720 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.1757 - val_loss: 0.1896 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1765 - val_loss: 0.1873 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1806 - val_loss: 0.1757 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1743 - val_loss: 0.2139 - learning_rate: 6.2500e-05\n",
      "Epoch 14/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1751 - val_loss: 0.2051 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1756 - val_loss: 0.1550 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1734 - val_loss: 0.1730 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1705 - val_loss: 0.1771 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1738 - val_loss: 0.1811 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1723 - val_loss: 0.1853 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1693 - val_loss: 0.1857 - learning_rate: 1.5625e-05\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 672us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 796us/step\n",
      "Iteration 2 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 19s - 10ms/step - loss: 1.5301 - val_loss: 0.2317 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.2842 - val_loss: 0.2037 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2308 - val_loss: 0.2392 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.2080 - val_loss: 0.2006 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1991 - val_loss: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1932 - val_loss: 0.2169 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1872 - val_loss: 0.1827 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1857 - val_loss: 0.2010 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1865 - val_loss: 0.1971 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1802 - val_loss: 0.1937 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1762 - val_loss: 0.2284 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1727 - val_loss: 0.1686 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1737 - val_loss: 0.1996 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1734 - val_loss: 0.1756 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1722 - val_loss: 0.1774 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1741 - val_loss: 0.1792 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1705 - val_loss: 0.1893 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1720 - val_loss: 0.2131 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1690 - val_loss: 0.1923 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1728 - val_loss: 0.1860 - learning_rate: 1.5625e-05\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 598us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 779us/step\n",
      "Iteration 3 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 19s - 9ms/step - loss: 1.5412 - val_loss: 0.2544 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2864 - val_loss: 0.2267 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2284 - val_loss: 0.2359 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2070 - val_loss: 0.2529 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1947 - val_loss: 0.2105 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1864 - val_loss: 0.2244 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1919 - val_loss: 0.2307 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1820 - val_loss: 0.2076 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "2000/2000 - 19s - 10ms/step - loss: 0.1835 - val_loss: 0.2455 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.1779 - val_loss: 0.1952 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1788 - val_loss: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1792 - val_loss: 0.1878 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1773 - val_loss: 0.2025 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1808 - val_loss: 0.1925 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1788 - val_loss: 0.1834 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1791 - val_loss: 0.1859 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "2000/2000 - 17s - 8ms/step - loss: 0.1777 - val_loss: 0.1985 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1753 - val_loss: 0.1993 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1755 - val_loss: 0.1697 - learning_rate: 2.5000e-04\n",
      "Epoch 20/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1698 - val_loss: 0.1743 - learning_rate: 2.5000e-04\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 681us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "Iteration 4 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 24s - 12ms/step - loss: 1.5747 - val_loss: 0.2586 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 18s - 9ms/step - loss: 0.2788 - val_loss: 0.2428 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 19s - 10ms/step - loss: 0.2296 - val_loss: 0.1961 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 18s - 9ms/step - loss: 0.2108 - val_loss: 0.2141 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.1951 - val_loss: 0.2228 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1896 - val_loss: 0.2181 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1810 - val_loss: 0.1875 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1804 - val_loss: 0.1903 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1806 - val_loss: 0.2042 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1751 - val_loss: 0.1890 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1740 - val_loss: 0.1849 - learning_rate: 6.2500e-05\n",
      "Epoch 12/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1760 - val_loss: 0.1819 - learning_rate: 6.2500e-05\n",
      "Epoch 13/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1733 - val_loss: 0.1833 - learning_rate: 6.2500e-05\n",
      "Epoch 14/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1755 - val_loss: 0.2215 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1701 - val_loss: 0.1934 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1725 - val_loss: 0.1693 - learning_rate: 1.5625e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1719 - val_loss: 0.1937 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1755 - val_loss: 0.1685 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1686 - val_loss: 0.1712 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1725 - val_loss: 0.1573 - learning_rate: 1.5625e-05\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 747us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 881us/step\n",
      "Iteration 5 complete\n"
     ]
    }
   ],
   "source": [
    "# run combined model\n",
    "for i in range(1,6):\n",
    "\n",
    "    model_combined, loss_info_combined = training_functions.run_deep_model(combined_train_prepped, combined_test_prepped, \n",
    "                                                                           combined_geo_dim, epochs=20, steps_per_epoch=2000,\n",
    "                                                                           lograte=True)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((combined_training[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(combined_training[:,3], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(combined_training[:,0], dtype=tf.float32),  # Geography\n",
    "                            tf.convert_to_tensor(combined_training[:,1], dtype=tf.float32))  # Gender\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((combined_test[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(combined_test[:,3], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(combined_test[:,0], dtype=tf.float32),  # Geography\n",
    "                        tf.convert_to_tensor(combined_test[:,1], dtype=tf.float32))  # Gender\n",
    "\n",
    "    training_predictions = model_combined.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_combined.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(combined_training, 4, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(combined_test, 4, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_combined.save(f\"../models/combined_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/combined_training_predictions{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/combined_test_predictions{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
