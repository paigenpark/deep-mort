{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Mortality Prediction (DLMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os as os\n",
    "tfkl = tf.keras.layers\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set global seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_functions' from '/Users/paigepark/Desktop/deep-mort/code/training_functions.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import training_functions\n",
    "import importlib\n",
    "\n",
    "importlib.reload(training_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_training = np.loadtxt('../data/state_training.txt')\n",
    "state_test = np.loadtxt('../data/state_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_training = np.loadtxt('../data/country_training.txt')\n",
    "country_test = np.loadtxt('../data/country_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training = np.loadtxt('../data/combined_training.txt')\n",
    "combined_test = np.loadtxt('../data/combined_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos_key = np.load('../data/geos_key.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_dict = {int(code): geo for geo, code in geos_key}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single population models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I am training indiviudal models for each population. I am only saving mses rather than predictions since the prediction data would be too large to store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pop = np.unique(country_training[:, 0])\n",
    "geo_dim = int(max(n_pop) + 1)\n",
    "geo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA: False\n",
      "GPU devices: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Optional: Set memory growth to prevent over-allocation\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model AUS: Gender 0\n",
      "Epoch 1/30\n",
      "500/500 - 6s - 12ms/step - loss: 5.3884 - val_loss: 0.5356 - learning_rate: 0.0010\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m single_geo_dim \u001b[38;5;241m=\u001b[39m country_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeo_dict[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Gender \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m model_single, loss_single \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_deep_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_country_training_prepped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43msingle_country_test_prepped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43msingle_geo_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlograte\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m tc \u001b[38;5;241m=\u001b[39m single_country_test  \n\u001b[1;32m     27\u001b[0m years \u001b[38;5;241m=\u001b[39m (tc[:,\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1959\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/deep-mort/code/training_functions.py:185\u001b[0m, in \u001b[0;36mrun_deep_model\u001b[0;34m(dataset_train, dataset_test, geo_dim, epochs, steps_per_epoch, lograte)\u001b[0m\n\u001b[1;32m    181\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_model(geo_dim)\n\u001b[1;32m    183\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    184\u001b[0m                                                 min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m, cooldown\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)]\n\u001b[0;32m--> 185\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    190\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for s in range(1,6):\n",
    "    # Set reproducible seeds per iteration\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)\n",
    "    random.seed(s)\n",
    "    os.environ['PYTHONHASHSEED'] = str(s)\n",
    "    \n",
    "    for j in range(0,2):\n",
    "        for i in range(50, geo_dim):\n",
    "            country_index = i\n",
    "            gender_index = j\n",
    "            single_country_training = country_training[(country_training[:,0] == country_index) & (country_training[:,1] == gender_index)]\n",
    "            single_country_test = country_test[(country_test[:,0] == country_index) & (country_test[:,1] == gender_index)]\n",
    "\n",
    "            single_country_training_prepped = training_functions.prep_data(single_country_training, mode=\"train\", changeratetolog=True)\n",
    "            single_country_test_prepped = training_functions.prep_data(single_country_test, mode=\"test\", changeratetolog=True)\n",
    "            single_geo_dim = country_index + 1\n",
    "\n",
    "            print(f\"Running model {geo_dict[i]}: Gender {j}\")\n",
    "\n",
    "            model_single, loss_single = training_functions.run_deep_model(single_country_training_prepped, \n",
    "                                                                          single_country_test_prepped, \n",
    "                                                                          single_geo_dim, epochs=30, \n",
    "                                                                          steps_per_epoch=500, lograte=True)\n",
    "        \n",
    "            tc = single_country_test  \n",
    "            years = (tc[:,2] - 1959) / 60\n",
    "            ages  = tc[:,3]\n",
    "            geos  = tc[:,0].astype(np.int32)\n",
    "            genders = tc[:,1]\n",
    "\n",
    "            test_input_features = (\n",
    "                tf.convert_to_tensor(years, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(ages, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(geos, dtype=tf.int32),      # ensure ints\n",
    "                tf.convert_to_tensor(genders, dtype=tf.float32),\n",
    "            )\n",
    "            \n",
    "            test_predictions = model_single.predict(test_input_features)\n",
    "\n",
    "\n",
    "            inputs_test = np.delete(single_country_test, 4, axis=1)\n",
    "            test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "            geo_name = geo_dict[i]\n",
    "\n",
    "            model_single.save(f\"../models/{geo_name}_gender_{j}.keras\")   \n",
    "\n",
    "            np.savez_compressed(f\"../data/{geo_name}_gender_{j}_iter_{s}.npz\", test_predictions) \n",
    "\n",
    "print(f\"Finished training for {s} iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Country Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "country_train_prepped = training_functions.prep_data(country_training, mode=\"train\", changeratetolog=True)\n",
    "country_test_prepped = training_functions.prep_data(country_test, mode=\"test\", changeratetolog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(country_training[:, 0]).y\n",
    "country_geo_dim = np.array(tf.size(unique_vals)).item()\n",
    "country_geo_dim = country_geo_dim + 50\n",
    "country_geo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1405/1405 - 9s - 6ms/step - loss: 1.9850 - val_loss: 0.2581 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 7s - 5ms/step - loss: 0.3244 - val_loss: 0.2397 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 7s - 5ms/step - loss: 0.2508 - val_loss: 0.1768 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 7s - 5ms/step - loss: 0.2251 - val_loss: 0.1754 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 7s - 5ms/step - loss: 0.2027 - val_loss: 0.2596 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 7s - 5ms/step - loss: 0.1881 - val_loss: 0.1946 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 7s - 5ms/step - loss: 0.1853 - val_loss: 0.1806 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 7s - 5ms/step - loss: 0.1737 - val_loss: 0.1815 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "1405/1405 - 7s - 5ms/step - loss: 0.1658 - val_loss: 0.1872 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 7s - 5ms/step - loss: 0.1720 - val_loss: 0.1998 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1650 - val_loss: 0.1647 - learning_rate: 6.2500e-05\n",
      "Epoch 12/20\n",
      "1405/1405 - 8s - 5ms/step - loss: 0.1635 - val_loss: 0.1780 - learning_rate: 6.2500e-05\n",
      "Epoch 13/20\n",
      "1405/1405 - 8s - 5ms/step - loss: 0.1642 - val_loss: 0.1692 - learning_rate: 6.2500e-05\n",
      "Epoch 14/20\n",
      "1405/1405 - 8s - 5ms/step - loss: 0.1667 - val_loss: 0.1721 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "1405/1405 - 8s - 5ms/step - loss: 0.1622 - val_loss: 0.1917 - learning_rate: 1.5625e-05\n",
      "Epoch 16/20\n",
      "1405/1405 - 8s - 5ms/step - loss: 0.1628 - val_loss: 0.2029 - learning_rate: 1.5625e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 8s - 5ms/step - loss: 0.1619 - val_loss: 0.1795 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1615 - val_loss: 0.1468 - learning_rate: 3.9063e-06\n",
      "Epoch 19/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1559 - val_loss: 0.1623 - learning_rate: 3.9063e-06\n",
      "Epoch 20/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1615 - val_loss: 0.1463 - learning_rate: 3.9063e-06\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 532us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508us/step\n",
      "Iteration 1 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 2.0321 - val_loss: 0.2563 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.3306 - val_loss: 0.2149 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.2526 - val_loss: 0.2082 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 9s - 6ms/step - loss: 0.2181 - val_loss: 0.3011 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 9s - 6ms/step - loss: 0.2048 - val_loss: 0.1888 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1887 - val_loss: 0.2054 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 9s - 6ms/step - loss: 0.1808 - val_loss: 0.2179 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 9s - 6ms/step - loss: 0.1802 - val_loss: 0.1986 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1637 - val_loss: 0.1740 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1650 - val_loss: 0.1635 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1643 - val_loss: 0.1528 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1592 - val_loss: 0.1716 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.1594 - val_loss: 0.1671 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 9s - 6ms/step - loss: 0.1594 - val_loss: 0.1628 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 9s - 6ms/step - loss: 0.1605 - val_loss: 0.1698 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "1405/1405 - 9s - 6ms/step - loss: 0.1547 - val_loss: 0.1492 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 9s - 6ms/step - loss: 0.1585 - val_loss: 0.1739 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 9s - 6ms/step - loss: 0.1541 - val_loss: 0.1789 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.1570 - val_loss: 0.1551 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.1553 - val_loss: 0.1651 - learning_rate: 1.5625e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 706us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step\n",
      "Iteration 2 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 2.0433 - val_loss: 0.3644 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.3263 - val_loss: 0.2300 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.2587 - val_loss: 0.1974 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.2243 - val_loss: 0.2031 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1979 - val_loss: 0.1678 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1866 - val_loss: 0.1851 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1826 - val_loss: 0.1959 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1755 - val_loss: 0.2060 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1644 - val_loss: 0.1886 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1596 - val_loss: 0.1853 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1647 - val_loss: 0.1879 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1605 - val_loss: 0.1879 - learning_rate: 6.2500e-05\n",
      "Epoch 13/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1558 - val_loss: 0.1449 - learning_rate: 6.2500e-05\n",
      "Epoch 14/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1613 - val_loss: 0.1710 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.1586 - val_loss: 0.1789 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1576 - val_loss: 0.1577 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1584 - val_loss: 0.1757 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.1576 - val_loss: 0.2248 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1547 - val_loss: 0.1771 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1506 - val_loss: 0.1954 - learning_rate: 3.9063e-06\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 516us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 494us/step\n",
      "Iteration 3 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 2.0209 - val_loss: 0.2263 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.3265 - val_loss: 0.2114 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2499 - val_loss: 0.2050 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2177 - val_loss: 0.2267 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2021 - val_loss: 0.1872 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1911 - val_loss: 0.2197 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1839 - val_loss: 0.2021 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1782 - val_loss: 0.1744 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1723 - val_loss: 0.1665 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1738 - val_loss: 0.1799 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1725 - val_loss: 0.2018 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1749 - val_loss: 0.1835 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1639 - val_loss: 0.1782 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1612 - val_loss: 0.1798 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1561 - val_loss: 0.1701 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1587 - val_loss: 0.1785 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1553 - val_loss: 0.1807 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1617 - val_loss: 0.1649 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1559 - val_loss: 0.1461 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1561 - val_loss: 0.1547 - learning_rate: 6.2500e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 514us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step\n",
      "Iteration 4 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 2.0331 - val_loss: 0.2638 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.3196 - val_loss: 0.2346 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.2479 - val_loss: 0.3029 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.2185 - val_loss: 0.2697 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1986 - val_loss: 0.1841 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1909 - val_loss: 0.1868 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1804 - val_loss: 0.2053 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1792 - val_loss: 0.1911 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1666 - val_loss: 0.2152 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1639 - val_loss: 0.1962 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1623 - val_loss: 0.1694 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1674 - val_loss: 0.1948 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1657 - val_loss: 0.1654 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1609 - val_loss: 0.2080 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1626 - val_loss: 0.1656 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1618 - val_loss: 0.1660 - learning_rate: 2.5000e-04\n",
      "Epoch 17/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1584 - val_loss: 0.1915 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1567 - val_loss: 0.1758 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1581 - val_loss: 0.1689 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 8s - 6ms/step - loss: 0.1593 - val_loss: 0.1448 - learning_rate: 1.5625e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 528us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step\n",
      "Iteration 5 complete\n"
     ]
    }
   ],
   "source": [
    "# run country model\n",
    "for i in range(1,6):\n",
    "    # Set reproducible seeds per iteration\n",
    "    np.random.seed(i)\n",
    "    tf.random.set_seed(i)\n",
    "    random.seed(i)\n",
    "    os.environ['PYTHONHASHSEED'] = str(i)\n",
    "\n",
    "    model_country, loss_info_country = training_functions.run_deep_model(country_train_prepped, country_test_prepped, country_geo_dim, \n",
    "                                                                         epochs=20, steps_per_epoch=1405, lograte=True)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((country_training[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(country_training[:,3], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(country_training[:,0], dtype=tf.float32),  # Geography\n",
    "                            tf.convert_to_tensor(country_training[:,1], dtype=tf.float32))  # Gender\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((country_test[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(country_test[:,3], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(country_test[:,0], dtype=tf.float32),  # Geography\n",
    "                        tf.convert_to_tensor(country_test[:,1], dtype=tf.float32))  # Gender\n",
    "\n",
    "    training_predictions = model_country.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_country.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(country_training, 4, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(country_test, 4, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_country.save(f\"../models/dl_country_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/dl_country_forecast_{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/dl_country_forecast_{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined (all country / all state) DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert combined data to tensors and other prep\n",
    "combined_train_prepped = training_functions.prep_data(combined_training, mode=\"train\", changeratetolog=True)\n",
    "combined_test_prepped = training_functions.prep_data(combined_test, mode=\"test\", changeratetolog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(combined_training[:, 0]).y\n",
    "combined_geo_dim = np.array(tf.size(unique_vals)).item()\n",
    "print(combined_geo_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 1.5381 - val_loss: 0.2362 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 11s - 6ms/step - loss: 0.2940 - val_loss: 0.2458 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2388 - val_loss: 0.2514 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 18s - 9ms/step - loss: 0.2123 - val_loss: 0.2381 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1952 - val_loss: 0.1732 - learning_rate: 2.5000e-04\n",
      "Epoch 6/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1878 - val_loss: 0.2045 - learning_rate: 2.5000e-04\n",
      "Epoch 7/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1880 - val_loss: 0.1694 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1875 - val_loss: 0.1859 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1824 - val_loss: 0.1791 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1783 - val_loss: 0.1857 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1779 - val_loss: 0.1867 - learning_rate: 6.2500e-05\n",
      "Epoch 12/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1813 - val_loss: 0.1639 - learning_rate: 6.2500e-05\n",
      "Epoch 13/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1787 - val_loss: 0.1803 - learning_rate: 6.2500e-05\n",
      "Epoch 14/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1759 - val_loss: 0.2093 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1791 - val_loss: 0.1724 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1757 - val_loss: 0.1814 - learning_rate: 1.5625e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1765 - val_loss: 0.1775 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1770 - val_loss: 0.1838 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1759 - val_loss: 0.1722 - learning_rate: 3.9063e-06\n",
      "Epoch 20/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1791 - val_loss: 0.1598 - learning_rate: 3.9063e-06\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 505us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 484us/step\n",
      "Iteration 1 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 1.5388 - val_loss: 0.2117 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.2836 - val_loss: 0.2457 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.2318 - val_loss: 0.2551 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.2080 - val_loss: 0.2317 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1925 - val_loss: 0.1736 - learning_rate: 2.5000e-04\n",
      "Epoch 6/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1853 - val_loss: 0.2035 - learning_rate: 2.5000e-04\n",
      "Epoch 7/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1860 - val_loss: 0.1660 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1845 - val_loss: 0.1858 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1803 - val_loss: 0.1800 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1772 - val_loss: 0.1863 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1761 - val_loss: 0.1900 - learning_rate: 6.2500e-05\n",
      "Epoch 12/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1795 - val_loss: 0.1660 - learning_rate: 6.2500e-05\n",
      "Epoch 13/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1772 - val_loss: 0.1800 - learning_rate: 6.2500e-05\n",
      "Epoch 14/20\n",
      "2000/2000 - 11s - 6ms/step - loss: 0.1744 - val_loss: 0.2100 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1777 - val_loss: 0.1755 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1740 - val_loss: 0.1852 - learning_rate: 1.5625e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1752 - val_loss: 0.1802 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 11s - 6ms/step - loss: 0.1758 - val_loss: 0.1844 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1751 - val_loss: 0.1743 - learning_rate: 3.9063e-06\n",
      "Epoch 20/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1781 - val_loss: 0.1604 - learning_rate: 3.9063e-06\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 493us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 599us/step\n",
      "Iteration 2 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 1.5413 - val_loss: 0.2314 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.2824 - val_loss: 0.2558 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 11s - 6ms/step - loss: 0.2331 - val_loss: 0.2413 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.2099 - val_loss: 0.2290 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.2011 - val_loss: 0.1930 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1903 - val_loss: 0.2174 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1897 - val_loss: 0.1728 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1883 - val_loss: 0.1975 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1828 - val_loss: 0.2093 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1790 - val_loss: 0.1928 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1739 - val_loss: 0.1942 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1770 - val_loss: 0.1665 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1741 - val_loss: 0.1819 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1717 - val_loss: 0.2112 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1745 - val_loss: 0.1744 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1705 - val_loss: 0.1856 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1713 - val_loss: 0.1789 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1713 - val_loss: 0.1850 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1703 - val_loss: 0.1764 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1729 - val_loss: 0.1588 - learning_rate: 1.5625e-05\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 495us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 483us/step\n",
      "Iteration 3 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 1.5378 - val_loss: 0.2310 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 11s - 6ms/step - loss: 0.2886 - val_loss: 0.2624 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 11s - 6ms/step - loss: 0.2352 - val_loss: 0.2488 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.2098 - val_loss: 0.2257 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.2014 - val_loss: 0.1876 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 11s - 6ms/step - loss: 0.1906 - val_loss: 0.2167 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1894 - val_loss: 0.1702 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1889 - val_loss: 0.1938 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1833 - val_loss: 0.2087 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1792 - val_loss: 0.1888 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1742 - val_loss: 0.1895 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1777 - val_loss: 0.1620 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1745 - val_loss: 0.1825 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1721 - val_loss: 0.2075 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1751 - val_loss: 0.1739 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1705 - val_loss: 0.1820 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1712 - val_loss: 0.1784 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1717 - val_loss: 0.1839 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1703 - val_loss: 0.1750 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1729 - val_loss: 0.1556 - learning_rate: 1.5625e-05\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 501us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 561us/step\n",
      "Iteration 4 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 1.5351 - val_loss: 0.2238 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.2852 - val_loss: 0.3003 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.2308 - val_loss: 0.2624 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.2057 - val_loss: 0.2230 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1972 - val_loss: 0.1808 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1862 - val_loss: 0.2104 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1865 - val_loss: 0.1709 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1854 - val_loss: 0.1981 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1804 - val_loss: 0.1974 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1770 - val_loss: 0.1873 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1730 - val_loss: 0.1893 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1762 - val_loss: 0.1646 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1729 - val_loss: 0.1790 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1705 - val_loss: 0.2103 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1737 - val_loss: 0.1732 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1688 - val_loss: 0.1816 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1701 - val_loss: 0.1772 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1699 - val_loss: 0.1847 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1693 - val_loss: 0.1733 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "2000/2000 - 12s - 6ms/step - loss: 0.1715 - val_loss: 0.1558 - learning_rate: 1.5625e-05\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 537us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 521us/step\n",
      "Iteration 5 complete\n"
     ]
    }
   ],
   "source": [
    "# run combined model\n",
    "for i in range(1,6):\n",
    "    # Set reproducible seeds per iteration\n",
    "    np.random.seed(i)\n",
    "    tf.random.set_seed(i)\n",
    "    random.seed(i)\n",
    "    os.environ['PYTHONHASHSEED'] = str(i)\n",
    "\n",
    "    model_combined, loss_info_combined = training_functions.run_deep_model(combined_train_prepped, combined_test_prepped, \n",
    "                                                                           combined_geo_dim, epochs=20, steps_per_epoch=2000,\n",
    "                                                                           lograte=True)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((combined_training[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(combined_training[:,3], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(combined_training[:,0], dtype=tf.float32),  # Geography\n",
    "                            tf.convert_to_tensor(combined_training[:,1], dtype=tf.float32))  # Gender\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((combined_test[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(combined_test[:,3], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(combined_test[:,0], dtype=tf.float32),  # Geography\n",
    "                        tf.convert_to_tensor(combined_test[:,1], dtype=tf.float32))  # Gender\n",
    "\n",
    "    training_predictions = model_combined.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_combined.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(combined_training, 4, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(combined_test, 4, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_combined.save(f\"../models/combined_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/dl_combined_forecast_{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/dl_combined_forecast_{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
