{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Mortality Prediction (DLMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%run data_preparation/split_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "tfkl = tf.keras.layers\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_functions' from '/home/ppark/repos/deep-mort/code/training_functions.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import training_functions\n",
    "import importlib\n",
    "\n",
    "importlib.reload(training_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_training = np.loadtxt('../data/state_training.txt')\n",
    "state_test = np.loadtxt('../data/state_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_training = np.loadtxt('../data/country_training_new.txt')\n",
    "country_test = np.loadtxt('../data/country_test_new.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training = np.loadtxt('../data/combined_training_new.txt')\n",
    "combined_test = np.loadtxt('../data/combined_test_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos_key = np.load('../data/geos_key_new.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_dict = {int(code): geo for geo, code in geos_key}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single population models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I am training indiviudal models for each population. I am only saving mses rather than predictions since the prediction data would be too large to store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pop = np.unique(country_test[:, 0])\n",
    "geo_dim = int(max(n_pop) + 1)\n",
    "geo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 10:42:39.283342: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.1\n",
      "Built with CUDA: True\n",
      "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Optional: Set memory growth to prevent over-allocation\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model AUS: Gender 0\n",
      "hello\n",
      "Epoch 1/30\n",
      "500/500 - 12s - loss: 5.5942 - val_loss: 0.4289 - lr: 0.0010 - 12s/epoch - 24ms/step\n",
      "Epoch 2/30\n",
      "500/500 - 4s - loss: 0.3910 - val_loss: 0.1492 - lr: 0.0010 - 4s/epoch - 9ms/step\n",
      "Epoch 3/30\n",
      "500/500 - 4s - loss: 0.2936 - val_loss: 0.0980 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 4/30\n",
      "500/500 - 4s - loss: 0.2268 - val_loss: 0.1172 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 5/30\n",
      "500/500 - 4s - loss: 0.1817 - val_loss: 0.0450 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 6/30\n",
      "500/500 - 4s - loss: 0.1519 - val_loss: 0.1110 - lr: 0.0010 - 4s/epoch - 7ms/step\n",
      "Epoch 7/30\n",
      "500/500 - 4s - loss: 0.1301 - val_loss: 0.0584 - lr: 0.0010 - 4s/epoch - 7ms/step\n",
      "Epoch 8/30\n",
      "500/500 - 4s - loss: 0.1127 - val_loss: 0.0366 - lr: 0.0010 - 4s/epoch - 7ms/step\n",
      "Epoch 9/30\n",
      "500/500 - 4s - loss: 0.1015 - val_loss: 0.0421 - lr: 0.0010 - 4s/epoch - 9ms/step\n",
      "Epoch 10/30\n",
      "500/500 - 4s - loss: 0.0916 - val_loss: 0.0428 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 11/30\n",
      "500/500 - 4s - loss: 0.0851 - val_loss: 0.0828 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 12/30\n",
      "500/500 - 4s - loss: 0.0771 - val_loss: 0.0310 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 13/30\n",
      "500/500 - 4s - loss: 0.0763 - val_loss: 0.0310 - lr: 2.5000e-04 - 4s/epoch - 7ms/step\n",
      "Epoch 14/30\n",
      "500/500 - 4s - loss: 0.0741 - val_loss: 0.0369 - lr: 2.5000e-04 - 4s/epoch - 7ms/step\n",
      "Epoch 15/30\n",
      "500/500 - 4s - loss: 0.0727 - val_loss: 0.0361 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 16/30\n",
      "500/500 - 4s - loss: 0.0731 - val_loss: 0.0394 - lr: 2.5000e-04 - 4s/epoch - 7ms/step\n",
      "Epoch 17/30\n",
      "500/500 - 4s - loss: 0.0656 - val_loss: 0.0308 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 18/30\n",
      "500/500 - 4s - loss: 0.0668 - val_loss: 0.0283 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 19/30\n",
      "500/500 - 4s - loss: 0.0683 - val_loss: 0.0297 - lr: 6.2500e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 20/30\n",
      "500/500 - 4s - loss: 0.0663 - val_loss: 0.0336 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 21/30\n",
      "500/500 - 4s - loss: 0.0660 - val_loss: 0.0288 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 22/30\n",
      "500/500 - 4s - loss: 0.0648 - val_loss: 0.0286 - lr: 1.5625e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 23/30\n",
      "500/500 - 4s - loss: 0.0643 - val_loss: 0.0335 - lr: 1.5625e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 24/30\n",
      "500/500 - 4s - loss: 0.0670 - val_loss: 0.0288 - lr: 1.5625e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 25/30\n",
      "500/500 - 3s - loss: 0.0678 - val_loss: 0.0299 - lr: 3.9063e-06 - 3s/epoch - 7ms/step\n",
      "Epoch 26/30\n",
      "500/500 - 4s - loss: 0.0639 - val_loss: 0.0302 - lr: 3.9063e-06 - 4s/epoch - 7ms/step\n",
      "Epoch 27/30\n",
      "500/500 - 4s - loss: 0.0667 - val_loss: 0.0295 - lr: 3.9063e-06 - 4s/epoch - 7ms/step\n",
      "Epoch 28/30\n",
      "500/500 - 4s - loss: 0.0649 - val_loss: 0.0282 - lr: 9.7656e-07 - 4s/epoch - 7ms/step\n",
      "Epoch 29/30\n",
      "500/500 - 4s - loss: 0.0654 - val_loss: 0.0282 - lr: 9.7656e-07 - 4s/epoch - 7ms/step\n",
      "Epoch 30/30\n",
      "500/500 - 4s - loss: 0.0644 - val_loss: 0.0293 - lr: 9.7656e-07 - 4s/epoch - 7ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Running model AUS: Gender 1\n",
      "hello\n",
      "Epoch 1/30\n",
      "500/500 - 13s - loss: 4.2780 - val_loss: 0.3848 - lr: 0.0010 - 13s/epoch - 26ms/step\n",
      "Epoch 2/30\n",
      "500/500 - 4s - loss: 0.3393 - val_loss: 0.3237 - lr: 0.0010 - 4s/epoch - 9ms/step\n",
      "Epoch 3/30\n",
      "500/500 - 4s - loss: 0.2456 - val_loss: 0.1507 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 4/30\n",
      "500/500 - 5s - loss: 0.1862 - val_loss: 0.0923 - lr: 0.0010 - 5s/epoch - 10ms/step\n",
      "Epoch 5/30\n",
      "500/500 - 5s - loss: 0.1534 - val_loss: 0.0952 - lr: 0.0010 - 5s/epoch - 9ms/step\n",
      "Epoch 6/30\n",
      "500/500 - 5s - loss: 0.1263 - val_loss: 0.0559 - lr: 0.0010 - 5s/epoch - 10ms/step\n",
      "Epoch 7/30\n",
      "500/500 - 5s - loss: 0.1060 - val_loss: 0.0725 - lr: 0.0010 - 5s/epoch - 10ms/step\n",
      "Epoch 8/30\n",
      "500/500 - 4s - loss: 0.0927 - val_loss: 0.0864 - lr: 0.0010 - 4s/epoch - 9ms/step\n",
      "Epoch 9/30\n",
      "500/500 - 5s - loss: 0.0828 - val_loss: 0.0509 - lr: 0.0010 - 5s/epoch - 9ms/step\n",
      "Epoch 10/30\n",
      "500/500 - 4s - loss: 0.0763 - val_loss: 0.0325 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 11/30\n",
      "500/500 - 4s - loss: 0.0714 - val_loss: 0.0285 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 12/30\n",
      "500/500 - 4s - loss: 0.0647 - val_loss: 0.0881 - lr: 0.0010 - 4s/epoch - 9ms/step\n",
      "Epoch 13/30\n",
      "500/500 - 5s - loss: 0.0648 - val_loss: 0.0624 - lr: 0.0010 - 5s/epoch - 10ms/step\n",
      "Epoch 14/30\n",
      "500/500 - 4s - loss: 0.0571 - val_loss: 0.0315 - lr: 0.0010 - 4s/epoch - 9ms/step\n",
      "Epoch 15/30\n",
      "500/500 - 4s - loss: 0.0540 - val_loss: 0.0272 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 16/30\n",
      "500/500 - 4s - loss: 0.0524 - val_loss: 0.0286 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 17/30\n",
      "500/500 - 4s - loss: 0.0525 - val_loss: 0.0335 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 18/30\n",
      "500/500 - 4s - loss: 0.0515 - val_loss: 0.0341 - lr: 2.5000e-04 - 4s/epoch - 7ms/step\n",
      "Epoch 19/30\n",
      "500/500 - 4s - loss: 0.0514 - val_loss: 0.0255 - lr: 6.2500e-05 - 4s/epoch - 9ms/step\n",
      "Epoch 20/30\n",
      "500/500 - 4s - loss: 0.0499 - val_loss: 0.0254 - lr: 6.2500e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 21/30\n",
      "500/500 - 4s - loss: 0.0493 - val_loss: 0.0228 - lr: 6.2500e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 22/30\n",
      "500/500 - 4s - loss: 0.0488 - val_loss: 0.0224 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 23/30\n",
      "500/500 - 4s - loss: 0.0474 - val_loss: 0.0241 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 24/30\n",
      "500/500 - 4s - loss: 0.0533 - val_loss: 0.0248 - lr: 6.2500e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 25/30\n",
      "500/500 - 4s - loss: 0.0496 - val_loss: 0.0194 - lr: 6.2500e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 26/30\n",
      "500/500 - 4s - loss: 0.0500 - val_loss: 0.0237 - lr: 6.2500e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 27/30\n",
      "500/500 - 4s - loss: 0.0495 - val_loss: 0.0233 - lr: 6.2500e-05 - 4s/epoch - 9ms/step\n",
      "Epoch 28/30\n",
      "500/500 - 4s - loss: 0.0476 - val_loss: 0.0246 - lr: 6.2500e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 29/30\n",
      "500/500 - 5s - loss: 0.0471 - val_loss: 0.0234 - lr: 1.5625e-05 - 5s/epoch - 10ms/step\n",
      "Epoch 30/30\n",
      "500/500 - 5s - loss: 0.0498 - val_loss: 0.0230 - lr: 1.5625e-05 - 5s/epoch - 9ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Running model AUS: Gender 0\n",
      "hello\n",
      "Epoch 1/30\n",
      "500/500 - 12s - loss: 5.5133 - val_loss: 0.5237 - lr: 0.0010 - 12s/epoch - 24ms/step\n",
      "Epoch 2/30\n",
      "500/500 - 4s - loss: 0.3988 - val_loss: 0.0878 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 3/30\n",
      "500/500 - 4s - loss: 0.2935 - val_loss: 0.0692 - lr: 0.0010 - 4s/epoch - 9ms/step\n",
      "Epoch 4/30\n",
      "500/500 - 4s - loss: 0.2218 - val_loss: 0.0463 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 5/30\n",
      "500/500 - 4s - loss: 0.1802 - val_loss: 0.0479 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 6/30\n",
      "500/500 - 4s - loss: 0.1493 - val_loss: 0.0396 - lr: 0.0010 - 4s/epoch - 7ms/step\n",
      "Epoch 7/30\n",
      "500/500 - 4s - loss: 0.1273 - val_loss: 0.0580 - lr: 0.0010 - 4s/epoch - 7ms/step\n",
      "Epoch 8/30\n",
      "500/500 - 4s - loss: 0.1117 - val_loss: 0.0403 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 9/30\n",
      "500/500 - 4s - loss: 0.1008 - val_loss: 0.0561 - lr: 0.0010 - 4s/epoch - 7ms/step\n",
      "Epoch 10/30\n",
      "500/500 - 4s - loss: 0.0884 - val_loss: 0.0300 - lr: 2.5000e-04 - 4s/epoch - 7ms/step\n",
      "Epoch 11/30\n",
      "500/500 - 4s - loss: 0.0895 - val_loss: 0.0364 - lr: 2.5000e-04 - 4s/epoch - 7ms/step\n",
      "Epoch 12/30\n",
      "500/500 - 4s - loss: 0.0826 - val_loss: 0.0368 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 13/30\n",
      "500/500 - 5s - loss: 0.0861 - val_loss: 0.0348 - lr: 2.5000e-04 - 5s/epoch - 10ms/step\n",
      "Epoch 14/30\n",
      "500/500 - 5s - loss: 0.0787 - val_loss: 0.0335 - lr: 6.2500e-05 - 5s/epoch - 10ms/step\n",
      "Epoch 15/30\n",
      "500/500 - 4s - loss: 0.0767 - val_loss: 0.0358 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 16/30\n",
      "500/500 - 4s - loss: 0.0819 - val_loss: 0.0295 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 17/30\n",
      "500/500 - 4s - loss: 0.0762 - val_loss: 0.0306 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 18/30\n",
      "500/500 - 4s - loss: 0.0765 - val_loss: 0.0278 - lr: 6.2500e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 19/30\n",
      "500/500 - 4s - loss: 0.0740 - val_loss: 0.0297 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 20/30\n",
      "500/500 - 4s - loss: 0.0749 - val_loss: 0.0293 - lr: 6.2500e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 21/30\n",
      "500/500 - 4s - loss: 0.0740 - val_loss: 0.0300 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 22/30\n",
      "500/500 - 4s - loss: 0.0734 - val_loss: 0.0308 - lr: 1.5625e-05 - 4s/epoch - 9ms/step\n",
      "Epoch 23/30\n",
      "500/500 - 4s - loss: 0.0744 - val_loss: 0.0313 - lr: 1.5625e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 24/30\n",
      "500/500 - 4s - loss: 0.0746 - val_loss: 0.0294 - lr: 1.5625e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 25/30\n",
      "500/500 - 4s - loss: 0.0726 - val_loss: 0.0262 - lr: 3.9063e-06 - 4s/epoch - 8ms/step\n",
      "Epoch 26/30\n",
      "500/500 - 4s - loss: 0.0739 - val_loss: 0.0289 - lr: 3.9063e-06 - 4s/epoch - 7ms/step\n",
      "Epoch 27/30\n",
      "500/500 - 4s - loss: 0.0719 - val_loss: 0.0301 - lr: 3.9063e-06 - 4s/epoch - 7ms/step\n",
      "Epoch 28/30\n",
      "500/500 - 4s - loss: 0.0734 - val_loss: 0.0275 - lr: 3.9063e-06 - 4s/epoch - 7ms/step\n",
      "Epoch 29/30\n",
      "500/500 - 4s - loss: 0.0700 - val_loss: 0.0318 - lr: 9.7656e-07 - 4s/epoch - 7ms/step\n",
      "Epoch 30/30\n",
      "500/500 - 4s - loss: 0.0724 - val_loss: 0.0299 - lr: 9.7656e-07 - 4s/epoch - 7ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Running model AUS: Gender 1\n",
      "hello\n",
      "Epoch 1/30\n",
      "500/500 - 12s - loss: 4.2990 - val_loss: 0.2950 - lr: 0.0010 - 12s/epoch - 25ms/step\n",
      "Epoch 2/30\n",
      "500/500 - 5s - loss: 0.3460 - val_loss: 0.1260 - lr: 0.0010 - 5s/epoch - 10ms/step\n",
      "Epoch 3/30\n",
      "500/500 - 5s - loss: 0.2480 - val_loss: 0.0587 - lr: 0.0010 - 5s/epoch - 9ms/step\n",
      "Epoch 4/30\n",
      "500/500 - 4s - loss: 0.1874 - val_loss: 0.1255 - lr: 0.0010 - 4s/epoch - 9ms/step\n",
      "Epoch 5/30\n",
      "500/500 - 5s - loss: 0.1496 - val_loss: 0.0702 - lr: 0.0010 - 5s/epoch - 10ms/step\n",
      "Epoch 6/30\n",
      "500/500 - 4s - loss: 0.1249 - val_loss: 0.1224 - lr: 0.0010 - 4s/epoch - 8ms/step\n",
      "Epoch 7/30\n",
      "500/500 - 4s - loss: 0.1071 - val_loss: 0.0450 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 8/30\n",
      "500/500 - 4s - loss: 0.1040 - val_loss: 0.0344 - lr: 2.5000e-04 - 4s/epoch - 7ms/step\n",
      "Epoch 9/30\n",
      "500/500 - 4s - loss: 0.0974 - val_loss: 0.0318 - lr: 2.5000e-04 - 4s/epoch - 7ms/step\n",
      "Epoch 10/30\n",
      "500/500 - 4s - loss: 0.0946 - val_loss: 0.0284 - lr: 2.5000e-04 - 4s/epoch - 7ms/step\n",
      "Epoch 11/30\n",
      "500/500 - 4s - loss: 0.0893 - val_loss: 0.0486 - lr: 2.5000e-04 - 4s/epoch - 7ms/step\n",
      "Epoch 12/30\n",
      "500/500 - 4s - loss: 0.0881 - val_loss: 0.0392 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 13/30\n",
      "500/500 - 4s - loss: 0.0830 - val_loss: 0.0273 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 14/30\n",
      "500/500 - 4s - loss: 0.0768 - val_loss: 0.0291 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 15/30\n",
      "500/500 - 4s - loss: 0.0745 - val_loss: 0.0423 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 16/30\n",
      "500/500 - 4s - loss: 0.0727 - val_loss: 0.0244 - lr: 2.5000e-04 - 4s/epoch - 7ms/step\n",
      "Epoch 17/30\n",
      "500/500 - 4s - loss: 0.0717 - val_loss: 0.0314 - lr: 2.5000e-04 - 4s/epoch - 8ms/step\n",
      "Epoch 18/30\n",
      "500/500 - 5s - loss: 0.0663 - val_loss: 0.0377 - lr: 2.5000e-04 - 5s/epoch - 9ms/step\n",
      "Epoch 19/30\n",
      "500/500 - 4s - loss: 0.0673 - val_loss: 0.0261 - lr: 2.5000e-04 - 4s/epoch - 9ms/step\n",
      "Epoch 20/30\n",
      "500/500 - 4s - loss: 0.0610 - val_loss: 0.0278 - lr: 6.2500e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 21/30\n",
      "500/500 - 4s - loss: 0.0640 - val_loss: 0.0254 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 22/30\n",
      "500/500 - 4s - loss: 0.0633 - val_loss: 0.0255 - lr: 6.2500e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 23/30\n",
      "500/500 - 4s - loss: 0.0595 - val_loss: 0.0267 - lr: 1.5625e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 24/30\n",
      "500/500 - 4s - loss: 0.0597 - val_loss: 0.0235 - lr: 1.5625e-05 - 4s/epoch - 9ms/step\n",
      "Epoch 25/30\n",
      "500/500 - 4s - loss: 0.0595 - val_loss: 0.0255 - lr: 1.5625e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 26/30\n",
      "500/500 - 4s - loss: 0.0597 - val_loss: 0.0231 - lr: 1.5625e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 27/30\n",
      "500/500 - 4s - loss: 0.0592 - val_loss: 0.0245 - lr: 1.5625e-05 - 4s/epoch - 8ms/step\n",
      "Epoch 28/30\n",
      "500/500 - 4s - loss: 0.0612 - val_loss: 0.0243 - lr: 1.5625e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 29/30\n",
      "500/500 - 4s - loss: 0.0609 - val_loss: 0.0248 - lr: 1.5625e-05 - 4s/epoch - 7ms/step\n",
      "Epoch 30/30\n",
      "500/500 - 4s - loss: 0.0589 - val_loss: 0.0238 - lr: 3.9063e-06 - 4s/epoch - 7ms/step\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "Finished training for 2 iterations.\n"
     ]
    }
   ],
   "source": [
    "for s in range(1,3):\n",
    "    for j in range(0,2):\n",
    "        for i in range(50, 51):\n",
    "            country_index = i\n",
    "            gender_index = j\n",
    "            single_country_training = country_training[(country_training[:,0] == country_index) & (country_training[:,1] == gender_index)]\n",
    "            single_country_test = country_test[(country_test[:,0] == country_index) & (country_test[:,1] == gender_index)]\n",
    "\n",
    "            single_country_training_prepped = training_functions.prep_data(single_country_training, mode=\"train\", changeratetolog=True)\n",
    "            single_country_test_prepped = training_functions.prep_data(single_country_test, mode=\"test\", changeratetolog=True)\n",
    "            single_geo_dim = country_index + 1\n",
    "\n",
    "            print(f\"Running model {geo_dict[i]}: Gender {j}\")\n",
    "\n",
    "            model_single, loss_single = training_functions.run_deep_model(single_country_training_prepped, \n",
    "                                                                          single_country_test_prepped, \n",
    "                                                                          single_geo_dim, epochs=30, \n",
    "                                                                          steps_per_epoch=500, lograte=True)\n",
    "        \n",
    "            tc = single_country_test  \n",
    "            years = (tc[:,2] - 1959) / 60\n",
    "            ages  = tc[:,3]\n",
    "            geos  = tc[:,0].astype(np.int32)\n",
    "            genders = tc[:,1]\n",
    "\n",
    "            test_input_features = (\n",
    "                tf.convert_to_tensor(years, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(ages, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(geos, dtype=tf.int32),      # ensure ints\n",
    "                tf.convert_to_tensor(genders, dtype=tf.float32),\n",
    "            )\n",
    "            \n",
    "            test_predictions = model_single.predict(test_input_features)\n",
    "\n",
    "\n",
    "            inputs_test = np.delete(single_country_test, 4, axis=1)\n",
    "            test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "            geo_name = geo_dict[i]\n",
    "\n",
    "            model_single.save(f\"../models/{geo_name}_gender_{j}.keras\")   \n",
    "\n",
    "            np.savez_compressed(f\"../data/single_preds/{geo_name}_gender_{j}_iter_{s}.npz\", test_predictions) \n",
    "\n",
    "print(f\"Finished training for {s} iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Country Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "country_train_prepped = training_functions.prep_data(country_training, mode=\"train\", changeratetolog=True)\n",
    "country_test_prepped = training_functions.prep_data(country_test, mode=\"test\", changeratetolog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(country_training[:, 0]).y\n",
    "country_geo_dim = np.array(tf.size(unique_vals)).item()\n",
    "country_geo_dim = country_geo_dim + 50\n",
    "country_geo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1405"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.ceil(len(country_training)/ 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 2.0501 - val_loss: 0.2499 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.3321 - val_loss: 0.2121 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2541 - val_loss: 0.1817 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.2135 - val_loss: 0.1808 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.2010 - val_loss: 0.1987 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.1932 - val_loss: 0.2210 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1786 - val_loss: 0.2357 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1682 - val_loss: 0.1942 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.1720 - val_loss: 0.1717 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1637 - val_loss: 0.1915 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1714 - val_loss: 0.1779 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1616 - val_loss: 0.1524 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1630 - val_loss: 0.1738 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1612 - val_loss: 0.1878 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1634 - val_loss: 0.1826 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1573 - val_loss: 0.1470 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1567 - val_loss: 0.1942 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1620 - val_loss: 0.1606 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 14s - 10ms/step - loss: 0.1569 - val_loss: 0.1953 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1545 - val_loss: 0.1677 - learning_rate: 1.5625e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 768us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step\n",
      "Iteration 1 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 14s - 10ms/step - loss: 1.9925 - val_loss: 0.2836 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.3387 - val_loss: 0.2105 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 11s - 7ms/step - loss: 0.2551 - val_loss: 0.1938 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.2211 - val_loss: 0.2003 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1960 - val_loss: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 16s - 11ms/step - loss: 0.1920 - val_loss: 0.2109 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.1713 - val_loss: 0.1771 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1757 - val_loss: 0.1850 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1689 - val_loss: 0.1958 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1637 - val_loss: 0.1498 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1646 - val_loss: 0.1859 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1639 - val_loss: 0.1631 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1687 - val_loss: 0.1686 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1574 - val_loss: 0.1715 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1592 - val_loss: 0.1778 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1596 - val_loss: 0.1657 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1585 - val_loss: 0.1686 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1610 - val_loss: 0.1658 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1573 - val_loss: 0.1692 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1577 - val_loss: 0.1676 - learning_rate: 3.9063e-06\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 756us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 602us/step\n",
      "Iteration 2 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 16s - 11ms/step - loss: 1.9587 - val_loss: 0.2350 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 13s - 10ms/step - loss: 0.3369 - val_loss: 0.2365 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.2515 - val_loss: 0.1991 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.2207 - val_loss: 0.2170 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 11s - 7ms/step - loss: 0.1984 - val_loss: 0.1997 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1900 - val_loss: 0.1811 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 14s - 10ms/step - loss: 0.1847 - val_loss: 0.1948 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1793 - val_loss: 0.2137 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.1708 - val_loss: 0.1633 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1691 - val_loss: 0.1659 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1745 - val_loss: 0.1809 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1716 - val_loss: 0.1783 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1600 - val_loss: 0.1800 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1571 - val_loss: 0.1754 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1550 - val_loss: 0.1704 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1579 - val_loss: 0.1491 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1523 - val_loss: 0.1688 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1550 - val_loss: 0.1592 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1549 - val_loss: 0.1641 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1556 - val_loss: 0.1745 - learning_rate: 1.5625e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 758us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step\n",
      "Iteration 3 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 17s - 12ms/step - loss: 2.0076 - val_loss: 0.3259 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.3307 - val_loss: 0.1950 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.2483 - val_loss: 0.2012 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2209 - val_loss: 0.2018 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2011 - val_loss: 0.2227 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1774 - val_loss: 0.1964 - learning_rate: 2.5000e-04\n",
      "Epoch 7/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.1766 - val_loss: 0.1791 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1755 - val_loss: 0.1647 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1665 - val_loss: 0.1916 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1688 - val_loss: 0.1461 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1704 - val_loss: 0.1749 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1710 - val_loss: 0.1902 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1679 - val_loss: 0.1696 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1656 - val_loss: 0.1688 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1590 - val_loss: 0.1837 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1602 - val_loss: 0.1666 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1585 - val_loss: 0.1470 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1600 - val_loss: 0.1559 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1630 - val_loss: 0.1590 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1635 - val_loss: 0.1790 - learning_rate: 3.9063e-06\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 738us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 593us/step\n",
      "Iteration 4 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 17s - 12ms/step - loss: 2.0672 - val_loss: 0.2633 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.3351 - val_loss: 0.2479 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2524 - val_loss: 0.2085 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.2216 - val_loss: 0.1839 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.2027 - val_loss: 0.2189 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1888 - val_loss: 0.1722 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1861 - val_loss: 0.1786 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1752 - val_loss: 0.2629 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1766 - val_loss: 0.1940 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1626 - val_loss: 0.1846 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1586 - val_loss: 0.1642 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1631 - val_loss: 0.1692 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1556 - val_loss: 0.1597 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1649 - val_loss: 0.1603 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1544 - val_loss: 0.1756 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1586 - val_loss: 0.1719 - learning_rate: 2.5000e-04\n",
      "Epoch 17/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1522 - val_loss: 0.1749 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1569 - val_loss: 0.1595 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1592 - val_loss: 0.1515 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1542 - val_loss: 0.1746 - learning_rate: 6.2500e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 662us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518us/step\n",
      "Iteration 5 complete\n"
     ]
    }
   ],
   "source": [
    "# run country model\n",
    "for i in range(1,6):\n",
    "\n",
    "    model_country, loss_info_country = training_functions.run_deep_model(country_train_prepped, country_test_prepped, country_geo_dim, \n",
    "                                                                         epochs=20, steps_per_epoch=1405, lograte=True)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((country_training[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(country_training[:,3], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(country_training[:,0], dtype=tf.float32),  # Geography\n",
    "                            tf.convert_to_tensor(country_training[:,1], dtype=tf.float32))  # Gender\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((country_test[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(country_test[:,3], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(country_test[:,0], dtype=tf.float32),  # Geography\n",
    "                        tf.convert_to_tensor(country_test[:,1], dtype=tf.float32))  # Gender\n",
    "\n",
    "    training_predictions = model_country.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_country.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(country_training, 4, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(country_test, 4, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_country.save(f\"../models/dl_country_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/dl_country_forecast{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/dl_country_forecast{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined (all country / all state) DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert combined data to tensors and other prep\n",
    "combined_train_prepped = training_functions.prep_data(combined_training, mode=\"train\", changeratetolog=True)\n",
    "combined_test_prepped = training_functions.prep_data(combined_test, mode=\"test\", changeratetolog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(combined_training[:, 0]).y\n",
    "combined_geo_dim = np.array(tf.size(unique_vals)).item()\n",
    "print(combined_geo_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2000/2000 - 19s - 9ms/step - loss: 1.5262 - val_loss: 0.2362 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.2855 - val_loss: 0.2518 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.2300 - val_loss: 0.2428 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2115 - val_loss: 0.2219 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1956 - val_loss: 0.2163 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1900 - val_loss: 0.1822 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1857 - val_loss: 0.1922 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "2000/2000 - 22s - 11ms/step - loss: 0.1839 - val_loss: 0.1892 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "2000/2000 - 18s - 9ms/step - loss: 0.1836 - val_loss: 0.2220 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1757 - val_loss: 0.1742 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1757 - val_loss: 0.1960 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1752 - val_loss: 0.1854 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1728 - val_loss: 0.1851 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1710 - val_loss: 0.1745 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1687 - val_loss: 0.1960 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1746 - val_loss: 0.2115 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 18s - 9ms/step - loss: 0.1729 - val_loss: 0.1988 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1696 - val_loss: 0.1894 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.1723 - val_loss: 0.1905 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1678 - val_loss: 0.2066 - learning_rate: 3.9063e-06\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 705us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 726us/step\n",
      "Iteration 1 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 21s - 10ms/step - loss: 1.5445 - val_loss: 0.2285 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2897 - val_loss: 0.2927 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2345 - val_loss: 0.2145 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.2094 - val_loss: 0.2166 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.1963 - val_loss: 0.2417 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1911 - val_loss: 0.2202 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1810 - val_loss: 0.2264 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1778 - val_loss: 0.1833 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1811 - val_loss: 0.1720 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.1757 - val_loss: 0.1896 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1765 - val_loss: 0.1873 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1806 - val_loss: 0.1757 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1743 - val_loss: 0.2139 - learning_rate: 6.2500e-05\n",
      "Epoch 14/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1751 - val_loss: 0.2051 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1756 - val_loss: 0.1550 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1734 - val_loss: 0.1730 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1705 - val_loss: 0.1771 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1738 - val_loss: 0.1811 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1723 - val_loss: 0.1853 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1693 - val_loss: 0.1857 - learning_rate: 1.5625e-05\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 672us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 796us/step\n",
      "Iteration 2 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 19s - 10ms/step - loss: 1.5301 - val_loss: 0.2317 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.2842 - val_loss: 0.2037 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2308 - val_loss: 0.2392 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.2080 - val_loss: 0.2006 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1991 - val_loss: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1932 - val_loss: 0.2169 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1872 - val_loss: 0.1827 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1857 - val_loss: 0.2010 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1865 - val_loss: 0.1971 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1802 - val_loss: 0.1937 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "2000/2000 - 13s - 6ms/step - loss: 0.1762 - val_loss: 0.2284 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1727 - val_loss: 0.1686 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1737 - val_loss: 0.1996 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1734 - val_loss: 0.1756 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1722 - val_loss: 0.1774 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1741 - val_loss: 0.1792 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1705 - val_loss: 0.1893 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1720 - val_loss: 0.2131 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1690 - val_loss: 0.1923 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1728 - val_loss: 0.1860 - learning_rate: 1.5625e-05\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 598us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 779us/step\n",
      "Iteration 3 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 19s - 9ms/step - loss: 1.5412 - val_loss: 0.2544 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2864 - val_loss: 0.2267 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2284 - val_loss: 0.2359 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.2070 - val_loss: 0.2529 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1947 - val_loss: 0.2105 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1864 - val_loss: 0.2244 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1919 - val_loss: 0.2307 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1820 - val_loss: 0.2076 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "2000/2000 - 19s - 10ms/step - loss: 0.1835 - val_loss: 0.2455 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.1779 - val_loss: 0.1952 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1788 - val_loss: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1792 - val_loss: 0.1878 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1773 - val_loss: 0.2025 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1808 - val_loss: 0.1925 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1788 - val_loss: 0.1834 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1791 - val_loss: 0.1859 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "2000/2000 - 17s - 8ms/step - loss: 0.1777 - val_loss: 0.1985 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1753 - val_loss: 0.1993 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1755 - val_loss: 0.1697 - learning_rate: 2.5000e-04\n",
      "Epoch 20/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1698 - val_loss: 0.1743 - learning_rate: 2.5000e-04\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 681us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "Iteration 4 complete\n",
      "Epoch 1/20\n",
      "2000/2000 - 24s - 12ms/step - loss: 1.5747 - val_loss: 0.2586 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "2000/2000 - 18s - 9ms/step - loss: 0.2788 - val_loss: 0.2428 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "2000/2000 - 19s - 10ms/step - loss: 0.2296 - val_loss: 0.1961 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "2000/2000 - 18s - 9ms/step - loss: 0.2108 - val_loss: 0.2141 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "2000/2000 - 16s - 8ms/step - loss: 0.1951 - val_loss: 0.2228 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1896 - val_loss: 0.2181 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1810 - val_loss: 0.1875 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1804 - val_loss: 0.1903 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1806 - val_loss: 0.2042 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1751 - val_loss: 0.1890 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1740 - val_loss: 0.1849 - learning_rate: 6.2500e-05\n",
      "Epoch 12/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1760 - val_loss: 0.1819 - learning_rate: 6.2500e-05\n",
      "Epoch 13/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1733 - val_loss: 0.1833 - learning_rate: 6.2500e-05\n",
      "Epoch 14/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1755 - val_loss: 0.2215 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "2000/2000 - 15s - 8ms/step - loss: 0.1701 - val_loss: 0.1934 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "2000/2000 - 13s - 7ms/step - loss: 0.1725 - val_loss: 0.1693 - learning_rate: 1.5625e-05\n",
      "Epoch 17/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1719 - val_loss: 0.1937 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "2000/2000 - 14s - 7ms/step - loss: 0.1755 - val_loss: 0.1685 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1686 - val_loss: 0.1712 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "2000/2000 - 15s - 7ms/step - loss: 0.1725 - val_loss: 0.1573 - learning_rate: 1.5625e-05\n",
      "\u001b[1m25925/25925\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 747us/step\n",
      "\u001b[1m5607/5607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 881us/step\n",
      "Iteration 5 complete\n"
     ]
    }
   ],
   "source": [
    "# run combined model\n",
    "for i in range(1,6):\n",
    "\n",
    "    model_combined, loss_info_combined = training_functions.run_deep_model(combined_train_prepped, combined_test_prepped, \n",
    "                                                                           combined_geo_dim, epochs=20, steps_per_epoch=2000,\n",
    "                                                                           lograte=True)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((combined_training[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(combined_training[:,3], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(combined_training[:,0], dtype=tf.float32),  # Geography\n",
    "                            tf.convert_to_tensor(combined_training[:,1], dtype=tf.float32))  # Gender\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((combined_test[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(combined_test[:,3], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(combined_test[:,0], dtype=tf.float32),  # Geography\n",
    "                        tf.convert_to_tensor(combined_test[:,1], dtype=tf.float32))  # Gender\n",
    "\n",
    "    training_predictions = model_combined.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_combined.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(combined_training, 4, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(combined_test, 4, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_combined.save(f\"../models/combined_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/combined_training_predictions{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/combined_test_predictions{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepmort-gpu)",
   "language": "python",
   "name": "deepmort-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
