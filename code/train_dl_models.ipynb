{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Mortality Prediction (DLMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%run data_preparation/split_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "tfkl = tf.keras.layers\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_functions' from '/Users/paigepark/Desktop/deep-mort/code/training_functions.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import training_functions\n",
    "import importlib\n",
    "\n",
    "importlib.reload(training_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_training = np.loadtxt('../data/state_training.txt')\n",
    "state_test = np.loadtxt('../data/state_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_training = np.loadtxt('../data/country_training_new.txt')\n",
    "country_test = np.loadtxt('../data/country_test_new.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training = np.loadtxt('../data/combined_training_new.txt')\n",
    "combined_test = np.loadtxt('../data/combined_test_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos_key = np.load('../data/geos_key_new.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_dict = {int(code): geo for geo, code in geos_key}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single population models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I am training indiviudal models for each population. I am only saving mses rather than predictions since the prediction data would be too large to store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pop = np.unique(country_training[:, 0])\n",
    "geo_dim = int(max(n_pop) + 1)\n",
    "geo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA: False\n",
      "GPU devices: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Optional: Set memory growth to prevent over-allocation\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700\n",
      "Running model AUS: Gender 0\n",
      "Epoch 1/50\n",
      "57/57 - 2s - 42ms/step - loss: 26.2680 - val_loss: 29.9856 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "57/57 - 0s - 7ms/step - loss: 13.9360 - val_loss: 13.0326 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "57/57 - 0s - 6ms/step - loss: 3.5309 - val_loss: 4.5640 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.7471 - val_loss: 2.5907 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.5945 - val_loss: 1.6731 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.5396 - val_loss: 1.4395 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.5213 - val_loss: 0.8574 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.5040 - val_loss: 0.8352 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "57/57 - 0s - 9ms/step - loss: 0.4513 - val_loss: 0.3908 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.4449 - val_loss: 0.3283 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.4222 - val_loss: 0.2604 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.4108 - val_loss: 0.0834 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.4095 - val_loss: 0.0565 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3798 - val_loss: 0.1186 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3810 - val_loss: 0.0839 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3644 - val_loss: 0.2230 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3309 - val_loss: 0.0758 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "57/57 - 0s - 5ms/step - loss: 0.3240 - val_loss: 0.0780 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3327 - val_loss: 0.0572 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "57/57 - 0s - 5ms/step - loss: 0.3190 - val_loss: 0.0451 - learning_rate: 6.2500e-05\n",
      "Epoch 21/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3279 - val_loss: 0.0466 - learning_rate: 6.2500e-05\n",
      "Epoch 22/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3190 - val_loss: 0.0547 - learning_rate: 6.2500e-05\n",
      "Epoch 23/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3214 - val_loss: 0.0503 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3285 - val_loss: 0.0491 - learning_rate: 1.5625e-05\n",
      "Epoch 25/50\n",
      "57/57 - 0s - 9ms/step - loss: 0.3201 - val_loss: 0.0491 - learning_rate: 1.5625e-05\n",
      "Epoch 26/50\n",
      "57/57 - 1s - 16ms/step - loss: 0.3188 - val_loss: 0.0486 - learning_rate: 1.5625e-05\n",
      "Epoch 27/50\n",
      "57/57 - 1s - 15ms/step - loss: 0.3170 - val_loss: 0.0429 - learning_rate: 3.9063e-06\n",
      "Epoch 28/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.3134 - val_loss: 0.0486 - learning_rate: 3.9063e-06\n",
      "Epoch 29/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3204 - val_loss: 0.0463 - learning_rate: 3.9063e-06\n",
      "Epoch 30/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3123 - val_loss: 0.0464 - learning_rate: 3.9063e-06\n",
      "Epoch 31/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3291 - val_loss: 0.0484 - learning_rate: 9.7656e-07\n",
      "Epoch 32/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3211 - val_loss: 0.0547 - learning_rate: 9.7656e-07\n",
      "Epoch 33/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3331 - val_loss: 0.0451 - learning_rate: 9.7656e-07\n",
      "Epoch 34/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3180 - val_loss: 0.0446 - learning_rate: 2.4414e-07\n",
      "Epoch 35/50\n",
      "57/57 - 0s - 5ms/step - loss: 0.3133 - val_loss: 0.0519 - learning_rate: 2.4414e-07\n",
      "Epoch 36/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3069 - val_loss: 0.0451 - learning_rate: 2.4414e-07\n",
      "Epoch 37/50\n",
      "57/57 - 0s - 5ms/step - loss: 0.3271 - val_loss: 0.0462 - learning_rate: 6.1035e-08\n",
      "Epoch 38/50\n",
      "57/57 - 0s - 5ms/step - loss: 0.3229 - val_loss: 0.0464 - learning_rate: 6.1035e-08\n",
      "Epoch 39/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3183 - val_loss: 0.0470 - learning_rate: 6.1035e-08\n",
      "Epoch 40/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3139 - val_loss: 0.0461 - learning_rate: 1.5259e-08\n",
      "Epoch 41/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3180 - val_loss: 0.0505 - learning_rate: 1.5259e-08\n",
      "Epoch 42/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3373 - val_loss: 0.0445 - learning_rate: 1.5259e-08\n",
      "Epoch 43/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3156 - val_loss: 0.0477 - learning_rate: 3.8147e-09\n",
      "Epoch 44/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3217 - val_loss: 0.0535 - learning_rate: 3.8147e-09\n",
      "Epoch 45/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3103 - val_loss: 0.0497 - learning_rate: 3.8147e-09\n",
      "Epoch 46/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3253 - val_loss: 0.0507 - learning_rate: 9.5367e-10\n",
      "Epoch 47/50\n",
      "57/57 - 0s - 5ms/step - loss: 0.3337 - val_loss: 0.0481 - learning_rate: 9.5367e-10\n",
      "Epoch 48/50\n",
      "57/57 - 0s - 5ms/step - loss: 0.3152 - val_loss: 0.0476 - learning_rate: 9.5367e-10\n",
      "Epoch 49/50\n",
      "57/57 - 0s - 5ms/step - loss: 0.3087 - val_loss: 0.0449 - learning_rate: 2.3842e-10\n",
      "Epoch 50/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3178 - val_loss: 0.0472 - learning_rate: 2.3842e-10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "4700\n",
      "Running model AUT: Gender 0\n",
      "Epoch 1/50\n",
      "57/57 - 2s - 37ms/step - loss: 26.6320 - val_loss: 33.4373 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "57/57 - 0s - 8ms/step - loss: 13.4416 - val_loss: 16.9465 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "57/57 - 0s - 6ms/step - loss: 3.2213 - val_loss: 6.9091 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.7194 - val_loss: 3.5491 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.6027 - val_loss: 2.1534 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "57/57 - 1s - 13ms/step - loss: 0.5567 - val_loss: 1.5550 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.5072 - val_loss: 0.8661 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.4990 - val_loss: 0.3242 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.4740 - val_loss: 0.2831 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.4359 - val_loss: 0.2875 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.4321 - val_loss: 0.3644 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.4224 - val_loss: 0.1216 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.3914 - val_loss: 0.2149 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3880 - val_loss: 0.1316 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3662 - val_loss: 0.1585 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3426 - val_loss: 0.1143 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3537 - val_loss: 0.1100 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3502 - val_loss: 0.1268 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3360 - val_loss: 0.1064 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3424 - val_loss: 0.0953 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3273 - val_loss: 0.0925 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3369 - val_loss: 0.0979 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3368 - val_loss: 0.0952 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "57/57 - 1s - 13ms/step - loss: 0.3287 - val_loss: 0.1294 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3199 - val_loss: 0.0986 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.3119 - val_loss: 0.0937 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.3135 - val_loss: 0.0919 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3161 - val_loss: 0.0895 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3191 - val_loss: 0.0941 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "57/57 - 1s - 18ms/step - loss: 0.3089 - val_loss: 0.0891 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "57/57 - 1s - 13ms/step - loss: 0.3093 - val_loss: 0.0948 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3143 - val_loss: 0.0897 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.3151 - val_loss: 0.0854 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3089 - val_loss: 0.0934 - learning_rate: 6.2500e-05\n",
      "Epoch 35/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3164 - val_loss: 0.1000 - learning_rate: 6.2500e-05\n",
      "Epoch 36/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3182 - val_loss: 0.0888 - learning_rate: 6.2500e-05\n",
      "Epoch 37/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3104 - val_loss: 0.0839 - learning_rate: 1.5625e-05\n",
      "Epoch 38/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3120 - val_loss: 0.0938 - learning_rate: 1.5625e-05\n",
      "Epoch 39/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3193 - val_loss: 0.0800 - learning_rate: 1.5625e-05\n",
      "Epoch 40/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.3108 - val_loss: 0.0952 - learning_rate: 1.5625e-05\n",
      "Epoch 41/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3133 - val_loss: 0.0930 - learning_rate: 1.5625e-05\n",
      "Epoch 42/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.3104 - val_loss: 0.0892 - learning_rate: 1.5625e-05\n",
      "Epoch 43/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3089 - val_loss: 0.0828 - learning_rate: 3.9063e-06\n",
      "Epoch 44/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3044 - val_loss: 0.0907 - learning_rate: 3.9063e-06\n",
      "Epoch 45/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3127 - val_loss: 0.0869 - learning_rate: 3.9063e-06\n",
      "Epoch 46/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3035 - val_loss: 0.0896 - learning_rate: 9.7656e-07\n",
      "Epoch 47/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.3083 - val_loss: 0.0900 - learning_rate: 9.7656e-07\n",
      "Epoch 48/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.3100 - val_loss: 0.0841 - learning_rate: 9.7656e-07\n",
      "Epoch 49/50\n",
      "57/57 - 0s - 9ms/step - loss: 0.3150 - val_loss: 0.0936 - learning_rate: 2.4414e-07\n",
      "Epoch 50/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3074 - val_loss: 0.0822 - learning_rate: 2.4414e-07\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "4700\n",
      "Running model AUS: Gender 1\n",
      "Epoch 1/50\n",
      "57/57 - 2s - 36ms/step - loss: 21.8071 - val_loss: 25.4172 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "57/57 - 1s - 9ms/step - loss: 10.2247 - val_loss: 10.3741 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "57/57 - 0s - 7ms/step - loss: 2.1922 - val_loss: 4.4395 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.6320 - val_loss: 2.4841 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.5488 - val_loss: 1.7180 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.5047 - val_loss: 0.9700 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.4635 - val_loss: 0.5249 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.4650 - val_loss: 1.0955 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.4330 - val_loss: 0.2542 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.4200 - val_loss: 0.2023 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3875 - val_loss: 0.1296 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3684 - val_loss: 0.2248 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3524 - val_loss: 0.1074 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.3333 - val_loss: 0.1893 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3227 - val_loss: 0.1656 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.3164 - val_loss: 0.1161 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3048 - val_loss: 0.0702 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2831 - val_loss: 0.0788 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2903 - val_loss: 0.0595 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2794 - val_loss: 0.0595 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2795 - val_loss: 0.0586 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2773 - val_loss: 0.0873 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2822 - val_loss: 0.0842 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2815 - val_loss: 0.0547 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2657 - val_loss: 0.0737 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2680 - val_loss: 0.0461 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2689 - val_loss: 0.0710 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2559 - val_loss: 0.0699 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.2490 - val_loss: 0.0575 - learning_rate: 2.5000e-04\n",
      "Epoch 30/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2521 - val_loss: 0.0400 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2575 - val_loss: 0.0468 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2605 - val_loss: 0.0498 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2591 - val_loss: 0.0490 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2418 - val_loss: 0.0477 - learning_rate: 1.5625e-05\n",
      "Epoch 35/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2531 - val_loss: 0.0473 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2550 - val_loss: 0.0429 - learning_rate: 1.5625e-05\n",
      "Epoch 37/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2522 - val_loss: 0.0455 - learning_rate: 3.9063e-06\n",
      "Epoch 38/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2530 - val_loss: 0.0440 - learning_rate: 3.9063e-06\n",
      "Epoch 39/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2463 - val_loss: 0.0390 - learning_rate: 3.9063e-06\n",
      "Epoch 40/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2520 - val_loss: 0.0430 - learning_rate: 3.9063e-06\n",
      "Epoch 41/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2518 - val_loss: 0.0405 - learning_rate: 3.9063e-06\n",
      "Epoch 42/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2491 - val_loss: 0.0434 - learning_rate: 3.9063e-06\n",
      "Epoch 43/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2511 - val_loss: 0.0458 - learning_rate: 9.7656e-07\n",
      "Epoch 44/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2456 - val_loss: 0.0408 - learning_rate: 9.7656e-07\n",
      "Epoch 45/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2472 - val_loss: 0.0399 - learning_rate: 9.7656e-07\n",
      "Epoch 46/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2501 - val_loss: 0.0396 - learning_rate: 2.4414e-07\n",
      "Epoch 47/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2584 - val_loss: 0.0375 - learning_rate: 2.4414e-07\n",
      "Epoch 48/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2547 - val_loss: 0.0363 - learning_rate: 2.4414e-07\n",
      "Epoch 49/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2468 - val_loss: 0.0404 - learning_rate: 2.4414e-07\n",
      "Epoch 50/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2478 - val_loss: 0.0413 - learning_rate: 2.4414e-07\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "4700\n",
      "Running model AUT: Gender 1\n",
      "Epoch 1/50\n",
      "57/57 - 2s - 34ms/step - loss: 20.9402 - val_loss: 27.2175 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "57/57 - 0s - 7ms/step - loss: 9.9086 - val_loss: 14.8733 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "57/57 - 0s - 7ms/step - loss: 2.0594 - val_loss: 5.1278 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.6164 - val_loss: 3.1757 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "57/57 - 0s - 6ms/step - loss: 0.5236 - val_loss: 2.2678 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.4750 - val_loss: 2.6556 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.4614 - val_loss: 1.2905 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.4442 - val_loss: 0.7222 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.4071 - val_loss: 0.4239 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.4006 - val_loss: 0.2032 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3783 - val_loss: 0.5840 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.3595 - val_loss: 0.1000 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3481 - val_loss: 0.2266 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.3261 - val_loss: 0.2111 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.3242 - val_loss: 0.1294 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3051 - val_loss: 0.1168 - learning_rate: 2.5000e-04\n",
      "Epoch 17/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.2953 - val_loss: 0.0782 - learning_rate: 2.5000e-04\n",
      "Epoch 18/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.2966 - val_loss: 0.1004 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.2840 - val_loss: 0.0736 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.2891 - val_loss: 0.0788 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.2834 - val_loss: 0.0805 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2813 - val_loss: 0.0936 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2781 - val_loss: 0.0914 - learning_rate: 6.2500e-05\n",
      "Epoch 24/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2869 - val_loss: 0.0711 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2943 - val_loss: 0.0642 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2698 - val_loss: 0.0805 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2817 - val_loss: 0.0618 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.2681 - val_loss: 0.0634 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2779 - val_loss: 0.0757 - learning_rate: 6.2500e-05\n",
      "Epoch 30/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2737 - val_loss: 0.0601 - learning_rate: 6.2500e-05\n",
      "Epoch 31/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2668 - val_loss: 0.0637 - learning_rate: 6.2500e-05\n",
      "Epoch 32/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2574 - val_loss: 0.0728 - learning_rate: 6.2500e-05\n",
      "Epoch 33/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2642 - val_loss: 0.0639 - learning_rate: 6.2500e-05\n",
      "Epoch 34/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2651 - val_loss: 0.0732 - learning_rate: 1.5625e-05\n",
      "Epoch 35/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2730 - val_loss: 0.0698 - learning_rate: 1.5625e-05\n",
      "Epoch 36/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2577 - val_loss: 0.0660 - learning_rate: 1.5625e-05\n",
      "Epoch 37/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2622 - val_loss: 0.0652 - learning_rate: 3.9063e-06\n",
      "Epoch 38/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.2615 - val_loss: 0.0649 - learning_rate: 3.9063e-06\n",
      "Epoch 39/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2666 - val_loss: 0.0722 - learning_rate: 3.9063e-06\n",
      "Epoch 40/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2725 - val_loss: 0.0626 - learning_rate: 9.7656e-07\n",
      "Epoch 41/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2676 - val_loss: 0.0710 - learning_rate: 9.7656e-07\n",
      "Epoch 42/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2761 - val_loss: 0.0708 - learning_rate: 9.7656e-07\n",
      "Epoch 43/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.2666 - val_loss: 0.0696 - learning_rate: 2.4414e-07\n",
      "Epoch 44/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.2778 - val_loss: 0.0770 - learning_rate: 2.4414e-07\n",
      "Epoch 45/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2654 - val_loss: 0.0744 - learning_rate: 2.4414e-07\n",
      "Epoch 46/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.2628 - val_loss: 0.0653 - learning_rate: 6.1035e-08\n",
      "Epoch 47/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.2715 - val_loss: 0.0694 - learning_rate: 6.1035e-08\n",
      "Epoch 48/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.2693 - val_loss: 0.0756 - learning_rate: 6.1035e-08\n",
      "Epoch 49/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.2738 - val_loss: 0.0732 - learning_rate: 1.5259e-08\n",
      "Epoch 50/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.2623 - val_loss: 0.0711 - learning_rate: 1.5259e-08\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "4700\n",
      "Running model AUS: Gender 0\n",
      "Epoch 1/50\n",
      "57/57 - 2s - 37ms/step - loss: 25.9843 - val_loss: 31.0413 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "57/57 - 1s - 10ms/step - loss: 13.5765 - val_loss: 14.9936 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "57/57 - 1s - 11ms/step - loss: 3.3894 - val_loss: 4.6901 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.7553 - val_loss: 2.6578 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.6090 - val_loss: 1.9046 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.5732 - val_loss: 1.2680 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.5394 - val_loss: 0.8925 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.5102 - val_loss: 0.8675 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "57/57 - 1s - 15ms/step - loss: 0.4913 - val_loss: 0.4311 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "57/57 - 1s - 12ms/step - loss: 0.4530 - val_loss: 0.5662 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "57/57 - 1s - 13ms/step - loss: 0.4527 - val_loss: 0.3322 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "57/57 - 1s - 12ms/step - loss: 0.4353 - val_loss: 0.0728 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.4077 - val_loss: 0.1039 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.4105 - val_loss: 0.0596 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.4051 - val_loss: 0.1351 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3695 - val_loss: 0.1189 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "57/57 - 0s - 9ms/step - loss: 0.3608 - val_loss: 0.0906 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "57/57 - 1s - 12ms/step - loss: 0.3278 - val_loss: 0.0520 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3417 - val_loss: 0.0545 - learning_rate: 2.5000e-04\n",
      "Epoch 20/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3456 - val_loss: 0.0477 - learning_rate: 2.5000e-04\n",
      "Epoch 21/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3188 - val_loss: 0.0539 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "57/57 - 0s - 9ms/step - loss: 0.3252 - val_loss: 0.0501 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3222 - val_loss: 0.0542 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3268 - val_loss: 0.0601 - learning_rate: 6.2500e-05\n",
      "Epoch 25/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.3150 - val_loss: 0.0558 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3163 - val_loss: 0.0522 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3211 - val_loss: 0.0528 - learning_rate: 1.5625e-05\n",
      "Epoch 28/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3124 - val_loss: 0.0523 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3117 - val_loss: 0.0581 - learning_rate: 1.5625e-05\n",
      "Epoch 30/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3209 - val_loss: 0.0474 - learning_rate: 3.9063e-06\n",
      "Epoch 31/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3068 - val_loss: 0.0505 - learning_rate: 3.9063e-06\n",
      "Epoch 32/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3152 - val_loss: 0.0469 - learning_rate: 3.9063e-06\n",
      "Epoch 33/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3148 - val_loss: 0.0465 - learning_rate: 3.9063e-06\n",
      "Epoch 34/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3179 - val_loss: 0.0493 - learning_rate: 3.9063e-06\n",
      "Epoch 35/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3143 - val_loss: 0.0484 - learning_rate: 3.9063e-06\n",
      "Epoch 36/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3156 - val_loss: 0.0514 - learning_rate: 3.9063e-06\n",
      "Epoch 37/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3075 - val_loss: 0.0472 - learning_rate: 9.7656e-07\n",
      "Epoch 38/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3197 - val_loss: 0.0486 - learning_rate: 9.7656e-07\n",
      "Epoch 39/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3124 - val_loss: 0.0429 - learning_rate: 9.7656e-07\n",
      "Epoch 40/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3145 - val_loss: 0.0466 - learning_rate: 9.7656e-07\n",
      "Epoch 41/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3295 - val_loss: 0.0504 - learning_rate: 9.7656e-07\n",
      "Epoch 42/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3109 - val_loss: 0.0448 - learning_rate: 9.7656e-07\n",
      "Epoch 43/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3110 - val_loss: 0.0433 - learning_rate: 2.4414e-07\n",
      "Epoch 44/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3206 - val_loss: 0.0474 - learning_rate: 2.4414e-07\n",
      "Epoch 45/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3278 - val_loss: 0.0512 - learning_rate: 2.4414e-07\n",
      "Epoch 46/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3197 - val_loss: 0.0494 - learning_rate: 6.1035e-08\n",
      "Epoch 47/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.3245 - val_loss: 0.0486 - learning_rate: 6.1035e-08\n",
      "Epoch 48/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3257 - val_loss: 0.0447 - learning_rate: 6.1035e-08\n",
      "Epoch 49/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3174 - val_loss: 0.0505 - learning_rate: 1.5259e-08\n",
      "Epoch 50/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3083 - val_loss: 0.0471 - learning_rate: 1.5259e-08\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "4700\n",
      "Running model AUT: Gender 0\n",
      "Epoch 1/50\n",
      "57/57 - 2s - 39ms/step - loss: 26.3660 - val_loss: 31.9252 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "57/57 - 0s - 8ms/step - loss: 13.7323 - val_loss: 15.8432 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "57/57 - 1s - 9ms/step - loss: 3.6298 - val_loss: 5.7023 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.7580 - val_loss: 3.1643 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.6146 - val_loss: 2.4467 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.5568 - val_loss: 2.5895 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "57/57 - 1s - 16ms/step - loss: 0.5273 - val_loss: 1.4396 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "57/57 - 1s - 16ms/step - loss: 0.4892 - val_loss: 0.8149 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "57/57 - 0s - 9ms/step - loss: 0.4843 - val_loss: 0.4621 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "57/57 - 1s - 14ms/step - loss: 0.4708 - val_loss: 0.2865 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.4516 - val_loss: 0.6062 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.4269 - val_loss: 0.1515 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "57/57 - 1s - 12ms/step - loss: 0.4273 - val_loss: 0.1812 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.4222 - val_loss: 0.1373 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "57/57 - 1s - 13ms/step - loss: 0.3810 - val_loss: 0.1206 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3584 - val_loss: 0.1452 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3544 - val_loss: 0.1095 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.3422 - val_loss: 0.1310 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3481 - val_loss: 0.1214 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "57/57 - 1s - 12ms/step - loss: 0.3287 - val_loss: 0.1199 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3293 - val_loss: 0.0888 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3261 - val_loss: 0.0945 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.3035 - val_loss: 0.0977 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3214 - val_loss: 0.1041 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3065 - val_loss: 0.0913 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.2995 - val_loss: 0.0914 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3040 - val_loss: 0.0919 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3019 - val_loss: 0.0895 - learning_rate: 1.5625e-05\n",
      "Epoch 29/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3093 - val_loss: 0.0842 - learning_rate: 1.5625e-05\n",
      "Epoch 30/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3016 - val_loss: 0.0924 - learning_rate: 1.5625e-05\n",
      "Epoch 31/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2932 - val_loss: 0.0881 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3057 - val_loss: 0.0877 - learning_rate: 1.5625e-05\n",
      "Epoch 33/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3009 - val_loss: 0.0843 - learning_rate: 3.9063e-06\n",
      "Epoch 34/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.2963 - val_loss: 0.0926 - learning_rate: 3.9063e-06\n",
      "Epoch 35/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3071 - val_loss: 0.0870 - learning_rate: 3.9063e-06\n",
      "Epoch 36/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2888 - val_loss: 0.0859 - learning_rate: 9.7656e-07\n",
      "Epoch 37/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3090 - val_loss: 0.0876 - learning_rate: 9.7656e-07\n",
      "Epoch 38/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3004 - val_loss: 0.0902 - learning_rate: 9.7656e-07\n",
      "Epoch 39/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3083 - val_loss: 0.0902 - learning_rate: 2.4414e-07\n",
      "Epoch 40/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2971 - val_loss: 0.0808 - learning_rate: 2.4414e-07\n",
      "Epoch 41/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2966 - val_loss: 0.0892 - learning_rate: 2.4414e-07\n",
      "Epoch 42/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.3082 - val_loss: 0.0923 - learning_rate: 2.4414e-07\n",
      "Epoch 43/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3103 - val_loss: 0.0876 - learning_rate: 2.4414e-07\n",
      "Epoch 44/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3023 - val_loss: 0.0840 - learning_rate: 6.1035e-08\n",
      "Epoch 45/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.3010 - val_loss: 0.0858 - learning_rate: 6.1035e-08\n",
      "Epoch 46/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2959 - val_loss: 0.0853 - learning_rate: 6.1035e-08\n",
      "Epoch 47/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3116 - val_loss: 0.0984 - learning_rate: 1.5259e-08\n",
      "Epoch 48/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3011 - val_loss: 0.0866 - learning_rate: 1.5259e-08\n",
      "Epoch 49/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.2983 - val_loss: 0.0931 - learning_rate: 1.5259e-08\n",
      "Epoch 50/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.3033 - val_loss: 0.0928 - learning_rate: 3.8147e-09\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "4700\n",
      "Running model AUS: Gender 1\n",
      "Epoch 1/50\n",
      "57/57 - 2s - 38ms/step - loss: 22.0865 - val_loss: 29.2074 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "57/57 - 0s - 8ms/step - loss: 9.7867 - val_loss: 16.0228 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "57/57 - 0s - 9ms/step - loss: 2.1431 - val_loss: 6.3175 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.6369 - val_loss: 3.9836 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.5432 - val_loss: 3.1246 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.4840 - val_loss: 2.2100 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.4772 - val_loss: 1.7408 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "57/57 - 0s - 7ms/step - loss: 0.4443 - val_loss: 1.1566 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.4272 - val_loss: 0.7546 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.4008 - val_loss: 0.3256 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "57/57 - 1s - 14ms/step - loss: 0.3759 - val_loss: 0.4151 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "57/57 - 1s - 20ms/step - loss: 0.3586 - val_loss: 0.2363 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "57/57 - 1s - 19ms/step - loss: 0.3415 - val_loss: 0.1681 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "57/57 - 1s - 15ms/step - loss: 0.3338 - val_loss: 0.1820 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3203 - val_loss: 0.1615 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3117 - val_loss: 0.1732 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.3032 - val_loss: 0.1383 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.2909 - val_loss: 0.0794 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "57/57 - 1s - 12ms/step - loss: 0.2852 - val_loss: 0.1488 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.2752 - val_loss: 0.1273 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.2666 - val_loss: 0.2114 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.2465 - val_loss: 0.1620 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.2428 - val_loss: 0.1089 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.2401 - val_loss: 0.0928 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "57/57 - 1s - 9ms/step - loss: 0.2329 - val_loss: 0.0673 - learning_rate: 6.2500e-05\n",
      "Epoch 26/50\n",
      "57/57 - 1s - 14ms/step - loss: 0.2340 - val_loss: 0.0769 - learning_rate: 6.2500e-05\n",
      "Epoch 27/50\n",
      "57/57 - 0s - 9ms/step - loss: 0.2296 - val_loss: 0.0683 - learning_rate: 6.2500e-05\n",
      "Epoch 28/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.2332 - val_loss: 0.0727 - learning_rate: 6.2500e-05\n",
      "Epoch 29/50\n",
      "57/57 - 0s - 9ms/step - loss: 0.2365 - val_loss: 0.0732 - learning_rate: 1.5625e-05\n",
      "Epoch 30/50\n",
      "57/57 - 1s - 16ms/step - loss: 0.2353 - val_loss: 0.0721 - learning_rate: 1.5625e-05\n",
      "Epoch 31/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.2345 - val_loss: 0.0699 - learning_rate: 1.5625e-05\n",
      "Epoch 32/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.2351 - val_loss: 0.0699 - learning_rate: 3.9063e-06\n",
      "Epoch 33/50\n",
      "57/57 - 1s - 10ms/step - loss: 0.2358 - val_loss: 0.0704 - learning_rate: 3.9063e-06\n",
      "Epoch 34/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.2380 - val_loss: 0.0668 - learning_rate: 3.9063e-06\n",
      "Epoch 35/50\n",
      "57/57 - 1s - 12ms/step - loss: 0.2376 - val_loss: 0.0757 - learning_rate: 3.9063e-06\n",
      "Epoch 36/50\n",
      "57/57 - 1s - 11ms/step - loss: 0.2273 - val_loss: 0.0713 - learning_rate: 3.9063e-06\n",
      "Epoch 37/50\n",
      "57/57 - 0s - 8ms/step - loss: 0.2374 - val_loss: 0.0710 - learning_rate: 3.9063e-06\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m steps_per_epoch \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(N \u001b[38;5;241m/\u001b[39m batch_size) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;66;03m# Adjust multiplier as needed\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeo_dict[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Gender \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m model_single, loss_single \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_deep_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_country_training_prepped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43msingle_country_test_prepped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43msingle_geo_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlograte\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m tc \u001b[38;5;241m=\u001b[39m single_country_test  \n\u001b[1;32m     25\u001b[0m years \u001b[38;5;241m=\u001b[39m (tc[:,\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1959\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/deep-mort/code/training_functions.py:185\u001b[0m, in \u001b[0;36mrun_deep_model\u001b[0;34m(dataset_train, dataset_test, geo_dim, epochs, steps_per_epoch, lograte)\u001b[0m\n\u001b[1;32m    181\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_model(geo_dim)\n\u001b[1;32m    183\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    184\u001b[0m                                                 min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m, cooldown\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)]\n\u001b[0;32m--> 185\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    190\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for s in range(1,6):\n",
    "    for j in range(0,2):\n",
    "        for i in range(50, 52):\n",
    "            country_index = i\n",
    "            gender_index = j\n",
    "            single_country_training = country_training[(country_training[:,0] == country_index) & (country_training[:,1] == gender_index)]\n",
    "            single_country_test = country_test[(country_test[:,0] == country_index) & (country_test[:,1] == gender_index)]\n",
    "\n",
    "            single_country_training_prepped = training_functions.prep_data(single_country_training, mode=\"train\", changeratetolog=True)\n",
    "            single_country_test_prepped = training_functions.prep_data(single_country_test, mode=\"test\", changeratetolog=True)\n",
    "            single_geo_dim = country_index + 1\n",
    "\n",
    "            # set steps_per_epoch based on the number of training samples\n",
    "            N = len(single_country_training)\n",
    "            batch_size = 256\n",
    "            steps_per_epoch = math.ceil(N / batch_size) * 3 \n",
    "\n",
    "            print(f\"Running model {geo_dict[i]}: Gender {j}\")\n",
    "\n",
    "            model_single, loss_single = training_functions.run_deep_model(single_country_training_prepped, \n",
    "                                                                          single_country_test_prepped, \n",
    "                                                                          single_geo_dim, epochs=50, \n",
    "                                                                          steps_per_epoch=steps_per_epoch, lograte=True)\n",
    "        \n",
    "            tc = single_country_test  \n",
    "            years = (tc[:,2] - 1959) / 60\n",
    "            ages  = tc[:,3]\n",
    "            geos  = tc[:,0].astype(np.int32)\n",
    "            genders = tc[:,1]\n",
    "\n",
    "            test_input_features = (\n",
    "                tf.convert_to_tensor(years, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(ages, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(geos, dtype=tf.int32),      # ensure ints\n",
    "                tf.convert_to_tensor(genders, dtype=tf.float32),\n",
    "            )\n",
    "            \n",
    "            test_predictions = model_single.predict(test_input_features)\n",
    "\n",
    "\n",
    "            inputs_test = np.delete(single_country_test, 4, axis=1)\n",
    "            test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "            geo_name = geo_dict[i]\n",
    "\n",
    "            # model_single.save(f\"../models/{geo_name}_gender_{j}.keras\")   \n",
    "\n",
    "            # np.savez_compressed(f\"../data/{geo_name}_gender_{j}_iter_{s}.npz\", test_predictions) \n",
    "\n",
    "print(f\"Finished training for {s} iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Country Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "country_train_prepped = training_functions.prep_data(country_training, mode=\"train\", changeratetolog=True)\n",
    "country_test_prepped = training_functions.prep_data(country_test, mode=\"test\", changeratetolog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(country_training[:, 0]).y\n",
    "country_geo_dim = np.array(tf.size(unique_vals)).item()\n",
    "country_geo_dim = country_geo_dim + 50\n",
    "country_geo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1405"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.ceil(len(country_training)/ 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 2.0501 - val_loss: 0.2499 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.3321 - val_loss: 0.2121 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2541 - val_loss: 0.1817 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.2135 - val_loss: 0.1808 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.2010 - val_loss: 0.1987 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.1932 - val_loss: 0.2210 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1786 - val_loss: 0.2357 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1682 - val_loss: 0.1942 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "1405/1405 - 9s - 7ms/step - loss: 0.1720 - val_loss: 0.1717 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1637 - val_loss: 0.1915 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1714 - val_loss: 0.1779 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1616 - val_loss: 0.1524 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1630 - val_loss: 0.1738 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1612 - val_loss: 0.1878 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1634 - val_loss: 0.1826 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1573 - val_loss: 0.1470 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1567 - val_loss: 0.1942 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1620 - val_loss: 0.1606 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 14s - 10ms/step - loss: 0.1569 - val_loss: 0.1953 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1545 - val_loss: 0.1677 - learning_rate: 1.5625e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 768us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step\n",
      "Iteration 1 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 14s - 10ms/step - loss: 1.9925 - val_loss: 0.2836 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.3387 - val_loss: 0.2105 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 11s - 7ms/step - loss: 0.2551 - val_loss: 0.1938 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.2211 - val_loss: 0.2003 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1960 - val_loss: 0.2040 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 16s - 11ms/step - loss: 0.1920 - val_loss: 0.2109 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.1713 - val_loss: 0.1771 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1757 - val_loss: 0.1850 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1689 - val_loss: 0.1958 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1637 - val_loss: 0.1498 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1646 - val_loss: 0.1859 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1639 - val_loss: 0.1631 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1687 - val_loss: 0.1686 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1574 - val_loss: 0.1715 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1592 - val_loss: 0.1778 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1596 - val_loss: 0.1657 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1585 - val_loss: 0.1686 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1610 - val_loss: 0.1658 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1573 - val_loss: 0.1692 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1577 - val_loss: 0.1676 - learning_rate: 3.9063e-06\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 756us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 602us/step\n",
      "Iteration 2 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 16s - 11ms/step - loss: 1.9587 - val_loss: 0.2350 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 13s - 10ms/step - loss: 0.3369 - val_loss: 0.2365 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.2515 - val_loss: 0.1991 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.2207 - val_loss: 0.2170 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 11s - 7ms/step - loss: 0.1984 - val_loss: 0.1997 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1900 - val_loss: 0.1811 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 14s - 10ms/step - loss: 0.1847 - val_loss: 0.1948 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1793 - val_loss: 0.2137 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.1708 - val_loss: 0.1633 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1691 - val_loss: 0.1659 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1745 - val_loss: 0.1809 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1716 - val_loss: 0.1783 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1600 - val_loss: 0.1800 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1571 - val_loss: 0.1754 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1550 - val_loss: 0.1704 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1579 - val_loss: 0.1491 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1523 - val_loss: 0.1688 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1550 - val_loss: 0.1592 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1549 - val_loss: 0.1641 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1556 - val_loss: 0.1745 - learning_rate: 1.5625e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 758us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step\n",
      "Iteration 3 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 17s - 12ms/step - loss: 2.0076 - val_loss: 0.3259 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.3307 - val_loss: 0.1950 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.2483 - val_loss: 0.2012 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2209 - val_loss: 0.2018 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2011 - val_loss: 0.2227 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1774 - val_loss: 0.1964 - learning_rate: 2.5000e-04\n",
      "Epoch 7/20\n",
      "1405/1405 - 13s - 9ms/step - loss: 0.1766 - val_loss: 0.1791 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1755 - val_loss: 0.1647 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1665 - val_loss: 0.1916 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1688 - val_loss: 0.1461 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1704 - val_loss: 0.1749 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1710 - val_loss: 0.1902 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1679 - val_loss: 0.1696 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1656 - val_loss: 0.1688 - learning_rate: 6.2500e-05\n",
      "Epoch 15/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.1590 - val_loss: 0.1837 - learning_rate: 6.2500e-05\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1602 - val_loss: 0.1666 - learning_rate: 6.2500e-05\n",
      "Epoch 17/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1585 - val_loss: 0.1470 - learning_rate: 1.5625e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 12s - 8ms/step - loss: 0.1600 - val_loss: 0.1559 - learning_rate: 1.5625e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1630 - val_loss: 0.1590 - learning_rate: 1.5625e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1635 - val_loss: 0.1790 - learning_rate: 3.9063e-06\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 738us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 593us/step\n",
      "Iteration 4 complete\n",
      "Epoch 1/20\n",
      "1405/1405 - 17s - 12ms/step - loss: 2.0672 - val_loss: 0.2633 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.3351 - val_loss: 0.2479 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.2524 - val_loss: 0.2085 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.2216 - val_loss: 0.1839 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "1405/1405 - 12s - 9ms/step - loss: 0.2027 - val_loss: 0.2189 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1888 - val_loss: 0.1722 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1861 - val_loss: 0.1786 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1752 - val_loss: 0.2629 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1766 - val_loss: 0.1940 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1626 - val_loss: 0.1846 - learning_rate: 2.5000e-04\n",
      "Epoch 11/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1586 - val_loss: 0.1642 - learning_rate: 2.5000e-04\n",
      "Epoch 12/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1631 - val_loss: 0.1692 - learning_rate: 2.5000e-04\n",
      "Epoch 13/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1556 - val_loss: 0.1597 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1649 - val_loss: 0.1603 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1544 - val_loss: 0.1756 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1586 - val_loss: 0.1719 - learning_rate: 2.5000e-04\n",
      "Epoch 17/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1522 - val_loss: 0.1749 - learning_rate: 6.2500e-05\n",
      "Epoch 18/20\n",
      "1405/1405 - 11s - 8ms/step - loss: 0.1569 - val_loss: 0.1595 - learning_rate: 6.2500e-05\n",
      "Epoch 19/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1592 - val_loss: 0.1515 - learning_rate: 6.2500e-05\n",
      "Epoch 20/20\n",
      "1405/1405 - 10s - 7ms/step - loss: 0.1542 - val_loss: 0.1746 - learning_rate: 6.2500e-05\n",
      "\u001b[1m11238/11238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 662us/step\n",
      "\u001b[1m2482/2482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518us/step\n",
      "Iteration 5 complete\n"
     ]
    }
   ],
   "source": [
    "# run country model\n",
    "for i in range(1,6):\n",
    "    N = len(country_training)\n",
    "    batch_size = 256\n",
    "    steps_per_epoch = math.ceil(N / batch_size)\n",
    "\n",
    "    model_country, loss_info_country = training_functions.run_deep_model(country_train_prepped, country_test_prepped, country_geo_dim, \n",
    "                                                                         epochs=20, steps_per_epoch=steps_per_epoch, lograte=True)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((country_training[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(country_training[:,3], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(country_training[:,0], dtype=tf.float32),  # Geography\n",
    "                            tf.convert_to_tensor(country_training[:,1], dtype=tf.float32))  # Gender\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((country_test[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(country_test[:,3], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(country_test[:,0], dtype=tf.float32),  # Geography\n",
    "                        tf.convert_to_tensor(country_test[:,1], dtype=tf.float32))  # Gender\n",
    "\n",
    "    training_predictions = model_country.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_country.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(country_training, 4, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(country_test, 4, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_country.save(f\"../models/dl_country_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/dl_country_forecast{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/dl_country_forecast{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined (all country / all state) DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert combined data to tensors and other prep\n",
    "combined_train_prepped = training_functions.prep_data(combined_training, mode=\"train\", changeratetolog=True)\n",
    "combined_test_prepped = training_functions.prep_data(combined_test, mode=\"test\", changeratetolog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(combined_training[:, 0]).y\n",
    "combined_geo_dim = np.array(tf.size(unique_vals)).item()\n",
    "print(combined_geo_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3240.6015625"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_training)/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run combined model\n",
    "for i in range(1,6):\n",
    "    N = len(combined_training)\n",
    "    batch_size = 256\n",
    "    steps_per_epoch = math.ceil(N / batch_size) / 2 # Adjust multiplier as needed\n",
    "\n",
    "    model_combined, loss_info_combined = training_functions.run_deep_model(combined_train_prepped, combined_test_prepped, \n",
    "                                                                           combined_geo_dim, epochs=20, steps_per_epoch=steps_per_epoch,\n",
    "                                                                           lograte=True)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((combined_training[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(combined_training[:,3], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(combined_training[:,0], dtype=tf.float32),  # Geography\n",
    "                            tf.convert_to_tensor(combined_training[:,1], dtype=tf.float32))  # Gender\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((combined_test[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(combined_test[:,3], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(combined_test[:,0], dtype=tf.float32),  # Geography\n",
    "                        tf.convert_to_tensor(combined_test[:,1], dtype=tf.float32))  # Gender\n",
    "\n",
    "    training_predictions = model_combined.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_combined.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(combined_training, 4, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(combined_test, 4, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_combined.save(f\"../models/combined_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/combined_training_predictions{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/combined_test_predictions{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
