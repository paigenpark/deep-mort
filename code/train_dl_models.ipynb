{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for Mortality Prediction (DLMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os as os\n",
    "tfkl = tf.keras.layers\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_functions' from '/Users/paigepark/Library/Mobile Documents/com~apple~CloudDocs/Desktop/deep-mort/code/training_functions.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import training_functions\n",
    "import importlib\n",
    "\n",
    "importlib.reload(training_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_training = np.loadtxt('../data/state_training.txt')\n",
    "state_test = np.loadtxt('../data/state_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_training = np.loadtxt('../data/country_training.txt')\n",
    "country_test = np.loadtxt('../data/country_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training = np.loadtxt('../data/combined_training.txt')\n",
    "combined_test = np.loadtxt('../data/combined_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos_key = np.load('../data/geos_key.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_dict = {int(code): geo for geo, code in geos_key}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single population models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I am training indiviudal models for each population. Here, I only save mses rather than predictions since the prediction data would be too large to store. Running single pop models is very computationally intesive. Most results in the paper come from the model using all countries, which takes a few minutes to run one iteration. \n",
    "\n",
    "The single pop models will each take a few minutes and altogether will take many hours. If interested in reproducing most of the figures, not including the single pop figures, skip this section and go to the \"All Country Model\" section below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "n_pop = np.unique(country_training[:, 0])\n",
    "geo_dim = int(max(n_pop) + 1)\n",
    "geo_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "Built with CUDA: False\n",
      "GPU devices: []\n"
     ]
    }
   ],
   "source": [
    "# this cell used to check remote GPU status - IGNORE -\n",
    "\n",
    "# print(\"TensorFlow version:\", tf.__version__)\n",
    "# print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "# print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# for gpu in tf.config.list_physical_devices('GPU'):\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(1,6):\n",
    "    # Set reproducible seeds per iteration\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)\n",
    "    random.seed(s)\n",
    "    os.environ['PYTHONHASHSEED'] = str(s)\n",
    "    \n",
    "    for j in range(0,2):\n",
    "        for i in range(50, geo_dim):\n",
    "            country_index = i\n",
    "            gender_index = j\n",
    "            single_country_training = country_training[(country_training[:,0] == country_index) & (country_training[:,1] == gender_index)]\n",
    "            single_country_test = country_test[(country_test[:,0] == country_index) & (country_test[:,1] == gender_index)]\n",
    "\n",
    "            single_country_training_prepped = training_functions.prep_data(single_country_training, mode=\"train\", changeratetolog=True)\n",
    "            single_country_test_prepped = training_functions.prep_data(single_country_test, mode=\"test\", changeratetolog=True)\n",
    "            single_geo_dim = country_index + 1\n",
    "\n",
    "            print(f\"Running model {geo_dict[i]}: Gender {j}\")\n",
    "\n",
    "            model_single, loss_single = training_functions.run_deep_model(single_country_training_prepped, \n",
    "                                                                          single_country_test_prepped, \n",
    "                                                                          single_geo_dim, epochs=30, \n",
    "                                                                          steps_per_epoch=500, lograte=True)\n",
    "        \n",
    "            tc = single_country_test  \n",
    "            years = (tc[:,2] - 1959) / 60\n",
    "            ages  = tc[:,3]\n",
    "            geos  = tc[:,0].astype(np.int32)\n",
    "            genders = tc[:,1]\n",
    "\n",
    "            test_input_features = (\n",
    "                tf.convert_to_tensor(years, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(ages, dtype=tf.float32),\n",
    "                tf.convert_to_tensor(geos, dtype=tf.int32),      # ensure ints\n",
    "                tf.convert_to_tensor(genders, dtype=tf.float32),\n",
    "            )\n",
    "            \n",
    "            test_predictions = model_single.predict(test_input_features)\n",
    "\n",
    "\n",
    "            inputs_test = np.delete(single_country_test, 4, axis=1)\n",
    "            test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "            geo_name = geo_dict[i]\n",
    "\n",
    "            model_single.save(f\"../models/{geo_name}_gender_{j}.keras\")   \n",
    "\n",
    "            np.savez_compressed(f\"../data/{geo_name}_gender_{j}_iter_{s}.npz\", test_predictions) \n",
    "\n",
    "print(f\"Finished training for {s} iterations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Country Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models are those used in the paper to produce all of main figures/table in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "country_train_prepped = training_functions.prep_data(country_training, mode=\"train\", changeratetolog=True)\n",
    "country_test_prepped = training_functions.prep_data(country_test, mode=\"test\", changeratetolog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(country_training[:, 0]).y\n",
    "country_geo_dim = np.array(tf.size(unique_vals)).item()\n",
    "country_geo_dim = country_geo_dim + 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all country model\n",
    "for i in range(1,6):\n",
    "    # Set reproducible seeds per iteration\n",
    "    np.random.seed(i)\n",
    "    tf.random.set_seed(i)\n",
    "    random.seed(i)\n",
    "    os.environ['PYTHONHASHSEED'] = str(i)\n",
    "\n",
    "    model_country, loss_info_country = training_functions.run_deep_model(country_train_prepped, country_test_prepped, country_geo_dim, \n",
    "                                                                         epochs=20, \n",
    "                                                                         steps_per_epoch=1405, \n",
    "                                                                         lograte=True)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((country_training[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(country_training[:,3], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(country_training[:,0], dtype=tf.float32),  # Geography\n",
    "                            tf.convert_to_tensor(country_training[:,1], dtype=tf.float32))  # Gender\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((country_test[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(country_test[:,3], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(country_test[:,0], dtype=tf.float32),  # Geography\n",
    "                        tf.convert_to_tensor(country_test[:,1], dtype=tf.float32))  # Gender\n",
    "\n",
    "    training_predictions = model_country.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_country.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(country_training, 4, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(country_test, 4, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_country.save(f\"../models/dl_country_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/dl_country_fitted_{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/dl_country_forecast_{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined (all country / all state) DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert combined data to tensors and other prep\n",
    "combined_train_prepped = training_functions.prep_data(combined_training, mode=\"train\", changeratetolog=True)\n",
    "combined_test_prepped = training_functions.prep_data(combined_test, mode=\"test\", changeratetolog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "# get the proper geography input dimension for model set up \n",
    "unique_vals = tf.unique(combined_training[:, 0]).y\n",
    "combined_geo_dim = np.array(tf.size(unique_vals)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run combined model\n",
    "for i in range(1,6):\n",
    "    # Set reproducible seeds per iteration\n",
    "    np.random.seed(i)\n",
    "    tf.random.set_seed(i)\n",
    "    random.seed(i)\n",
    "    os.environ['PYTHONHASHSEED'] = str(i)\n",
    "\n",
    "    model_combined, loss_info_combined = training_functions.run_deep_model(combined_train_prepped, combined_test_prepped, \n",
    "                                                                           combined_geo_dim, epochs=20, steps_per_epoch=2000,\n",
    "                                                                           lograte=True)\n",
    "\n",
    "    training_input_features = (tf.convert_to_tensor((combined_training[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                            tf.convert_to_tensor(combined_training[:,3], dtype=tf.float32),  # Age\n",
    "                            tf.convert_to_tensor(combined_training[:,0], dtype=tf.float32),  # Geography\n",
    "                            tf.convert_to_tensor(combined_training[:,1], dtype=tf.float32))  # Gender\n",
    "    \n",
    "    test_input_features = (tf.convert_to_tensor((combined_test[:,2] - 1959) / 60, dtype=tf.float32),  # Normalized year\n",
    "                        tf.convert_to_tensor(combined_test[:,3], dtype=tf.float32),  # Age\n",
    "                        tf.convert_to_tensor(combined_test[:,0], dtype=tf.float32),  # Geography\n",
    "                        tf.convert_to_tensor(combined_test[:,1], dtype=tf.float32))  # Gender\n",
    "\n",
    "    training_predictions = model_combined.predict(training_input_features)\n",
    "\n",
    "    test_predictions = model_combined.predict(test_input_features)\n",
    "\n",
    "    inputs = np.delete(combined_training, 4, axis=1)\n",
    "    training_predictions = np.column_stack((inputs, training_predictions))\n",
    "    inputs_test = np.delete(combined_test, 4, axis=1)\n",
    "    test_predictions = np.column_stack((inputs_test, test_predictions))\n",
    "\n",
    "    model_combined.save(f\"../models/combined_model_{i}.keras\")\n",
    "\n",
    "    np.savetxt(f\"../data/dl_combined_fitted_{i}.txt\", training_predictions)\n",
    "    np.savetxt(f\"../data/dl_combined_forecast_{i}.txt\", test_predictions)    \n",
    "\n",
    "    print(f\"Iteration {i} complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep (Python 3.11)",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
