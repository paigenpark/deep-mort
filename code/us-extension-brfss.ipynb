{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "tfkl = tf.keras.layers\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.layers import Input, Embedding, Flatten, Dense, BatchNormalization, Dropout, concatenate\n",
    "#from keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PopName', 'Sex', 'Year', 'Age', 'mx']\n"
     ]
    }
   ],
   "source": [
    "# loading in USMDB data\n",
    "data = []\n",
    "ages = []\n",
    "states = []\n",
    "genders = []\n",
    "\n",
    "with open(\"../data/usmdb/usmdb.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file,delimiter=',')\n",
    "    for row_index, row in enumerate(reader):\n",
    "        if row_index == 0:\n",
    "            print(row)\n",
    "        if row_index >= 1:\n",
    "            state, gender, year, age, rate = row\n",
    "            year = int(year)\n",
    "            try:\n",
    "                age = int(age)\n",
    "            except:\n",
    "                age = -1\n",
    "            if state not in states:\n",
    "                states.append(state)\n",
    "            state = states.index(state)\n",
    "            if gender not in genders:\n",
    "                genders.append(gender)\n",
    "            gender = genders.index(gender)\n",
    "            try:\n",
    "                rate = float(rate)\n",
    "            except:\n",
    "                rate = -1\n",
    "            if rate > 1:\n",
    "                rate = 1\n",
    "            # get rid of years, ages, not in health data and other cleaning\n",
    "            if age != -1 and rate != -1 and age <= 99 and age >=18 and year >= 1993:\n",
    "                data.append([state, gender, year, age, rate])\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ... 49. 49. 49.]\n",
      "[[0.0000e+00 0.0000e+00 1.9930e+03 1.8000e+01 2.7000e-04]\n",
      " [0.0000e+00 0.0000e+00 1.9930e+03 1.9000e+01 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 1.9930e+03 2.0000e+01 1.0700e-03]\n",
      " ...\n",
      " [4.9000e+01 1.0000e+00 2.0200e+03 9.7000e+01 3.8917e-01]\n",
      " [4.9000e+01 1.0000e+00 2.0200e+03 9.8000e+01 4.2072e-01]\n",
      " [4.9000e+01 1.0000e+00 2.0200e+03 9.9000e+01 4.5292e-01]]\n",
      "['AK', 'AL', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
      "['f', 'm']\n"
     ]
    }
   ],
   "source": [
    "print(data[:,0])\n",
    "print(data)\n",
    "print(states)\n",
    "print(genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/brfss/brfss_agg.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last minute cleaning. Will put chunk below into cleaning file soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      state    age     sex  year        bmi\n",
      "0        AL  18-24  female  1993  21.704250\n",
      "1        AL  18-24  female  1994  23.100608\n",
      "2        AL  18-24  female  1995  23.313510\n",
      "3        AL  18-24  female  1996  24.502406\n",
      "4        AL  18-24  female  1997  23.347746\n",
      "...     ...    ...     ...   ...        ...\n",
      "38849    WY    80+    male  2017  27.069832\n",
      "38850    WY    80+    male  2018  26.646026\n",
      "38851    WY    80+    male  2019  26.365848\n",
      "38852    WY    80+    male  2020  26.726692\n",
      "38853    WY    80+    male  2021  26.220133\n",
      "\n",
      "[37570 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# removing missing - should add this to cleaning dataset in the future\n",
    "index_missing = df[ (df['sex'] == '7')].index\n",
    "df.drop(index_missing, inplace=True)\n",
    "\n",
    "# Mapping from FIPS code to state abbreviation\n",
    "fips_to_abbreviation = {\n",
    "    1: 'AL', 2: 'AK', 4: 'AZ', 5: 'AR', 6: 'CA', 8: 'CO', 9: 'CT', 10: 'DE', 12: 'FL',\n",
    "    13: 'GA', 15: 'HI', 16: 'ID', 17: 'IL', 18: 'IN', 19: 'IA', 20: 'KS', 21: 'KY',\n",
    "    22: 'LA', 23: 'ME', 24: 'MD', 25: 'MA', 26: 'MI', 27: 'MN', 28: 'MS', 29: 'MO',\n",
    "    30: 'MT', 31: 'NE', 32: 'NV', 33: 'NH', 34: 'NJ', 35: 'NM', 36: 'NY', 37: 'NC',\n",
    "    38: 'ND', 39: 'OH', 40: 'OK', 41: 'OR', 42: 'PA', 44: 'RI', 45: 'SC', 46: 'SD',\n",
    "    47: 'TN', 48: 'TX', 49: 'UT', 50: 'VT', 51: 'VA', 53: 'WA', 54: 'WV', 55: 'WI',\n",
    "    56: 'WY'\n",
    "}\n",
    "\n",
    "# Convert FIPS codes to state abbreviations\n",
    "df['state'] = df['state'].map(fips_to_abbreviation)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state       int64\n",
      "age      category\n",
      "sex         int64\n",
      "year        int64\n",
      "bmi       float64\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paigepark/anaconda3/envs/deep/lib/python3.11/site-packages/pandas/core/arrays/categorical.py:528: RuntimeWarning: invalid value encountered in cast\n",
      "  fill_value = lib.item_from_zerodim(np.array(np.nan).astype(dtype))\n"
     ]
    }
   ],
   "source": [
    "df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "df['state'] = df['state'].astype('category')\n",
    "df['state'] = df['state'].apply(lambda x: states.index(x))\n",
    "df['state'] = df['state'].astype('int64')\n",
    "df['age'] = df['age'].astype('category')\n",
    "df['sex'] = df['sex'].map({'female': 0, 'male': 1})\n",
    "print(df.dtypes)\n",
    "\n",
    "health_data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train no covariate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training and test sets \n",
    "# training_index = np.logical_and(data[:, 2] >= 1998, data[:, 2] <= 2010)\n",
    "# training_data = data[training_index, :]\n",
    "# print(training_data.shape)\n",
    "\n",
    "# test_index = np.logical_and(data[:, 2] > 2010, data[:, 2] <= 2015)\n",
    "# test_data = data[test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = tf.convert_to_tensor(training_data)\n",
    "# test_data = tf.convert_to_tensor(test_data)\n",
    "# # cast tensor to type float32\n",
    "# training_data = tf.cast(training_data, tf.float32)\n",
    "# test_data = tf.cast(test_data, tf.float32)\n",
    "# num_train = training_data.shape[0]\n",
    "# num_test = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define function to fetch and process data entries from training or test data \n",
    "# def get_data(index, mode):\n",
    "#     if mode == \"train\":\n",
    "#         # randomly selects index from training data between 0 and num_train\n",
    "#         rand_index = tf.random.uniform([],minval=0, maxval=num_train, dtype=tf.int32) \n",
    "#         entry = training_data[rand_index, :]\n",
    "#     elif mode == \"not_random\":\n",
    "#         # selects specified index from test data \n",
    "#         entry = test_data[index, :]\n",
    "#     else: \n",
    "#         # for any other value of mode, randomly selects index from test\n",
    "#         rand_index = tf.random.uniform([],minval=0, maxval=num_test, dtype=tf.int32)\n",
    "#         entry = test_data[rand_index, :]\n",
    "#     state, gender, year, age, rate = entry[0], entry[1], entry[2], entry[3], entry[4]\n",
    "#     year = (year - 1998)/21\n",
    "#     age = tf.cast(age, tf.int32)\n",
    "#     state = tf.cast(state, tf.int32)\n",
    "#     gender = tf.cast(gender, tf.int32)\n",
    "#     year = tf.reshape(year, [1])\n",
    "#     age = tf.reshape(age, [1])\n",
    "#     state = tf.reshape(state, [1])\n",
    "#     gender = tf.reshape(gender, [1])\n",
    "#     rate = tf.reshape(rate, [1])\n",
    "#     return (year, age, state, gender), rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_data function to set up training and test tensorflow datasets \n",
    "# dataset_train = tf.data.Dataset.from_tensor_slices(np.arange(10000))\n",
    "# dataset_train = dataset_train.repeat()\n",
    "# dataset_train = dataset_train.map(lambda x: get_data(x, mode=\"train\"), num_parallel_calls=4)\n",
    "# dataset_train = dataset_train.batch(256)\n",
    "# dataset_train = dataset_train.prefetch(buffer_size=512)\n",
    "\n",
    "# dataset_test = tf.data.Dataset.from_tensor_slices(np.arange(10000))\n",
    "# dataset_test = dataset_test.repeat()\n",
    "# dataset_test = dataset_test.map(lambda x: get_data(x, mode=\"test\"), num_parallel_calls=4)\n",
    "# dataset_test = dataset_test.batch(256)\n",
    "# dataset_test = dataset_test.prefetch(buffer_size=512)\n",
    "\n",
    "# dataset_test2 = tf.data.Dataset.from_tensor_slices(np.arange(68000))\n",
    "# dataset_test2 = dataset_test2.map(lambda x: get_data(x, mode=\"not_random\"), num_parallel_calls=4)\n",
    "# dataset_test2 = dataset_test2.batch(256)\n",
    "# dataset_test2 = dataset_test2.prefetch(buffer_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining inputs \n",
    "# year = tfkl.Input(shape=(1,), dtype='float32', name='Year')\n",
    "# age =  tfkl.Input(shape=(1,), dtype='int32', name='Age')\n",
    "# state = tfkl.Input(shape=(1,), dtype='int32', name='State')\n",
    "# gender = tfkl.Input(shape=(1,), dtype='int32', name='Gender')\n",
    "\n",
    "# # defining embedding layers \n",
    "# age_embed = tfkl.Embedding(input_dim=100, output_dim=5, input_length=1, name='Age_embed')(age)\n",
    "# age_embed = tfkl.Flatten()(age_embed)\n",
    "\n",
    "# gender_embed = tfkl.Embedding(input_dim=2, output_dim=5, input_length=1, name='Gender_embed')(gender)\n",
    "# gender_embed = tfkl.Flatten()(gender_embed)\n",
    "\n",
    "# state_embed = tfkl.Embedding(input_dim=50, output_dim=5, input_length=1, name='State_embed')(state)\n",
    "# state_embed = tfkl.Flatten()(state_embed)\n",
    "\n",
    "# # create feature vector that concatenates all inputs \n",
    "# x = tfkl.Concatenate()([year, age_embed, gender_embed, state_embed])\n",
    "# x1 = x\n",
    "\n",
    "# # setting up middle layers \n",
    "# x = tfkl.Dense(128, activation='tanh')(x)\n",
    "# x = tfkl.BatchNormalization()(x)\n",
    "# x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "# x = tfkl.Dense(128, activation='tanh')(x)\n",
    "# x = tfkl.BatchNormalization()(x)\n",
    "# x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "# x = tfkl.Dense(128, activation='tanh')(x)\n",
    "# x = tfkl.BatchNormalization()(x)\n",
    "# x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "# x = tfkl.Dense(128, activation='tanh')(x)\n",
    "# x = tfkl.BatchNormalization()(x)\n",
    "# x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "# # setting up output layer \n",
    "# x = tfkl.Concatenate()([x1, x])\n",
    "# x = tfkl.Dense(128, activation='tanh')(x)\n",
    "# x = tfkl.BatchNormalization()(x)\n",
    "# x = tfkl.Dropout(0.05)(x)\n",
    "# x = tfkl.Dense(1, activation='sigmoid', name='final')(x)\n",
    "\n",
    "# # creating the model \n",
    "# model = tf.keras.Model(inputs=[year, age, state, gender], outputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "# model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, patience=3, verbose=0, mode=\"auto\", min_delta=1e-8, cooldown=0, min_lr=0.0)]\n",
    "# model.fit(dataset_train, steps_per_epoch=1000, validation_data=dataset_test, validation_steps=500, epochs=30, verbose=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train covariate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge health and mortality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to make state, age, gender, and year indexable\n",
    "\n",
    "age_groups = []\n",
    "states = []\n",
    "years = []\n",
    "shaped_data = np.empty((50, 13, 2, 29))\n",
    "shaped_data[:, :, :, :] = np.nan\n",
    "for row in health_data:\n",
    "    state = row[0]\n",
    "    age = row[1]\n",
    "    gender = row[2]\n",
    "    year = row[3]\n",
    "    bmi = row[4]\n",
    "\n",
    "    if not state in states:\n",
    "        states.append(state)\n",
    "    state = states.index(state)\n",
    "\n",
    "    if not age in age_groups:\n",
    "        age_groups.append(age)\n",
    "    age = age_groups.index(age)\n",
    "\n",
    "    if not year in years:\n",
    "        years.append(year)\n",
    "    year = years.index(year)\n",
    "\n",
    "    shaped_data[state, age, gender, year] = bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values using the mean of all states\n",
    "\n",
    "imputed_data = shaped_data.copy()\n",
    "matching = np.isnan(shaped_data)\n",
    "mean_values = np.repeat(np.nanmean(shaped_data, axis=0)[np.newaxis, :, :, :], 50, 0)\n",
    "imputed_data[matching] = mean_values[matching]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229600, 6)\n"
     ]
    }
   ],
   "source": [
    "combined_data = []\n",
    "for i, row in enumerate(data):\n",
    "    state = row[0]\n",
    "    gender = row[1]\n",
    "    year = row[2]\n",
    "    age = row[3]\n",
    "    rate = row[4]\n",
    "    \n",
    "    age_index = (age - 20) // 5\n",
    "    if age_index == -1:\n",
    "        age_index = 0\n",
    "    if age_index > 12:\n",
    "        age_index = 12\n",
    "\n",
    "    state_index = states.index(int(state))\n",
    "\n",
    "    year_index = years.index(year)\n",
    "\n",
    "    bmi = imputed_data[state_index, int(age_index), int(gender), year_index - 5]\n",
    "\n",
    "    combined_data.append([state, gender, year , age, bmi, rate])\n",
    "\n",
    "combined_data = np.array(combined_data)\n",
    "print(combined_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Covariate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the bmi variable\n",
    "combined_data[:, 4] = (combined_data[:, 4] - np.min(combined_data[:, 4])) / (np.max(combined_data[:, 4]) - np.min(combined_data[:, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106600, 6)\n"
     ]
    }
   ],
   "source": [
    "# training and test sets \n",
    "training_index = np.logical_and(combined_data[:, 2] >= 1998, combined_data[:, 2] <= 2010)\n",
    "training_data = combined_data[training_index, :]\n",
    "print(training_data.shape)\n",
    "\n",
    "test_index = np.logical_and(combined_data[:, 2] > 2010, combined_data[:, 2] <= 2015)\n",
    "test_data = combined_data[test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = tf.convert_to_tensor(training_data)\n",
    "test_data = tf.convert_to_tensor(test_data)\n",
    "# cast tensor to type float32\n",
    "training_data = tf.cast(training_data, tf.float32)\n",
    "test_data = tf.cast(test_data, tf.float32)\n",
    "num_train = training_data.shape[0]\n",
    "num_test = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to fetch and process data entries from training or test data \n",
    "def get_data(index, mode, include_bmi=True, include_state=True):\n",
    "    if mode == \"train\":\n",
    "        # randomly selects index from training data between 0 and num_train\n",
    "        rand_index = tf.random.uniform([],minval=0, maxval=num_train, dtype=tf.int32) \n",
    "        entry = training_data[rand_index, :]\n",
    "    elif mode == \"not_random\":\n",
    "        # selects specified index from test data \n",
    "        entry = test_data[index, :]\n",
    "    else: \n",
    "        # for any other value of mode, randomly selects index from test\n",
    "        rand_index = tf.random.uniform([],minval=0, maxval=num_test, dtype=tf.int32)\n",
    "        entry = test_data[rand_index, :]\n",
    "    state, gender, year, age, bmi, rate = entry[0], entry[1], entry[2], entry[3], entry[4], entry[5]\n",
    "    year = (year - 1998)/21\n",
    "    age = tf.cast(age, tf.int32)\n",
    "    gender = tf.cast(gender, tf.int32)\n",
    "    year = tf.reshape(year, [1])\n",
    "    age = tf.reshape(age, [1])\n",
    "    gender = tf.reshape(gender, [1])\n",
    "    rate = tf.reshape(rate, [1])\n",
    "\n",
    "     # Conditionally include bmi and state\n",
    "    inputs = [year, age, gender]\n",
    "    if include_bmi:\n",
    "        bmi = tf.reshape(bmi, [1])\n",
    "        inputs.append(bmi)\n",
    "    if include_state:\n",
    "        state = tf.reshape(tf.cast(state, tf.int32), [1])\n",
    "        inputs.append(state)\n",
    "\n",
    "    return tuple(inputs), rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_data function to set up training and test tensorflow datasets \n",
    "def create_dataset(mode, range, include_bmi=True, include_state=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(np.arange(range))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.map(lambda x: get_data(x, mode=mode, include_bmi=include_bmi, include_state=include_state), \n",
    "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(256)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "dataset_test2 = create_dataset(mode=\"not_random\", range=68000)\n",
    "\n",
    "# dataset_test = tf.data.Dataset.from_tensor_slices(np.arange(10000))\n",
    "# dataset_test = dataset_test.repeat()\n",
    "# dataset_test = dataset_test.map(lambda x: get_data(x, mode=\"test\"), num_parallel_calls=4)\n",
    "# dataset_test = dataset_test.batch(256)\n",
    "# dataset_test = dataset_test.prefetch(buffer_size=512)\n",
    "\n",
    "# dataset_test2 = tf.data.Dataset.from_tensor_slices(np.arange(68000))\n",
    "# dataset_test2 = dataset_test2.map(lambda x: get_data(x, mode=\"not_random\"), num_parallel_calls=4)\n",
    "# dataset_test2 = dataset_test2.batch(256)\n",
    "# dataset_test2 = dataset_test2.prefetch(buffer_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine_model(include_bmi=True, include_state=True):\n",
    "    # defining inputs \n",
    "    year = tfkl.Input(shape=(1,), dtype='float32', name='Year')\n",
    "    age =  tfkl.Input(shape=(1,), dtype='int32', name='Age')\n",
    "    gender = tfkl.Input(shape=(1,), dtype='int32', name='Gender')\n",
    "    # conditional inputs\n",
    "    if include_state:\n",
    "        state = tfkl.Input(shape=(1,), dtype='int32', name='State')\n",
    "    if include_bmi:\n",
    "        bmi = tfkl.Input(shape=(1,), dtype='float32', name='Bmi')\n",
    "\n",
    "    # defining embedding layers \n",
    "    age_embed = tfkl.Embedding(input_dim=100, output_dim=5, input_length=1, name='Age_embed')(age)\n",
    "    age_embed = tfkl.Flatten()(age_embed)\n",
    "\n",
    "    gender_embed = tfkl.Embedding(input_dim=2, output_dim=5, input_length=1, name='Gender_embed')(gender)\n",
    "    gender_embed = tfkl.Flatten()(gender_embed)\n",
    "    \n",
    "    if include_state:\n",
    "        state_embed = tfkl.Embedding(input_dim=50, output_dim=5, input_length=1, name='State_embed')(state)\n",
    "        state_embed = tfkl.Flatten()(state_embed)\n",
    "\n",
    "    # create feature vector that concatenates all inputs \n",
    "    # x = tfkl.Concatenate()([year, age_embed, gender_embed, state_embed, bmi])\n",
    "    x = tfkl.Concatenate()([year, age_embed, gender_embed] + ([state_embed] if include_state else []) + ([bmi] if include_bmi else []))\n",
    "    x1 = x\n",
    "\n",
    "    # setting up middle layers \n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    # setting up output layer \n",
    "    x = tfkl.Concatenate()([x1, x])\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "    outputs = tfkl.Dense(1, activation='sigmoid', name='final')(x)\n",
    "\n",
    "    # creating the model \n",
    "    inputs = [year, age, gender] \n",
    "    if include_state:\n",
    "        inputs.append(state)\n",
    "    if include_bmi:\n",
    "        inputs.append(bmi)\n",
    "    # model = tf.keras.Model(inputs=[year, age, state, gender, bmi], outputs=[x])\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # compiling the model\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(loss, val_loss):\n",
    "    loss = np.array(loss)\n",
    "    val_loss = np.array(val_loss)\n",
    "    loss = np.mean(loss)\n",
    "    val_loss = np.mean(val_loss)\n",
    "    return loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifications\n",
    "specs = [\n",
    "    (\"No BMI\", False, True),\n",
    "    (\"With BMI\", True, True),\n",
    "    (\"No State or BMI\", False, False),\n",
    "    (\"BMI, no State\", True, False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1000/1000 - 9s - loss: 0.0134 - val_loss: 4.5938e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 7s - loss: 8.8327e-04 - val_loss: 1.9786e-04 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 7s - loss: 4.0048e-04 - val_loss: 2.2123e-04 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 6s - loss: 2.4296e-04 - val_loss: 2.1231e-04 - lr: 0.0010 - 6s/epoch - 6ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 7s - loss: 1.7300e-04 - val_loss: 6.0142e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 7s - loss: 1.2571e-04 - val_loss: 1.6517e-04 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 7s - loss: 1.0252e-04 - val_loss: 3.9470e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 7s - loss: 8.2378e-05 - val_loss: 5.4793e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 8s - loss: 7.6320e-05 - val_loss: 3.4778e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 7s - loss: 6.4248e-05 - val_loss: 5.4383e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 7s - loss: 6.1019e-05 - val_loss: 5.3105e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 7s - loss: 5.4931e-05 - val_loss: 4.8874e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 7s - loss: 4.3182e-05 - val_loss: 3.2182e-05 - lr: 2.5000e-04 - 7s/epoch - 7ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 7s - loss: 4.2482e-05 - val_loss: 3.3851e-05 - lr: 2.5000e-04 - 7s/epoch - 7ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 7s - loss: 4.0683e-05 - val_loss: 4.1487e-05 - lr: 2.5000e-04 - 7s/epoch - 7ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 7s - loss: 3.8715e-05 - val_loss: 3.2470e-05 - lr: 2.5000e-04 - 7s/epoch - 7ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 7s - loss: 3.6871e-05 - val_loss: 3.2943e-05 - lr: 6.2500e-05 - 7s/epoch - 7ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 8s - loss: 3.6772e-05 - val_loss: 3.3247e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 8s - loss: 3.6818e-05 - val_loss: 3.7244e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 7s - loss: 3.5006e-05 - val_loss: 3.7355e-05 - lr: 1.5625e-05 - 7s/epoch - 7ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 7s - loss: 3.4950e-05 - val_loss: 3.4390e-05 - lr: 1.5625e-05 - 7s/epoch - 7ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 8s - loss: 3.5671e-05 - val_loss: 3.7025e-05 - lr: 1.5625e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 7s - loss: 3.5483e-05 - val_loss: 3.4106e-05 - lr: 3.9063e-06 - 7s/epoch - 7ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 9s - loss: 3.4903e-05 - val_loss: 3.4711e-05 - lr: 3.9063e-06 - 9s/epoch - 9ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 8s - loss: 3.5421e-05 - val_loss: 3.4999e-05 - lr: 3.9063e-06 - 8s/epoch - 8ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 7s - loss: 3.5534e-05 - val_loss: 3.3763e-05 - lr: 9.7656e-07 - 7s/epoch - 7ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 8s - loss: 3.4713e-05 - val_loss: 3.4352e-05 - lr: 9.7656e-07 - 8s/epoch - 8ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 7s - loss: 3.4550e-05 - val_loss: 3.4960e-05 - lr: 9.7656e-07 - 7s/epoch - 7ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 8s - loss: 3.4883e-05 - val_loss: 3.4122e-05 - lr: 2.4414e-07 - 8s/epoch - 8ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 8s - loss: 3.5763e-05 - val_loss: 3.6015e-05 - lr: 2.4414e-07 - 8s/epoch - 8ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 8s - loss: 0.0129 - val_loss: 2.5574e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 8s - loss: 7.1539e-04 - val_loss: 3.7248e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 8s - loss: 3.2145e-04 - val_loss: 1.0781e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 7s - loss: 2.0055e-04 - val_loss: 9.2825e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 8s - loss: 1.4616e-04 - val_loss: 9.1171e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 8s - loss: 1.2338e-04 - val_loss: 1.0180e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 7s - loss: 9.3756e-05 - val_loss: 6.3860e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 8s - loss: 9.2504e-05 - val_loss: 7.3451e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 8s - loss: 7.5212e-05 - val_loss: 4.0930e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 8s - loss: 6.5407e-05 - val_loss: 4.5742e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 8s - loss: 6.0944e-05 - val_loss: 4.7983e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 8s - loss: 5.5415e-05 - val_loss: 3.4233e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 8s - loss: 5.6437e-05 - val_loss: 3.7501e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 8s - loss: 5.2621e-05 - val_loss: 3.0237e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 8s - loss: 4.9610e-05 - val_loss: 4.5937e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 8s - loss: 4.8553e-05 - val_loss: 1.2936e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 7s - loss: 4.9501e-05 - val_loss: 4.9852e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 7s - loss: 3.8513e-05 - val_loss: 3.3169e-05 - lr: 2.5000e-04 - 7s/epoch - 7ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 8s - loss: 3.7260e-05 - val_loss: 3.3614e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 7s - loss: 3.7588e-05 - val_loss: 2.8427e-05 - lr: 2.5000e-04 - 7s/epoch - 7ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 9s - loss: 3.7625e-05 - val_loss: 2.8590e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 7s - loss: 3.6583e-05 - val_loss: 2.7414e-05 - lr: 2.5000e-04 - 7s/epoch - 7ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 8s - loss: 3.6089e-05 - val_loss: 2.8272e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 8s - loss: 3.6016e-05 - val_loss: 2.9119e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 8s - loss: 3.5355e-05 - val_loss: 3.7439e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 7s - loss: 3.3580e-05 - val_loss: 3.2987e-05 - lr: 6.2500e-05 - 7s/epoch - 7ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 8s - loss: 3.3486e-05 - val_loss: 3.4911e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 7s - loss: 3.3168e-05 - val_loss: 3.2607e-05 - lr: 6.2500e-05 - 7s/epoch - 7ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 9s - loss: 3.3523e-05 - val_loss: 3.4506e-05 - lr: 1.5625e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 8s - loss: 3.2498e-05 - val_loss: 3.4530e-05 - lr: 1.5625e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 9s - loss: 0.0134 - val_loss: 2.2990e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 9s - loss: 5.9241e-04 - val_loss: 9.1623e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 8s - loss: 2.7399e-04 - val_loss: 5.5174e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 8s - loss: 2.0695e-04 - val_loss: 5.6824e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 8s - loss: 1.6204e-04 - val_loss: 4.4246e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 7s - loss: 1.3069e-04 - val_loss: 5.2115e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 8s - loss: 1.0516e-04 - val_loss: 3.8919e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 8s - loss: 9.1965e-05 - val_loss: 4.7121e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 8s - loss: 7.3089e-05 - val_loss: 3.3627e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 7s - loss: 6.6829e-05 - val_loss: 3.7407e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 8s - loss: 5.8171e-05 - val_loss: 3.9109e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 8s - loss: 5.3021e-05 - val_loss: 3.8095e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 8s - loss: 4.0140e-05 - val_loss: 2.8372e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 8s - loss: 3.9172e-05 - val_loss: 3.1226e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 8s - loss: 3.9452e-05 - val_loss: 3.1415e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 7s - loss: 3.8144e-05 - val_loss: 3.0732e-05 - lr: 2.5000e-04 - 7s/epoch - 7ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 7s - loss: 3.5209e-05 - val_loss: 3.0639e-05 - lr: 6.2500e-05 - 7s/epoch - 7ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 8s - loss: 3.5966e-05 - val_loss: 3.2087e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 8s - loss: 3.5171e-05 - val_loss: 2.8403e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 7s - loss: 3.3932e-05 - val_loss: 3.0423e-05 - lr: 1.5625e-05 - 7s/epoch - 7ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 8s - loss: 3.4655e-05 - val_loss: 2.9520e-05 - lr: 1.5625e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 7s - loss: 3.4324e-05 - val_loss: 3.0901e-05 - lr: 1.5625e-05 - 7s/epoch - 7ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 8s - loss: 3.4529e-05 - val_loss: 3.0988e-05 - lr: 3.9063e-06 - 8s/epoch - 8ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 7s - loss: 3.3553e-05 - val_loss: 3.1010e-05 - lr: 3.9063e-06 - 7s/epoch - 7ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 7s - loss: 3.4655e-05 - val_loss: 3.1167e-05 - lr: 3.9063e-06 - 7s/epoch - 7ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 8s - loss: 3.4083e-05 - val_loss: 3.1120e-05 - lr: 9.7656e-07 - 8s/epoch - 8ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 8s - loss: 3.4217e-05 - val_loss: 3.1301e-05 - lr: 9.7656e-07 - 8s/epoch - 8ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 8s - loss: 3.3819e-05 - val_loss: 3.0352e-05 - lr: 9.7656e-07 - 8s/epoch - 8ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 7s - loss: 3.3774e-05 - val_loss: 3.1228e-05 - lr: 2.4414e-07 - 7s/epoch - 7ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 8s - loss: 3.3714e-05 - val_loss: 3.0770e-05 - lr: 2.4414e-07 - 8s/epoch - 8ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 8s - loss: 0.0133 - val_loss: 6.0905e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 9s - loss: 6.5943e-04 - val_loss: 2.3215e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 8s - loss: 2.8841e-04 - val_loss: 5.4828e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 8s - loss: 2.0955e-04 - val_loss: 9.1588e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 8s - loss: 1.5349e-04 - val_loss: 6.5962e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 8s - loss: 1.1516e-04 - val_loss: 4.5905e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 8s - loss: 1.0265e-04 - val_loss: 8.2638e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 8s - loss: 8.7273e-05 - val_loss: 9.9841e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 7s - loss: 7.7145e-05 - val_loss: 3.8613e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 9s - loss: 6.8662e-05 - val_loss: 3.5207e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 7s - loss: 6.0296e-05 - val_loss: 3.5242e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 8s - loss: 6.0639e-05 - val_loss: 4.0745e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 7s - loss: 5.2621e-05 - val_loss: 3.2704e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 8s - loss: 5.4328e-05 - val_loss: 3.8317e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 7s - loss: 4.7860e-05 - val_loss: 3.1443e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 8s - loss: 4.7606e-05 - val_loss: 3.4739e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 8s - loss: 4.5391e-05 - val_loss: 5.0843e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 9s - loss: 4.6491e-05 - val_loss: 3.4113e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 8s - loss: 3.6895e-05 - val_loss: 3.2768e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 8s - loss: 3.5351e-05 - val_loss: 2.7692e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 8s - loss: 3.5245e-05 - val_loss: 3.2956e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 8s - loss: 3.4034e-05 - val_loss: 3.9127e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 8s - loss: 3.4358e-05 - val_loss: 3.0975e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 8s - loss: 3.2337e-05 - val_loss: 2.8444e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 7s - loss: 3.2968e-05 - val_loss: 2.9643e-05 - lr: 6.2500e-05 - 7s/epoch - 7ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 8s - loss: 3.2507e-05 - val_loss: 3.3404e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 7s - loss: 3.1629e-05 - val_loss: 2.9387e-05 - lr: 1.5625e-05 - 7s/epoch - 7ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 8s - loss: 3.1500e-05 - val_loss: 2.9605e-05 - lr: 1.5625e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 8s - loss: 3.1510e-05 - val_loss: 2.9680e-05 - lr: 1.5625e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 8s - loss: 3.1314e-05 - val_loss: 3.0780e-05 - lr: 3.9063e-06 - 8s/epoch - 8ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 9s - loss: 0.0129 - val_loss: 9.4289e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 9s - loss: 7.2774e-04 - val_loss: 4.3408e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 8s - loss: 3.3607e-04 - val_loss: 7.2397e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 8s - loss: 2.1235e-04 - val_loss: 6.7287e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 8s - loss: 1.5113e-04 - val_loss: 4.5049e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 8s - loss: 1.3608e-04 - val_loss: 2.2068e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 9s - loss: 9.1030e-05 - val_loss: 4.4894e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 8s - loss: 9.0487e-05 - val_loss: 6.6863e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 8s - loss: 7.5885e-05 - val_loss: 3.7942e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 8s - loss: 6.0153e-05 - val_loss: 4.3218e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 8s - loss: 5.3706e-05 - val_loss: 3.2073e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 8s - loss: 5.2387e-05 - val_loss: 3.1733e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 9s - loss: 5.1567e-05 - val_loss: 3.1597e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 8s - loss: 5.4837e-05 - val_loss: 4.6907e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 8s - loss: 4.9335e-05 - val_loss: 4.3106e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 8s - loss: 4.8448e-05 - val_loss: 5.4039e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 8s - loss: 3.8264e-05 - val_loss: 3.5060e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 9s - loss: 3.7411e-05 - val_loss: 3.2253e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 8s - loss: 3.6546e-05 - val_loss: 3.1917e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 8s - loss: 3.5265e-05 - val_loss: 3.1512e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 8s - loss: 3.4281e-05 - val_loss: 2.9083e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 9s - loss: 3.3866e-05 - val_loss: 3.1341e-05 - lr: 6.2500e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 8s - loss: 3.4623e-05 - val_loss: 2.7722e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 8s - loss: 3.3915e-05 - val_loss: 3.1294e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 8s - loss: 3.3526e-05 - val_loss: 2.9239e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 8s - loss: 3.3975e-05 - val_loss: 3.1727e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 9s - loss: 3.3147e-05 - val_loss: 2.9937e-05 - lr: 1.5625e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 8s - loss: 3.2921e-05 - val_loss: 2.8759e-05 - lr: 1.5625e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 8s - loss: 3.3141e-05 - val_loss: 2.9951e-05 - lr: 1.5625e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 8s - loss: 3.3504e-05 - val_loss: 3.0134e-05 - lr: 3.9063e-06 - 8s/epoch - 8ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 8s - loss: 0.0140 - val_loss: 1.9874e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 9s - loss: 5.7762e-04 - val_loss: 9.3777e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 8s - loss: 3.3823e-04 - val_loss: 8.1897e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 8s - loss: 2.5024e-04 - val_loss: 1.2489e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 8s - loss: 2.0849e-04 - val_loss: 7.6777e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 8s - loss: 1.8275e-04 - val_loss: 1.3813e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 8s - loss: 1.5863e-04 - val_loss: 5.2358e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 8s - loss: 1.4337e-04 - val_loss: 9.3340e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 8s - loss: 1.2707e-04 - val_loss: 5.7842e-05 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 9s - loss: 1.1833e-04 - val_loss: 7.3240e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 10s - loss: 9.4636e-05 - val_loss: 4.8816e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 9s - loss: 9.2055e-05 - val_loss: 4.9674e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 9s - loss: 8.9350e-05 - val_loss: 5.0205e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 9s - loss: 8.7024e-05 - val_loss: 4.7678e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 9s - loss: 8.3065e-05 - val_loss: 5.3527e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 9s - loss: 8.2390e-05 - val_loss: 4.7408e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 8s - loss: 7.7381e-05 - val_loss: 4.6970e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 9s - loss: 7.7159e-05 - val_loss: 5.6861e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 9s - loss: 7.3675e-05 - val_loss: 5.0626e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 8s - loss: 7.3415e-05 - val_loss: 6.2214e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 9s - loss: 6.7523e-05 - val_loss: 4.5588e-05 - lr: 6.2500e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 8s - loss: 6.7341e-05 - val_loss: 4.9081e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 9s - loss: 6.8521e-05 - val_loss: 5.8006e-05 - lr: 6.2500e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 8s - loss: 6.6317e-05 - val_loss: 4.8430e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 9s - loss: 6.5664e-05 - val_loss: 4.8739e-05 - lr: 1.5625e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 8s - loss: 6.4877e-05 - val_loss: 5.3062e-05 - lr: 1.5625e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 9s - loss: 6.5055e-05 - val_loss: 5.1880e-05 - lr: 1.5625e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 9s - loss: 6.5539e-05 - val_loss: 4.9425e-05 - lr: 3.9063e-06 - 9s/epoch - 9ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 8s - loss: 6.4333e-05 - val_loss: 5.1263e-05 - lr: 3.9063e-06 - 8s/epoch - 8ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 9s - loss: 6.5307e-05 - val_loss: 5.2743e-05 - lr: 3.9063e-06 - 9s/epoch - 9ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 10s - loss: 0.0128 - val_loss: 2.6041e-04 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 8s - loss: 4.5893e-04 - val_loss: 1.1742e-04 - lr: 0.0010 - 8s/epoch - 8ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 9s - loss: 2.9674e-04 - val_loss: 8.6541e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 9s - loss: 2.3062e-04 - val_loss: 6.3031e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 9s - loss: 1.9580e-04 - val_loss: 9.6959e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 9s - loss: 1.7119e-04 - val_loss: 5.8350e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 9s - loss: 1.4548e-04 - val_loss: 6.0796e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 9s - loss: 1.2836e-04 - val_loss: 5.1839e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 9s - loss: 1.2012e-04 - val_loss: 1.1479e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 9s - loss: 1.0592e-04 - val_loss: 4.6207e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 9s - loss: 1.0143e-04 - val_loss: 6.1661e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 9s - loss: 9.4701e-05 - val_loss: 6.3049e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 10s - loss: 9.0047e-05 - val_loss: 5.3045e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 10s - loss: 7.4469e-05 - val_loss: 4.3075e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 10s - loss: 7.2093e-05 - val_loss: 4.3180e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 10s - loss: 6.9869e-05 - val_loss: 4.4685e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 10s - loss: 6.9459e-05 - val_loss: 4.2674e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 10s - loss: 6.8376e-05 - val_loss: 5.0639e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 10s - loss: 6.9276e-05 - val_loss: 4.8276e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 10s - loss: 6.8194e-05 - val_loss: 4.1318e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 10s - loss: 6.6600e-05 - val_loss: 4.1485e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 10s - loss: 6.4380e-05 - val_loss: 5.3870e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 10s - loss: 6.4680e-05 - val_loss: 4.2789e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 10s - loss: 6.1632e-05 - val_loss: 4.1983e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 10s - loss: 6.0824e-05 - val_loss: 4.6502e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 10s - loss: 6.0656e-05 - val_loss: 4.7387e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 10s - loss: 6.0170e-05 - val_loss: 4.2233e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 10s - loss: 5.9284e-05 - val_loss: 4.2909e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 10s - loss: 6.0261e-05 - val_loss: 4.2748e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 10s - loss: 6.0154e-05 - val_loss: 4.3730e-05 - lr: 3.9063e-06 - 10s/epoch - 10ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 11s - loss: 0.0134 - val_loss: 3.4726e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 10s - loss: 5.4787e-04 - val_loss: 2.1545e-04 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 10s - loss: 3.4607e-04 - val_loss: 8.9549e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 10s - loss: 2.6530e-04 - val_loss: 9.6428e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 10s - loss: 2.1278e-04 - val_loss: 1.3112e-04 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 10s - loss: 1.9045e-04 - val_loss: 7.5356e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 10s - loss: 1.6365e-04 - val_loss: 6.6644e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 10s - loss: 1.4130e-04 - val_loss: 7.0512e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 10s - loss: 1.2847e-04 - val_loss: 6.0244e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 10s - loss: 1.2119e-04 - val_loss: 1.0846e-04 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 10s - loss: 1.1135e-04 - val_loss: 6.2277e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 11s - loss: 1.0112e-04 - val_loss: 4.9925e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 10s - loss: 1.0171e-04 - val_loss: 5.9631e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 9s - loss: 9.4366e-05 - val_loss: 6.1191e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 9s - loss: 8.5861e-05 - val_loss: 4.5043e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 10s - loss: 8.7880e-05 - val_loss: 6.3439e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 9s - loss: 8.4093e-05 - val_loss: 5.1823e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 9s - loss: 8.1599e-05 - val_loss: 4.7900e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 9s - loss: 6.6515e-05 - val_loss: 3.8735e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 161s - loss: 6.4813e-05 - val_loss: 4.4870e-05 - lr: 2.5000e-04 - 161s/epoch - 161ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 11s - loss: 6.3870e-05 - val_loss: 3.8105e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 8s - loss: 6.3493e-05 - val_loss: 4.3598e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 7s - loss: 6.2151e-05 - val_loss: 4.5240e-05 - lr: 2.5000e-04 - 7s/epoch - 7ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 8s - loss: 6.1332e-05 - val_loss: 3.9444e-05 - lr: 2.5000e-04 - 8s/epoch - 8ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 8s - loss: 5.9613e-05 - val_loss: 4.0684e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 8s - loss: 5.8442e-05 - val_loss: 4.5890e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 8s - loss: 5.9665e-05 - val_loss: 4.4812e-05 - lr: 6.2500e-05 - 8s/epoch - 8ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 9s - loss: 5.7536e-05 - val_loss: 4.2824e-05 - lr: 1.5625e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 9s - loss: 5.7236e-05 - val_loss: 4.3220e-05 - lr: 1.5625e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 9s - loss: 5.8220e-05 - val_loss: 4.2698e-05 - lr: 1.5625e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 9s - loss: 0.0131 - val_loss: 3.2737e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 9s - loss: 7.1289e-04 - val_loss: 2.6129e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 9s - loss: 3.8743e-04 - val_loss: 1.3932e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 9s - loss: 2.6111e-04 - val_loss: 7.6216e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 9s - loss: 1.9785e-04 - val_loss: 7.3230e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 9s - loss: 1.7443e-04 - val_loss: 1.4692e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 9s - loss: 1.4497e-04 - val_loss: 6.7566e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 10s - loss: 1.3044e-04 - val_loss: 5.6900e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 9s - loss: 1.2443e-04 - val_loss: 7.8765e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 9s - loss: 1.1365e-04 - val_loss: 5.8905e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 9s - loss: 1.0871e-04 - val_loss: 7.4091e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 9s - loss: 8.6487e-05 - val_loss: 5.1090e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 9s - loss: 8.2412e-05 - val_loss: 4.6112e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 9s - loss: 8.2444e-05 - val_loss: 5.5503e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 10s - loss: 7.9429e-05 - val_loss: 4.9844e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 9s - loss: 8.0311e-05 - val_loss: 5.3850e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 9s - loss: 7.3231e-05 - val_loss: 4.5629e-05 - lr: 6.2500e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 9s - loss: 7.1865e-05 - val_loss: 4.6182e-05 - lr: 6.2500e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 10s - loss: 7.0748e-05 - val_loss: 4.4996e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 10s - loss: 7.0927e-05 - val_loss: 4.7803e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 9s - loss: 6.9877e-05 - val_loss: 4.6517e-05 - lr: 6.2500e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 9s - loss: 6.9650e-05 - val_loss: 4.5714e-05 - lr: 6.2500e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 9s - loss: 6.8658e-05 - val_loss: 4.3460e-05 - lr: 1.5625e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 9s - loss: 6.8385e-05 - val_loss: 4.6276e-05 - lr: 1.5625e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 10s - loss: 6.7377e-05 - val_loss: 4.3991e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 10s - loss: 6.8274e-05 - val_loss: 4.4088e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 10s - loss: 6.8103e-05 - val_loss: 4.4774e-05 - lr: 3.9063e-06 - 10s/epoch - 10ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 10s - loss: 6.8072e-05 - val_loss: 4.4510e-05 - lr: 3.9063e-06 - 10s/epoch - 10ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 9s - loss: 6.7104e-05 - val_loss: 4.4157e-05 - lr: 3.9063e-06 - 9s/epoch - 9ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 9s - loss: 6.8040e-05 - val_loss: 4.4264e-05 - lr: 9.7656e-07 - 9s/epoch - 9ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 10s - loss: 0.0135 - val_loss: 4.5459e-04 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 10s - loss: 8.1282e-04 - val_loss: 2.6014e-04 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 10s - loss: 4.8986e-04 - val_loss: 8.3523e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 10s - loss: 3.1097e-04 - val_loss: 1.1439e-04 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 10s - loss: 2.2546e-04 - val_loss: 7.4702e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 10s - loss: 1.7955e-04 - val_loss: 6.9259e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 9s - loss: 1.5599e-04 - val_loss: 7.2133e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 10s - loss: 1.3486e-04 - val_loss: 5.1464e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 10s - loss: 1.2191e-04 - val_loss: 8.8399e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 11s - loss: 1.1384e-04 - val_loss: 5.5589e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 10s - loss: 1.0624e-04 - val_loss: 4.8985e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 10s - loss: 1.0275e-04 - val_loss: 5.5466e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 10s - loss: 9.6894e-05 - val_loss: 4.5588e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 11s - loss: 9.5261e-05 - val_loss: 7.0342e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 10s - loss: 8.9589e-05 - val_loss: 4.7507e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 10s - loss: 8.8941e-05 - val_loss: 8.9016e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 10s - loss: 7.2532e-05 - val_loss: 4.2857e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 10s - loss: 7.1676e-05 - val_loss: 4.0527e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 10s - loss: 7.1172e-05 - val_loss: 4.6649e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 10s - loss: 6.9651e-05 - val_loss: 4.0580e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 10s - loss: 6.7103e-05 - val_loss: 4.4173e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 10s - loss: 6.5331e-05 - val_loss: 4.2292e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 10s - loss: 6.4488e-05 - val_loss: 4.0828e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 10s - loss: 6.3931e-05 - val_loss: 4.3840e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 10s - loss: 6.3480e-05 - val_loss: 3.9933e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 10s - loss: 6.3495e-05 - val_loss: 4.3221e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 10s - loss: 6.2865e-05 - val_loss: 4.0074e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 11s - loss: 6.3680e-05 - val_loss: 4.1303e-05 - lr: 1.5625e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 10s - loss: 6.3456e-05 - val_loss: 4.2636e-05 - lr: 3.9063e-06 - 10s/epoch - 10ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 11s - loss: 6.2795e-05 - val_loss: 4.1477e-05 - lr: 3.9063e-06 - 11s/epoch - 11ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 10s - loss: 0.0135 - val_loss: 3.9274e-04 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 9s - loss: 8.6052e-04 - val_loss: 1.1347e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 10s - loss: 3.6180e-04 - val_loss: 7.1109e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 10s - loss: 2.2186e-04 - val_loss: 7.4056e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 9s - loss: 1.6520e-04 - val_loss: 1.0369e-04 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 9s - loss: 1.4048e-04 - val_loss: 8.2675e-05 - lr: 0.0010 - 9s/epoch - 9ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 9s - loss: 1.0231e-04 - val_loss: 5.6376e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 9s - loss: 1.0151e-04 - val_loss: 5.3818e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 9s - loss: 9.6751e-05 - val_loss: 6.1023e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 9s - loss: 9.0975e-05 - val_loss: 7.3634e-05 - lr: 2.5000e-04 - 9s/epoch - 9ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 10s - loss: 8.5531e-05 - val_loss: 5.7464e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 9s - loss: 7.5557e-05 - val_loss: 5.2102e-05 - lr: 6.2500e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 10s - loss: 7.3638e-05 - val_loss: 5.1990e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 10s - loss: 7.2826e-05 - val_loss: 9.6043e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 9s - loss: 7.2338e-05 - val_loss: 6.3847e-05 - lr: 6.2500e-05 - 9s/epoch - 9ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 10s - loss: 7.2616e-05 - val_loss: 5.5547e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 10s - loss: 7.0849e-05 - val_loss: 5.5517e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 11s - loss: 6.9767e-05 - val_loss: 5.3115e-05 - lr: 1.5625e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 10s - loss: 6.9757e-05 - val_loss: 5.3822e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 10s - loss: 6.9835e-05 - val_loss: 5.4448e-05 - lr: 3.9063e-06 - 10s/epoch - 10ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 10s - loss: 6.9847e-05 - val_loss: 5.3261e-05 - lr: 3.9063e-06 - 10s/epoch - 10ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 10s - loss: 6.9463e-05 - val_loss: 5.4299e-05 - lr: 3.9063e-06 - 10s/epoch - 10ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 10s - loss: 6.8970e-05 - val_loss: 5.3383e-05 - lr: 9.7656e-07 - 10s/epoch - 10ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 10s - loss: 6.9499e-05 - val_loss: 5.4214e-05 - lr: 9.7656e-07 - 10s/epoch - 10ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 11s - loss: 6.9417e-05 - val_loss: 5.2450e-05 - lr: 9.7656e-07 - 11s/epoch - 11ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 12s - loss: 6.9277e-05 - val_loss: 5.3279e-05 - lr: 2.4414e-07 - 12s/epoch - 12ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 10s - loss: 6.9279e-05 - val_loss: 5.3922e-05 - lr: 2.4414e-07 - 10s/epoch - 10ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 10s - loss: 6.8274e-05 - val_loss: 5.3539e-05 - lr: 2.4414e-07 - 10s/epoch - 10ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 10s - loss: 6.8542e-05 - val_loss: 5.4521e-05 - lr: 6.1035e-08 - 10s/epoch - 10ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 10s - loss: 6.9722e-05 - val_loss: 5.3770e-05 - lr: 6.1035e-08 - 10s/epoch - 10ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 11s - loss: 0.0135 - val_loss: 0.0011 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 10s - loss: 7.3552e-04 - val_loss: 1.9285e-04 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 11s - loss: 3.7018e-04 - val_loss: 1.2285e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 11s - loss: 2.3269e-04 - val_loss: 1.1942e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 10s - loss: 1.8898e-04 - val_loss: 8.4466e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 10s - loss: 1.5468e-04 - val_loss: 9.2054e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 11s - loss: 1.3743e-04 - val_loss: 5.8809e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 10s - loss: 1.0989e-04 - val_loss: 6.0431e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 10s - loss: 9.1485e-05 - val_loss: 5.5521e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 10s - loss: 8.2698e-05 - val_loss: 5.7818e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 10s - loss: 8.3208e-05 - val_loss: 7.0444e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 10s - loss: 7.9055e-05 - val_loss: 6.5671e-05 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 10s - loss: 6.7318e-05 - val_loss: 5.4371e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 10s - loss: 6.7734e-05 - val_loss: 5.9188e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 10s - loss: 6.7022e-05 - val_loss: 5.6498e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 10s - loss: 6.7411e-05 - val_loss: 7.4468e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 10s - loss: 6.3466e-05 - val_loss: 6.4402e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 11s - loss: 6.3871e-05 - val_loss: 5.7693e-05 - lr: 6.2500e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 11s - loss: 6.4501e-05 - val_loss: 5.6064e-05 - lr: 6.2500e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 10s - loss: 6.2658e-05 - val_loss: 5.7669e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 10s - loss: 6.3142e-05 - val_loss: 5.7397e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 11s - loss: 6.2663e-05 - val_loss: 5.8930e-05 - lr: 1.5625e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 11s - loss: 6.2730e-05 - val_loss: 5.7766e-05 - lr: 3.9063e-06 - 11s/epoch - 11ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 11s - loss: 6.3208e-05 - val_loss: 5.7414e-05 - lr: 3.9063e-06 - 11s/epoch - 11ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 11s - loss: 6.2408e-05 - val_loss: 5.6739e-05 - lr: 3.9063e-06 - 11s/epoch - 11ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 11s - loss: 6.3956e-05 - val_loss: 5.7403e-05 - lr: 9.7656e-07 - 11s/epoch - 11ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 11s - loss: 6.2360e-05 - val_loss: 5.7777e-05 - lr: 9.7656e-07 - 11s/epoch - 11ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 11s - loss: 6.3625e-05 - val_loss: 5.8392e-05 - lr: 9.7656e-07 - 11s/epoch - 11ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 11s - loss: 6.3315e-05 - val_loss: 5.8150e-05 - lr: 2.4414e-07 - 11s/epoch - 11ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 13s - loss: 6.2398e-05 - val_loss: 5.7429e-05 - lr: 2.4414e-07 - 13s/epoch - 13ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 12s - loss: 0.0134 - val_loss: 3.8806e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 11s - loss: 7.5622e-04 - val_loss: 6.1645e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 11s - loss: 3.5762e-04 - val_loss: 1.1633e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 12s - loss: 2.2807e-04 - val_loss: 7.0956e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 13s - loss: 1.8354e-04 - val_loss: 1.2507e-04 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 12s - loss: 1.4060e-04 - val_loss: 8.4130e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 12s - loss: 1.2429e-04 - val_loss: 2.0558e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 11s - loss: 9.3049e-05 - val_loss: 5.5805e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 11s - loss: 8.7246e-05 - val_loss: 8.3795e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 12s - loss: 8.2630e-05 - val_loss: 5.3776e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 11s - loss: 8.2534e-05 - val_loss: 5.7024e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 11s - loss: 7.9732e-05 - val_loss: 5.6155e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 12s - loss: 7.7937e-05 - val_loss: 5.2313e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 12s - loss: 7.7160e-05 - val_loss: 7.0349e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 11s - loss: 7.4893e-05 - val_loss: 8.4896e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 11s - loss: 7.5837e-05 - val_loss: 5.2247e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 11s - loss: 7.2364e-05 - val_loss: 6.2612e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 11s - loss: 7.1992e-05 - val_loss: 5.6354e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 12s - loss: 7.0864e-05 - val_loss: 6.2800e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 12s - loss: 6.7183e-05 - val_loss: 6.0506e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 12s - loss: 6.6383e-05 - val_loss: 5.3286e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 12s - loss: 6.6604e-05 - val_loss: 5.6051e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 12s - loss: 6.4517e-05 - val_loss: 5.5323e-05 - lr: 1.5625e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 11s - loss: 6.4258e-05 - val_loss: 5.7649e-05 - lr: 1.5625e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 12s - loss: 6.5201e-05 - val_loss: 5.5745e-05 - lr: 1.5625e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 12s - loss: 6.5400e-05 - val_loss: 5.6390e-05 - lr: 3.9063e-06 - 12s/epoch - 12ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 11s - loss: 6.5235e-05 - val_loss: 5.5562e-05 - lr: 3.9063e-06 - 11s/epoch - 11ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 12s - loss: 6.3920e-05 - val_loss: 5.6146e-05 - lr: 3.9063e-06 - 12s/epoch - 12ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 12s - loss: 6.4362e-05 - val_loss: 5.8410e-05 - lr: 9.7656e-07 - 12s/epoch - 12ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 12s - loss: 6.4426e-05 - val_loss: 5.6808e-05 - lr: 9.7656e-07 - 12s/epoch - 12ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 12s - loss: 0.0136 - val_loss: 4.1407e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 11s - loss: 9.2507e-04 - val_loss: 5.2664e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 11s - loss: 4.2469e-04 - val_loss: 1.2076e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 12s - loss: 2.4738e-04 - val_loss: 7.8443e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 11s - loss: 1.7382e-04 - val_loss: 8.4555e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 12s - loss: 1.4241e-04 - val_loss: 1.2408e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 12s - loss: 1.2577e-04 - val_loss: 6.6680e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 11s - loss: 1.0430e-04 - val_loss: 7.1883e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 11s - loss: 9.7019e-05 - val_loss: 5.4759e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 11s - loss: 8.3155e-05 - val_loss: 5.8152e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 11s - loss: 8.3894e-05 - val_loss: 6.1491e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 11s - loss: 7.9256e-05 - val_loss: 5.6775e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 12s - loss: 6.7040e-05 - val_loss: 5.3934e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 12s - loss: 6.7228e-05 - val_loss: 5.4686e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 12s - loss: 6.7620e-05 - val_loss: 5.9192e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 13s - loss: 6.5777e-05 - val_loss: 5.5640e-05 - lr: 2.5000e-04 - 13s/epoch - 13ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 13s - loss: 6.4967e-05 - val_loss: 5.3815e-05 - lr: 6.2500e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 12s - loss: 6.4041e-05 - val_loss: 5.3546e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 12s - loss: 6.3785e-05 - val_loss: 5.3093e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 12s - loss: 6.5536e-05 - val_loss: 5.4213e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 12s - loss: 6.3919e-05 - val_loss: 5.5778e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 12s - loss: 6.4243e-05 - val_loss: 5.5685e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 12s - loss: 6.4319e-05 - val_loss: 5.6060e-05 - lr: 1.5625e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 12s - loss: 6.4031e-05 - val_loss: 5.3466e-05 - lr: 1.5625e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 12s - loss: 6.3108e-05 - val_loss: 5.4608e-05 - lr: 1.5625e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 13s - loss: 6.3145e-05 - val_loss: 5.5323e-05 - lr: 3.9063e-06 - 13s/epoch - 13ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 13s - loss: 6.2282e-05 - val_loss: 5.6265e-05 - lr: 3.9063e-06 - 13s/epoch - 13ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 13s - loss: 6.2677e-05 - val_loss: 5.4648e-05 - lr: 3.9063e-06 - 13s/epoch - 13ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 12s - loss: 6.3338e-05 - val_loss: 5.5827e-05 - lr: 9.7656e-07 - 12s/epoch - 12ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 13s - loss: 6.2939e-05 - val_loss: 5.4560e-05 - lr: 9.7656e-07 - 13s/epoch - 13ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 12s - loss: 0.0134 - val_loss: 9.7443e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 12s - loss: 0.0011 - val_loss: 3.2519e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 12s - loss: 6.4101e-04 - val_loss: 4.8471e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 13s - loss: 3.7136e-04 - val_loss: 1.6036e-04 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 12s - loss: 2.5189e-04 - val_loss: 8.6290e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 11s - loss: 1.7335e-04 - val_loss: 9.1609e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 12s - loss: 1.4347e-04 - val_loss: 6.4810e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 12s - loss: 1.1892e-04 - val_loss: 5.9151e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 12s - loss: 1.0314e-04 - val_loss: 7.1295e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 12s - loss: 9.8013e-05 - val_loss: 5.3888e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 13s - loss: 9.0464e-05 - val_loss: 5.7327e-05 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 12s - loss: 8.6773e-05 - val_loss: 5.6472e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 12s - loss: 8.3992e-05 - val_loss: 6.1462e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 12s - loss: 7.2960e-05 - val_loss: 5.1414e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 12s - loss: 7.1998e-05 - val_loss: 5.0639e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 12s - loss: 7.1563e-05 - val_loss: 5.1771e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 13s - loss: 7.1421e-05 - val_loss: 5.6268e-05 - lr: 2.5000e-04 - 13s/epoch - 13ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 12s - loss: 7.1745e-05 - val_loss: 5.1192e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 12s - loss: 6.8982e-05 - val_loss: 5.2966e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 12s - loss: 6.7938e-05 - val_loss: 5.0218e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 12s - loss: 6.7097e-05 - val_loss: 5.0393e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 13s - loss: 6.7691e-05 - val_loss: 5.1348e-05 - lr: 6.2500e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 13s - loss: 6.7115e-05 - val_loss: 5.5533e-05 - lr: 6.2500e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 13s - loss: 6.6993e-05 - val_loss: 5.1925e-05 - lr: 1.5625e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 13s - loss: 6.7301e-05 - val_loss: 5.0865e-05 - lr: 1.5625e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 13s - loss: 6.7404e-05 - val_loss: 5.0749e-05 - lr: 1.5625e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 14s - loss: 6.7411e-05 - val_loss: 5.2059e-05 - lr: 3.9063e-06 - 14s/epoch - 14ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 12s - loss: 6.6420e-05 - val_loss: 5.2707e-05 - lr: 3.9063e-06 - 12s/epoch - 12ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 14s - loss: 6.6298e-05 - val_loss: 5.2403e-05 - lr: 3.9063e-06 - 14s/epoch - 14ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 14s - loss: 6.6173e-05 - val_loss: 5.1883e-05 - lr: 9.7656e-07 - 14s/epoch - 14ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 13s - loss: 0.0133 - val_loss: 3.4417e-04 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 15s - loss: 9.5414e-04 - val_loss: 2.1331e-04 - lr: 0.0010 - 15s/epoch - 15ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 13s - loss: 4.8836e-04 - val_loss: 2.7339e-04 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 13s - loss: 3.0378e-04 - val_loss: 1.2403e-04 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 12s - loss: 2.3047e-04 - val_loss: 1.9858e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 13s - loss: 1.6401e-04 - val_loss: 1.6324e-04 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 12s - loss: 1.4025e-04 - val_loss: 1.0668e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 12s - loss: 1.2131e-04 - val_loss: 9.0384e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 13s - loss: 1.0439e-04 - val_loss: 5.8881e-05 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 12s - loss: 9.5555e-05 - val_loss: 5.1461e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 12s - loss: 9.0380e-05 - val_loss: 7.4386e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 13s - loss: 8.3845e-05 - val_loss: 5.6106e-05 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 13s - loss: 8.0997e-05 - val_loss: 5.5011e-05 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 13s - loss: 6.8060e-05 - val_loss: 4.9640e-05 - lr: 2.5000e-04 - 13s/epoch - 13ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 12s - loss: 6.6515e-05 - val_loss: 4.9503e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 12s - loss: 6.5481e-05 - val_loss: 5.4286e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 12s - loss: 6.5231e-05 - val_loss: 4.8157e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 13s - loss: 6.4699e-05 - val_loss: 5.0636e-05 - lr: 2.5000e-04 - 13s/epoch - 13ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 14s - loss: 6.4161e-05 - val_loss: 4.9269e-05 - lr: 2.5000e-04 - 14s/epoch - 14ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 13s - loss: 6.3678e-05 - val_loss: 5.5426e-05 - lr: 2.5000e-04 - 13s/epoch - 13ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 12s - loss: 6.1368e-05 - val_loss: 5.0943e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 13s - loss: 6.1031e-05 - val_loss: 4.9945e-05 - lr: 6.2500e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 12s - loss: 5.9968e-05 - val_loss: 5.5618e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 12s - loss: 6.0416e-05 - val_loss: 4.8899e-05 - lr: 1.5625e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 12s - loss: 6.0367e-05 - val_loss: 5.0592e-05 - lr: 1.5625e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 12s - loss: 6.0582e-05 - val_loss: 5.0042e-05 - lr: 1.5625e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 12s - loss: 6.0559e-05 - val_loss: 5.1462e-05 - lr: 3.9063e-06 - 12s/epoch - 12ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 12s - loss: 6.0872e-05 - val_loss: 5.2214e-05 - lr: 3.9063e-06 - 12s/epoch - 12ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 12s - loss: 5.9948e-05 - val_loss: 5.0832e-05 - lr: 3.9063e-06 - 12s/epoch - 12ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 12s - loss: 5.9534e-05 - val_loss: 5.1852e-05 - lr: 9.7656e-07 - 12s/epoch - 12ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 12s - loss: 0.0135 - val_loss: 7.2147e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 10s - loss: 8.5382e-04 - val_loss: 3.8403e-04 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 11s - loss: 4.0877e-04 - val_loss: 2.0546e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 11s - loss: 2.4273e-04 - val_loss: 9.1442e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 11s - loss: 1.8197e-04 - val_loss: 3.7188e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 11s - loss: 1.5231e-04 - val_loss: 1.3958e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 11s - loss: 1.3309e-04 - val_loss: 7.4385e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 11s - loss: 1.0491e-04 - val_loss: 8.8318e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 11s - loss: 1.0407e-04 - val_loss: 7.6302e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 11s - loss: 9.4346e-05 - val_loss: 6.8345e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 11s - loss: 8.4593e-05 - val_loss: 6.8796e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 11s - loss: 8.4175e-05 - val_loss: 5.5918e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 11s - loss: 7.9659e-05 - val_loss: 5.2456e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 11s - loss: 8.0305e-05 - val_loss: 5.4940e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 11s - loss: 7.6160e-05 - val_loss: 5.5670e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 11s - loss: 7.6204e-05 - val_loss: 5.4601e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 11s - loss: 6.6888e-05 - val_loss: 5.4433e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 11s - loss: 6.6603e-05 - val_loss: 5.6587e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 11s - loss: 6.4845e-05 - val_loss: 5.8947e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 11s - loss: 6.2526e-05 - val_loss: 5.2212e-05 - lr: 6.2500e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 12s - loss: 6.3556e-05 - val_loss: 5.1434e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 11s - loss: 6.1510e-05 - val_loss: 5.0199e-05 - lr: 6.2500e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 12s - loss: 6.0472e-05 - val_loss: 5.1112e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 12s - loss: 6.1200e-05 - val_loss: 5.2043e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 11s - loss: 6.0834e-05 - val_loss: 4.8664e-05 - lr: 6.2500e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 11s - loss: 5.9597e-05 - val_loss: 5.2237e-05 - lr: 6.2500e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 12s - loss: 6.0833e-05 - val_loss: 4.9681e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 12s - loss: 6.0797e-05 - val_loss: 4.9184e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 12s - loss: 5.9318e-05 - val_loss: 5.0492e-05 - lr: 1.5625e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 11s - loss: 5.9860e-05 - val_loss: 5.0549e-05 - lr: 1.5625e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 13s - loss: 0.0130 - val_loss: 5.3987e-04 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 12s - loss: 8.2084e-04 - val_loss: 1.8736e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 12s - loss: 3.4923e-04 - val_loss: 1.5483e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 11s - loss: 2.4476e-04 - val_loss: 1.2026e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 11s - loss: 1.8502e-04 - val_loss: 6.6679e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 11s - loss: 1.4490e-04 - val_loss: 1.2431e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 12s - loss: 1.2432e-04 - val_loss: 6.5968e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 12s - loss: 1.0797e-04 - val_loss: 7.9995e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 15s - loss: 1.0007e-04 - val_loss: 9.3919e-05 - lr: 0.0010 - 15s/epoch - 15ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 12s - loss: 9.3047e-05 - val_loss: 9.0854e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 13s - loss: 7.6456e-05 - val_loss: 6.8977e-05 - lr: 2.5000e-04 - 13s/epoch - 13ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 13s - loss: 7.3557e-05 - val_loss: 6.3064e-05 - lr: 2.5000e-04 - 13s/epoch - 13ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 12s - loss: 7.3103e-05 - val_loss: 7.0644e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 13s - loss: 7.1992e-05 - val_loss: 5.8224e-05 - lr: 2.5000e-04 - 13s/epoch - 13ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 13s - loss: 7.0397e-05 - val_loss: 7.2318e-05 - lr: 2.5000e-04 - 13s/epoch - 13ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 16s - loss: 7.0279e-05 - val_loss: 9.2575e-05 - lr: 2.5000e-04 - 16s/epoch - 16ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 15s - loss: 6.8676e-05 - val_loss: 6.5112e-05 - lr: 2.5000e-04 - 15s/epoch - 15ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 12s - loss: 6.7363e-05 - val_loss: 5.7070e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 14s - loss: 6.5309e-05 - val_loss: 5.7237e-05 - lr: 6.2500e-05 - 14s/epoch - 14ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 13s - loss: 6.5456e-05 - val_loss: 5.6643e-05 - lr: 6.2500e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 14s - loss: 6.6083e-05 - val_loss: 6.0403e-05 - lr: 6.2500e-05 - 14s/epoch - 14ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 13s - loss: 6.5119e-05 - val_loss: 6.0958e-05 - lr: 6.2500e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 13s - loss: 6.4984e-05 - val_loss: 6.1846e-05 - lr: 6.2500e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 13s - loss: 6.4737e-05 - val_loss: 5.8792e-05 - lr: 1.5625e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 12s - loss: 6.4582e-05 - val_loss: 6.0255e-05 - lr: 1.5625e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 12s - loss: 6.4141e-05 - val_loss: 6.1285e-05 - lr: 1.5625e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 12s - loss: 6.3694e-05 - val_loss: 6.0075e-05 - lr: 3.9063e-06 - 12s/epoch - 12ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 13s - loss: 6.4540e-05 - val_loss: 6.1144e-05 - lr: 3.9063e-06 - 13s/epoch - 13ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 13s - loss: 6.4635e-05 - val_loss: 5.9238e-05 - lr: 3.9063e-06 - 13s/epoch - 13ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 11s - loss: 6.3897e-05 - val_loss: 5.8960e-05 - lr: 9.7656e-07 - 11s/epoch - 11ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 13s - loss: 0.0133 - val_loss: 3.6650e-04 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 13s - loss: 8.2156e-04 - val_loss: 1.4716e-04 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 13s - loss: 4.0720e-04 - val_loss: 1.7726e-04 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 11s - loss: 2.6931e-04 - val_loss: 7.7445e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 12s - loss: 1.6842e-04 - val_loss: 5.8690e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 11s - loss: 1.2864e-04 - val_loss: 1.4932e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 11s - loss: 1.1877e-04 - val_loss: 9.2169e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 11s - loss: 9.8699e-05 - val_loss: 6.8908e-05 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 11s - loss: 7.7691e-05 - val_loss: 6.0679e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 11s - loss: 7.5318e-05 - val_loss: 5.5851e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 13s - loss: 7.5791e-05 - val_loss: 5.3852e-05 - lr: 2.5000e-04 - 13s/epoch - 13ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 12s - loss: 7.5057e-05 - val_loss: 5.2029e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 12s - loss: 7.2987e-05 - val_loss: 5.2147e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 12s - loss: 7.3086e-05 - val_loss: 6.2245e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 12s - loss: 7.0491e-05 - val_loss: 5.1193e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 13s - loss: 6.8349e-05 - val_loss: 5.1353e-05 - lr: 2.5000e-04 - 13s/epoch - 13ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 11s - loss: 6.9466e-05 - val_loss: 5.7558e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 12s - loss: 6.8227e-05 - val_loss: 5.2792e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 12s - loss: 6.4179e-05 - val_loss: 5.2485e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 11s - loss: 6.2885e-05 - val_loss: 5.7168e-05 - lr: 6.2500e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 11s - loss: 6.3404e-05 - val_loss: 4.9901e-05 - lr: 6.2500e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 11s - loss: 6.2702e-05 - val_loss: 4.9005e-05 - lr: 6.2500e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 12s - loss: 6.2036e-05 - val_loss: 5.2638e-05 - lr: 6.2500e-05 - 12s/epoch - 12ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 14s - loss: 6.1931e-05 - val_loss: 5.3490e-05 - lr: 6.2500e-05 - 14s/epoch - 14ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 13s - loss: 6.2804e-05 - val_loss: 5.7660e-05 - lr: 6.2500e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 14s - loss: 6.1056e-05 - val_loss: 5.0640e-05 - lr: 1.5625e-05 - 14s/epoch - 14ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 13s - loss: 6.1490e-05 - val_loss: 5.2282e-05 - lr: 1.5625e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 13s - loss: 6.0250e-05 - val_loss: 5.4621e-05 - lr: 1.5625e-05 - 13s/epoch - 13ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 13s - loss: 6.0835e-05 - val_loss: 5.3513e-05 - lr: 3.9063e-06 - 13s/epoch - 13ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 13s - loss: 6.1651e-05 - val_loss: 5.1150e-05 - lr: 3.9063e-06 - 13s/epoch - 13ms/step\n",
      "Epoch 1/30\n",
      "1000/1000 - 13s - loss: 0.0132 - val_loss: 6.4599e-04 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 12s - loss: 7.4135e-04 - val_loss: 1.2310e-04 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 12s - loss: 3.4459e-04 - val_loss: 8.2233e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 13s - loss: 2.2121e-04 - val_loss: 7.6164e-05 - lr: 0.0010 - 13s/epoch - 13ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 10s - loss: 1.7759e-04 - val_loss: 4.1421e-04 - lr: 0.0010 - 10s/epoch - 10ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 12s - loss: 1.4249e-04 - val_loss: 8.8714e-05 - lr: 0.0010 - 12s/epoch - 12ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 11s - loss: 1.2664e-04 - val_loss: 1.7377e-04 - lr: 0.0010 - 11s/epoch - 11ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 11s - loss: 9.8498e-05 - val_loss: 7.9398e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 11s - loss: 9.5109e-05 - val_loss: 1.9067e-04 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 12s - loss: 9.1631e-05 - val_loss: 6.1456e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 12s - loss: 8.5323e-05 - val_loss: 6.0505e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 11s - loss: 8.2304e-05 - val_loss: 5.7355e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 14s - loss: 7.7666e-05 - val_loss: 6.7335e-05 - lr: 2.5000e-04 - 14s/epoch - 14ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 12s - loss: 7.8758e-05 - val_loss: 5.9584e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 11s - loss: 7.3601e-05 - val_loss: 5.1152e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 10s - loss: 7.2764e-05 - val_loss: 5.5852e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 10s - loss: 7.0388e-05 - val_loss: 4.9069e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 12s - loss: 6.9668e-05 - val_loss: 6.1370e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 11s - loss: 6.9746e-05 - val_loss: 5.2481e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 10s - loss: 6.8822e-05 - val_loss: 4.8459e-05 - lr: 2.5000e-04 - 10s/epoch - 10ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 11s - loss: 6.8304e-05 - val_loss: 5.2157e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 12s - loss: 6.6738e-05 - val_loss: 5.1376e-05 - lr: 2.5000e-04 - 12s/epoch - 12ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 11s - loss: 6.6160e-05 - val_loss: 8.1971e-05 - lr: 2.5000e-04 - 11s/epoch - 11ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 11s - loss: 6.3397e-05 - val_loss: 5.4022e-05 - lr: 6.2500e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 11s - loss: 6.2492e-05 - val_loss: 5.2668e-05 - lr: 6.2500e-05 - 11s/epoch - 11ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 10s - loss: 6.2397e-05 - val_loss: 5.1949e-05 - lr: 6.2500e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 10s - loss: 6.0908e-05 - val_loss: 5.2622e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 10s - loss: 6.1728e-05 - val_loss: 4.8539e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 10s - loss: 6.1458e-05 - val_loss: 5.4378e-05 - lr: 1.5625e-05 - 10s/epoch - 10ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 10s - loss: 6.0672e-05 - val_loss: 5.1885e-05 - lr: 3.9063e-06 - 10s/epoch - 10ms/step\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for spec_name, include_bmi, include_state in specs:\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    dataset_train = create_dataset(mode=\"train\", range=10000, include_bmi=include_bmi, include_state=include_state)\n",
    "    dataset_test = create_dataset(mode=\"test\", range=10000, include_bmi=include_bmi, include_state=include_state)\n",
    "    for i in range(5):\n",
    "        model = redefine_model(include_bmi=include_bmi, include_state=include_state)\n",
    "        callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, patience=3, verbose=0, mode=\"auto\", min_delta=1e-8, cooldown=0, min_lr=0.0)]\n",
    "        history = model.fit(dataset_train, steps_per_epoch=1000, validation_data=dataset_test, validation_steps=500, epochs=30, verbose=2, callbacks=callbacks)\n",
    "        loss.append(history.history['loss'][-1])\n",
    "        val_loss.append(history.history['val_loss'][-1])\n",
    "    avg_loss, avg_val_loss = get_loss(loss, val_loss)\n",
    "    results.append((spec_name, avg_loss, avg_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('No BMI', 3.335853252792731e-05, 3.244583567720838e-05), ('With BMI', 6.290314922807738e-05, 4.4982434337725864e-05), ('No State or BMI', 6.513160624308512e-05, 5.488997849170119e-05), ('BMI, no State', 6.112269329605624e-05, 5.2879014401696625e-05)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{lcc}\n",
      "\\hline\n",
      "Model Specification & Average Loss & Average Validation Loss \\\\ \\hline\n",
      "No BMI & 0.000033 & 0.000032 \\\\\n",
      "With BMI & 0.000063 & 0.000045 \\\\\n",
      "No State or BMI & 0.000065 & 0.000055 \\\\\n",
      "BMI, no State & 0.000061 & 0.000053 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\caption{Model Performance}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# Generate LaTeX table\n",
    "latex_table = \"\\\\begin{table}[H]\\n\\\\centering\\n\\\\begin{tabular}{lcc}\\n\\\\hline\\n\"\n",
    "latex_table += \"Model Specification & Average Loss & Average Validation Loss \\\\\\\\ \\\\hline\\n\"\n",
    "for spec_name, avg_loss, avg_val_loss in results:\n",
    "    latex_table += f\"{spec_name} & {avg_loss:.6f} & {avg_val_loss:.6f} \\\\\\\\\\n\"\n",
    "latex_table += \"\\\\hline\\n\\\\end{tabular}\\n\\\\caption{Model Performance}\\n\\\\end{table}\"\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMI 1st run: loss: 6.5036e-05 - val_loss: 7.7524e-05 \n",
    "BMI 2nd run: loss: 7.0120e-05 - val_loss: 5.9770e-05\n",
    "BMI no lag: loss: 6.7715e-05 - val_loss: 5.2124e-05\n",
    "No State No BMI: loss: 6.5259e-05 - val_loss: 5.4376e-05\n",
    "State No BMI: loss: 3.5489e-05 - val_loss: 3.0721e-05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
