{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "tfkl = tf.keras.layers\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.layers import Input, Embedding, Flatten, Dense, BatchNormalization, Dropout, concatenate\n",
    "#from keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PopName', 'Sex', 'Year', 'Age', 'mx']\n"
     ]
    }
   ],
   "source": [
    "# loading in USMDB data\n",
    "data = []\n",
    "ages = []\n",
    "states = []\n",
    "genders = []\n",
    "\n",
    "with open(\"../data/usmdb/usmdb.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file,delimiter=',')\n",
    "    for row_index, row in enumerate(reader):\n",
    "        if row_index == 0:\n",
    "            print(row)\n",
    "        if row_index >= 1:\n",
    "            state, gender, year, age, rate = row\n",
    "            year = int(year)\n",
    "            try:\n",
    "                age = int(age)\n",
    "            except:\n",
    "                age = -1\n",
    "            if state not in states:\n",
    "                states.append(state)\n",
    "            state = states.index(state)\n",
    "            if gender not in genders:\n",
    "                genders.append(gender)\n",
    "            gender = genders.index(gender)\n",
    "            try:\n",
    "                rate = float(rate)\n",
    "            except:\n",
    "                rate = -1\n",
    "            if rate > 1:\n",
    "                rate = 1\n",
    "            # get rid of years, ages, not in health data and other cleaning\n",
    "            if age != -1 and rate != -1 and age <= 99 and age >=18 and year >= 1993:\n",
    "                data.append([state, gender, year, age, rate])\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ... 49. 49. 49.]\n",
      "[[0.0000e+00 0.0000e+00 1.9930e+03 1.8000e+01 2.7000e-04]\n",
      " [0.0000e+00 0.0000e+00 1.9930e+03 1.9000e+01 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 1.9930e+03 2.0000e+01 1.0700e-03]\n",
      " ...\n",
      " [4.9000e+01 1.0000e+00 2.0200e+03 9.7000e+01 3.8917e-01]\n",
      " [4.9000e+01 1.0000e+00 2.0200e+03 9.8000e+01 4.2072e-01]\n",
      " [4.9000e+01 1.0000e+00 2.0200e+03 9.9000e+01 4.5292e-01]]\n",
      "['AK', 'AL', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
      "['f', 'm']\n"
     ]
    }
   ],
   "source": [
    "print(data[:,0])\n",
    "print(data)\n",
    "print(states)\n",
    "print(genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/brfss/brfss_agg.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last minute cleaning. Will put chunk below into cleaning file soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      state    age     sex  year        bmi\n",
      "0        AL  18-24  female  1993  21.704250\n",
      "1        AL  18-24  female  1994  23.100608\n",
      "2        AL  18-24  female  1995  23.313510\n",
      "3        AL  18-24  female  1996  24.502406\n",
      "4        AL  18-24  female  1997  23.347746\n",
      "...     ...    ...     ...   ...        ...\n",
      "38849    WY    80+    male  2017  27.069832\n",
      "38850    WY    80+    male  2018  26.646026\n",
      "38851    WY    80+    male  2019  26.365848\n",
      "38852    WY    80+    male  2020  26.726692\n",
      "38853    WY    80+    male  2021  26.220133\n",
      "\n",
      "[37570 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# removing missing - should add this to cleaning dataset in the future\n",
    "index_missing = df[ (df['sex'] == '7')].index\n",
    "df.drop(index_missing, inplace=True)\n",
    "\n",
    "# Mapping from FIPS code to state abbreviation\n",
    "fips_to_abbreviation = {\n",
    "    1: 'AL', 2: 'AK', 4: 'AZ', 5: 'AR', 6: 'CA', 8: 'CO', 9: 'CT', 10: 'DE', 12: 'FL',\n",
    "    13: 'GA', 15: 'HI', 16: 'ID', 17: 'IL', 18: 'IN', 19: 'IA', 20: 'KS', 21: 'KY',\n",
    "    22: 'LA', 23: 'ME', 24: 'MD', 25: 'MA', 26: 'MI', 27: 'MN', 28: 'MS', 29: 'MO',\n",
    "    30: 'MT', 31: 'NE', 32: 'NV', 33: 'NH', 34: 'NJ', 35: 'NM', 36: 'NY', 37: 'NC',\n",
    "    38: 'ND', 39: 'OH', 40: 'OK', 41: 'OR', 42: 'PA', 44: 'RI', 45: 'SC', 46: 'SD',\n",
    "    47: 'TN', 48: 'TX', 49: 'UT', 50: 'VT', 51: 'VA', 53: 'WA', 54: 'WV', 55: 'WI',\n",
    "    56: 'WY'\n",
    "}\n",
    "\n",
    "# Convert FIPS codes to state abbreviations\n",
    "df['state'] = df['state'].map(fips_to_abbreviation)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state       int64\n",
      "age      category\n",
      "sex         int64\n",
      "year        int64\n",
      "bmi       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "df['state'] = df['state'].astype('category')\n",
    "df['state'] = df['state'].apply(lambda x: states.index(x))\n",
    "df['state'] = df['state'].astype('int64')\n",
    "df['age'] = df['age'].astype('category')\n",
    "df['sex'] = df['sex'].map({'female': 0, 'male': 1})\n",
    "print(df.dtypes)\n",
    "\n",
    "health_data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train no covariate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # training and test sets \n",
    "# training_index = np.logical_and(data[:, 2] >= 1998, data[:, 2] <= 2010)\n",
    "# training_data = data[training_index, :]\n",
    "# print(training_data.shape)\n",
    "\n",
    "# test_index = np.logical_and(data[:, 2] > 2010, data[:, 2] <= 2015)\n",
    "# test_data = data[test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data = tf.convert_to_tensor(training_data)\n",
    "# test_data = tf.convert_to_tensor(test_data)\n",
    "# # cast tensor to type float32\n",
    "# training_data = tf.cast(training_data, tf.float32)\n",
    "# test_data = tf.cast(test_data, tf.float32)\n",
    "# num_train = training_data.shape[0]\n",
    "# num_test = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define function to fetch and process data entries from training or test data \n",
    "# def get_data(index, mode):\n",
    "#     if mode == \"train\":\n",
    "#         # randomly selects index from training data between 0 and num_train\n",
    "#         rand_index = tf.random.uniform([],minval=0, maxval=num_train, dtype=tf.int32) \n",
    "#         entry = training_data[rand_index, :]\n",
    "#     elif mode == \"not_random\":\n",
    "#         # selects specified index from test data \n",
    "#         entry = test_data[index, :]\n",
    "#     else: \n",
    "#         # for any other value of mode, randomly selects index from test\n",
    "#         rand_index = tf.random.uniform([],minval=0, maxval=num_test, dtype=tf.int32)\n",
    "#         entry = test_data[rand_index, :]\n",
    "#     state, gender, year, age, rate = entry[0], entry[1], entry[2], entry[3], entry[4]\n",
    "#     year = (year - 1998)/21\n",
    "#     age = tf.cast(age, tf.int32)\n",
    "#     state = tf.cast(state, tf.int32)\n",
    "#     gender = tf.cast(gender, tf.int32)\n",
    "#     year = tf.reshape(year, [1])\n",
    "#     age = tf.reshape(age, [1])\n",
    "#     state = tf.reshape(state, [1])\n",
    "#     gender = tf.reshape(gender, [1])\n",
    "#     rate = tf.reshape(rate, [1])\n",
    "#     return (year, age, state, gender), rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_data function to set up training and test tensorflow datasets \n",
    "# dataset_train = tf.data.Dataset.from_tensor_slices(np.arange(10000))\n",
    "# dataset_train = dataset_train.repeat()\n",
    "# dataset_train = dataset_train.map(lambda x: get_data(x, mode=\"train\"), num_parallel_calls=4)\n",
    "# dataset_train = dataset_train.batch(256)\n",
    "# dataset_train = dataset_train.prefetch(buffer_size=512)\n",
    "\n",
    "# dataset_test = tf.data.Dataset.from_tensor_slices(np.arange(10000))\n",
    "# dataset_test = dataset_test.repeat()\n",
    "# dataset_test = dataset_test.map(lambda x: get_data(x, mode=\"test\"), num_parallel_calls=4)\n",
    "# dataset_test = dataset_test.batch(256)\n",
    "# dataset_test = dataset_test.prefetch(buffer_size=512)\n",
    "\n",
    "# dataset_test2 = tf.data.Dataset.from_tensor_slices(np.arange(68000))\n",
    "# dataset_test2 = dataset_test2.map(lambda x: get_data(x, mode=\"not_random\"), num_parallel_calls=4)\n",
    "# dataset_test2 = dataset_test2.batch(256)\n",
    "# dataset_test2 = dataset_test2.prefetch(buffer_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining inputs \n",
    "# year = tfkl.Input(shape=(1,), dtype='float32', name='Year')\n",
    "# age =  tfkl.Input(shape=(1,), dtype='int32', name='Age')\n",
    "# state = tfkl.Input(shape=(1,), dtype='int32', name='State')\n",
    "# gender = tfkl.Input(shape=(1,), dtype='int32', name='Gender')\n",
    "\n",
    "# # defining embedding layers \n",
    "# age_embed = tfkl.Embedding(input_dim=100, output_dim=5, input_length=1, name='Age_embed')(age)\n",
    "# age_embed = tfkl.Flatten()(age_embed)\n",
    "\n",
    "# gender_embed = tfkl.Embedding(input_dim=2, output_dim=5, input_length=1, name='Gender_embed')(gender)\n",
    "# gender_embed = tfkl.Flatten()(gender_embed)\n",
    "\n",
    "# state_embed = tfkl.Embedding(input_dim=50, output_dim=5, input_length=1, name='State_embed')(state)\n",
    "# state_embed = tfkl.Flatten()(state_embed)\n",
    "\n",
    "# # create feature vector that concatenates all inputs \n",
    "# x = tfkl.Concatenate()([year, age_embed, gender_embed, state_embed])\n",
    "# x1 = x\n",
    "\n",
    "# # setting up middle layers \n",
    "# x = tfkl.Dense(128, activation='tanh')(x)\n",
    "# x = tfkl.BatchNormalization()(x)\n",
    "# x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "# x = tfkl.Dense(128, activation='tanh')(x)\n",
    "# x = tfkl.BatchNormalization()(x)\n",
    "# x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "# x = tfkl.Dense(128, activation='tanh')(x)\n",
    "# x = tfkl.BatchNormalization()(x)\n",
    "# x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "# x = tfkl.Dense(128, activation='tanh')(x)\n",
    "# x = tfkl.BatchNormalization()(x)\n",
    "# x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "# # setting up output layer \n",
    "# x = tfkl.Concatenate()([x1, x])\n",
    "# x = tfkl.Dense(128, activation='tanh')(x)\n",
    "# x = tfkl.BatchNormalization()(x)\n",
    "# x = tfkl.Dropout(0.05)(x)\n",
    "# x = tfkl.Dense(1, activation='sigmoid', name='final')(x)\n",
    "\n",
    "# # creating the model \n",
    "# model = tf.keras.Model(inputs=[year, age, state, gender], outputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "# model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, patience=3, verbose=0, mode=\"auto\", min_delta=1e-8, cooldown=0, min_lr=0.0)]\n",
    "# model.fit(dataset_train, steps_per_epoch=1000, validation_data=dataset_test, validation_steps=500, epochs=30, verbose=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train covariate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge health and mortality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to make state, age, gender, and year indexable\n",
    "\n",
    "age_groups = []\n",
    "states = []\n",
    "years = []\n",
    "shaped_data = np.empty((50, 13, 2, 29))\n",
    "shaped_data[:, :, :, :] = np.nan\n",
    "for row in health_data:\n",
    "    state = row[0]\n",
    "    age = row[1]\n",
    "    gender = row[2]\n",
    "    year = row[3]\n",
    "    bmi = row[4]\n",
    "\n",
    "    if not state in states:\n",
    "        states.append(state)\n",
    "    state = states.index(state)\n",
    "\n",
    "    if not age in age_groups:\n",
    "        age_groups.append(age)\n",
    "    age = age_groups.index(age)\n",
    "\n",
    "    if not year in years:\n",
    "        years.append(year)\n",
    "    year = years.index(year)\n",
    "\n",
    "    shaped_data[state, age, gender, year] = bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values using the mean of all states\n",
    "\n",
    "imputed_data = shaped_data.copy()\n",
    "matching = np.isnan(shaped_data)\n",
    "mean_values = np.repeat(np.nanmean(shaped_data, axis=0)[np.newaxis, :, :, :], 50, 0)\n",
    "imputed_data[matching] = mean_values[matching]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229600, 6)\n"
     ]
    }
   ],
   "source": [
    "combined_data = []\n",
    "for i, row in enumerate(data):\n",
    "    state = row[0]\n",
    "    gender = row[1]\n",
    "    year = row[2]\n",
    "    age = row[3]\n",
    "    rate = row[4]\n",
    "    \n",
    "    age_index = (age - 20) // 5\n",
    "    if age_index == -1:\n",
    "        age_index = 0\n",
    "    if age_index > 12:\n",
    "        age_index = 12\n",
    "\n",
    "    state_index = states.index(int(state))\n",
    "\n",
    "    year_index = years.index(year)\n",
    "\n",
    "    bmi = imputed_data[state_index, int(age_index), int(gender), year_index - 5]\n",
    "\n",
    "    combined_data.append([state, gender, year , age, bmi, rate])\n",
    "\n",
    "combined_data = np.array(combined_data)\n",
    "print(combined_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Covariate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the bmi variable\n",
    "combined_data[:, 4] = (combined_data[:, 4] - np.min(combined_data[:, 4])) / (np.max(combined_data[:, 4]) - np.min(combined_data[:, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106600, 6)\n"
     ]
    }
   ],
   "source": [
    "# training and test sets \n",
    "training_index = np.logical_and(combined_data[:, 2] >= 1998, combined_data[:, 2] <= 2010)\n",
    "training_data = combined_data[training_index, :]\n",
    "print(training_data.shape)\n",
    "\n",
    "test_index = np.logical_and(combined_data[:, 2] > 2010, combined_data[:, 2] <= 2015)\n",
    "test_data = combined_data[test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = tf.convert_to_tensor(training_data)\n",
    "test_data = tf.convert_to_tensor(test_data)\n",
    "# cast tensor to type float32\n",
    "training_data = tf.cast(training_data, tf.float32)\n",
    "test_data = tf.cast(test_data, tf.float32)\n",
    "num_train = training_data.shape[0]\n",
    "num_test = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to fetch and process data entries from training or test data \n",
    "def get_data(index, mode, include_year=True, include_bmi=True, include_state=True):\n",
    "    if mode == \"train\":\n",
    "        # randomly selects index from training data between 0 and num_train\n",
    "        rand_index = tf.random.uniform([],minval=0, maxval=num_train, dtype=tf.int32) \n",
    "        entry = training_data[rand_index, :]\n",
    "    elif mode == \"not_random\":\n",
    "        # selects specified index from test data \n",
    "        entry = test_data[index, :]\n",
    "    else: \n",
    "        # for any other value of mode, randomly selects index from test\n",
    "        rand_index = tf.random.uniform([],minval=0, maxval=num_test, dtype=tf.int32)\n",
    "        entry = test_data[rand_index, :]\n",
    "    state, gender, year, age, bmi, rate = entry[0], entry[1], entry[2], entry[3], entry[4], entry[5]\n",
    "    age = tf.cast(age, tf.int32)\n",
    "    gender = tf.cast(gender, tf.int32)\n",
    "    age = tf.reshape(age, [1])\n",
    "    gender = tf.reshape(gender, [1])\n",
    "    rate = tf.reshape(rate, [1])\n",
    "\n",
    "     # Conditionally include bmi and state\n",
    "    inputs = [age, gender]\n",
    "    if include_year:\n",
    "        year = (year - 1998)/21\n",
    "        year = tf.reshape(year, [1])\n",
    "        inputs.append(year)\n",
    "    if include_bmi:\n",
    "        bmi = tf.reshape(bmi, [1])\n",
    "        inputs.append(bmi)\n",
    "    if include_state:\n",
    "        state = tf.reshape(tf.cast(state, tf.int32), [1])\n",
    "        inputs.append(state)\n",
    "\n",
    "    return tuple(inputs), rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_data function to set up training and test tensorflow datasets \n",
    "def create_dataset(mode, range, include_year=True, include_bmi=True, include_state=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(np.arange(range))\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.map(lambda x: get_data(x, mode=mode, include_year=include_year, include_bmi=include_bmi, include_state=include_state), \n",
    "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(256)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "dataset_test2 = create_dataset(mode=\"not_random\", range=68000)\n",
    "\n",
    "# dataset_test = tf.data.Dataset.from_tensor_slices(np.arange(10000))\n",
    "# dataset_test = dataset_test.repeat()\n",
    "# dataset_test = dataset_test.map(lambda x: get_data(x, mode=\"test\"), num_parallel_calls=4)\n",
    "# dataset_test = dataset_test.batch(256)\n",
    "# dataset_test = dataset_test.prefetch(buffer_size=512)\n",
    "\n",
    "# dataset_test2 = tf.data.Dataset.from_tensor_slices(np.arange(68000))\n",
    "# dataset_test2 = dataset_test2.map(lambda x: get_data(x, mode=\"not_random\"), num_parallel_calls=4)\n",
    "# dataset_test2 = dataset_test2.batch(256)\n",
    "# dataset_test2 = dataset_test2.prefetch(buffer_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine_model(include_year=True, include_bmi=True, include_state=True):\n",
    "    # defining inputs \n",
    "    age =  tfkl.Input(shape=(1,), dtype='int32', name='Age')\n",
    "    gender = tfkl.Input(shape=(1,), dtype='int32', name='Gender')\n",
    "    # conditional inputs\n",
    "    if include_year:\n",
    "        year = tfkl.Input(shape=(1,), dtype='float32', name='Year')\n",
    "    if include_state:\n",
    "        state = tfkl.Input(shape=(1,), dtype='int32', name='State')\n",
    "    if include_bmi:\n",
    "        bmi = tfkl.Input(shape=(1,), dtype='float32', name='Bmi')\n",
    "\n",
    "    # defining embedding layers \n",
    "    age_embed = tfkl.Embedding(input_dim=100, output_dim=5, input_length=1, name='Age_embed')(age)\n",
    "    age_embed = tfkl.Flatten()(age_embed)\n",
    "\n",
    "    gender_embed = tfkl.Embedding(input_dim=2, output_dim=5, input_length=1, name='Gender_embed')(gender)\n",
    "    gender_embed = tfkl.Flatten()(gender_embed)\n",
    "    \n",
    "    if include_state:\n",
    "        state_embed = tfkl.Embedding(input_dim=50, output_dim=5, input_length=1, name='State_embed')(state)\n",
    "        state_embed = tfkl.Flatten()(state_embed)\n",
    "\n",
    "    # create feature vector that concatenates all inputs \n",
    "    # x = tfkl.Concatenate()([year, age_embed, gender_embed, state_embed, bmi])\n",
    "    x = tfkl.Concatenate()([age_embed, gender_embed] + ([year] if include_year else []) + ([state_embed] if include_state else []) + ([bmi] if include_bmi else []))\n",
    "    x1 = x\n",
    "\n",
    "    # setting up middle layers \n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    # setting up output layer \n",
    "    x = tfkl.Concatenate()([x1, x])\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "    outputs = tfkl.Dense(1, activation='sigmoid', name='final')(x)\n",
    "\n",
    "    # creating the model \n",
    "    inputs = [age, gender]\n",
    "    if include_year:\n",
    "        inputs.append(year)\n",
    "    if include_state:\n",
    "        inputs.append(state)\n",
    "    if include_bmi:\n",
    "        inputs.append(bmi)\n",
    "    # model = tf.keras.Model(inputs=[year, age, state, gender, bmi], outputs=[x])\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # compiling the model\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(loss, val_loss):\n",
    "    loss = np.array(loss)\n",
    "    val_loss = np.array(val_loss)\n",
    "    loss = np.mean(loss)\n",
    "    val_loss = np.mean(val_loss)\n",
    "    return loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparitive_training(specs, epochs=30, runs=5):\n",
    "    results = []\n",
    "    for spec_name, include_year, include_bmi, include_state in specs:\n",
    "        loss = []\n",
    "        val_loss = []\n",
    "        dataset_train = create_dataset(mode=\"train\", range=10000, include_year=include_year, include_bmi=include_bmi, include_state=include_state)\n",
    "        dataset_test = create_dataset(mode=\"test\", range=10000, include_year=include_year, include_bmi=include_bmi, include_state=include_state)\n",
    "        for i in range(runs):\n",
    "            model = redefine_model(include_year=include_year, include_bmi=include_bmi, include_state=include_state)\n",
    "            callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, patience=3, verbose=0, mode=\"auto\", min_delta=1e-8, cooldown=0, min_lr=0.0)]\n",
    "            history = model.fit(dataset_train, steps_per_epoch=1000, validation_data=dataset_test, validation_steps=500, epochs=epochs, verbose=2, callbacks=callbacks)\n",
    "            loss.append(history.history['loss'][-1])\n",
    "            val_loss.append(history.history['val_loss'][-1])\n",
    "        avg_loss, avg_val_loss = get_loss(loss, val_loss)\n",
    "        results.append((spec_name, avg_loss, avg_val_loss))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifications\n",
    "specs = [\n",
    "    (\"No BMI\", True, False, True),\n",
    "    (\"With BMI\", True, True, True),\n",
    "    (\"No State or BMI\", True, False, False),\n",
    "    (\"BMI, no State\", True, True, False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 - 6s - loss: 0.0128 - val_loss: 3.2029e-04 - lr: 0.0010 - 6s/epoch - 6ms/step\n",
      "1000/1000 - 6s - loss: 0.0124 - val_loss: 1.4067e-04 - lr: 0.0010 - 6s/epoch - 6ms/step\n",
      "1000/1000 - 6s - loss: 0.0134 - val_loss: 4.5284e-04 - lr: 0.0010 - 6s/epoch - 6ms/step\n",
      "1000/1000 - 5s - loss: 0.0132 - val_loss: 2.6595e-04 - lr: 0.0010 - 5s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "results = comparitive_training(specs, epochs=1, runs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('No BMI', 0.012779438868165016, 0.0003202946681994945), ('With BMI', 0.012358171865344048, 0.00014066557923797518), ('No State or BMI', 0.01343628391623497, 0.00045283869258128107), ('BMI, no State', 0.013175425119698048, 0.00026595068629831076)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{lcc}\n",
      "\\hline\n",
      "Model Specification & Average Loss & Average Validation Loss \\\\ \\hline\n",
      "No BMI & 0.000033 & 0.000032 \\\\\n",
      "With BMI & 0.000063 & 0.000045 \\\\\n",
      "No State or BMI & 0.000065 & 0.000055 \\\\\n",
      "BMI, no State & 0.000061 & 0.000053 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\caption{Model Performance}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "# Generate LaTeX table\n",
    "latex_table = \"\\\\begin{table}[H]\\n\\\\centering\\n\\\\begin{tabular}{lcc}\\n\\\\hline\\n\"\n",
    "latex_table += \"Model Specification & Average Loss & Average Validation Loss \\\\\\\\ \\\\hline\\n\"\n",
    "for spec_name, avg_loss, avg_val_loss in results:\n",
    "    latex_table += f\"{spec_name} & {avg_loss:.6f} & {avg_val_loss:.6f} \\\\\\\\\\n\"\n",
    "latex_table += \"\\\\hline\\n\\\\end{tabular}\\n\\\\caption{Model Performance}\\n\\\\end{table}\"\n",
    "\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMI 1st run: loss: 6.5036e-05 - val_loss: 7.7524e-05 \n",
    "BMI 2nd run: loss: 7.0120e-05 - val_loss: 5.9770e-05\n",
    "BMI no lag: loss: 6.7715e-05 - val_loss: 5.2124e-05\n",
    "No State No BMI: loss: 6.5259e-05 - val_loss: 5.4376e-05\n",
    "State No BMI: loss: 3.5489e-05 - val_loss: 3.0721e-05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
