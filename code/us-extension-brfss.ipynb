{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "tfkl = tf.keras.layers\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "#from keras.layers import Input, Embedding, Flatten, Dense, BatchNormalization, Dropout, concatenate\n",
    "#from keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PopName', 'Sex', 'Year', 'Age', 'mx']\n"
     ]
    }
   ],
   "source": [
    "# loading in USMDB data\n",
    "data = []\n",
    "ages = []\n",
    "states = []\n",
    "genders = []\n",
    "\n",
    "with open(\"../data/usmdb/usmdb.csv\", \"r\") as file:\n",
    "    reader = csv.reader(file,delimiter=',')\n",
    "    for row_index, row in enumerate(reader):\n",
    "        if row_index == 0:\n",
    "            print(row)\n",
    "        if row_index >= 1:\n",
    "            state, gender, year, age, rate = row\n",
    "            year = int(year)\n",
    "            try:\n",
    "                age = int(age)\n",
    "            except:\n",
    "                age = -1\n",
    "            if state not in states:\n",
    "                states.append(state)\n",
    "            state = states.index(state)\n",
    "            if gender not in genders:\n",
    "                genders.append(gender)\n",
    "            gender = genders.index(gender)\n",
    "            try:\n",
    "                rate = float(rate)\n",
    "            except:\n",
    "                rate = -1\n",
    "            if rate > 1:\n",
    "                rate = 1\n",
    "            # get rid of years, ages, not in health data and other cleaning\n",
    "            if age != -1 and rate != -1 and age <= 99 and age >=18 and year >= 1993:\n",
    "                data.append([state, gender, year, age, rate])\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ... 49. 49. 49.]\n",
      "[[0.0000e+00 0.0000e+00 1.9930e+03 1.8000e+01 2.7000e-04]\n",
      " [0.0000e+00 0.0000e+00 1.9930e+03 1.9000e+01 0.0000e+00]\n",
      " [0.0000e+00 0.0000e+00 1.9930e+03 2.0000e+01 1.0700e-03]\n",
      " ...\n",
      " [4.9000e+01 1.0000e+00 2.0200e+03 9.7000e+01 3.8917e-01]\n",
      " [4.9000e+01 1.0000e+00 2.0200e+03 9.8000e+01 4.2072e-01]\n",
      " [4.9000e+01 1.0000e+00 2.0200e+03 9.9000e+01 4.5292e-01]]\n",
      "['AK', 'AL', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
      "['f', 'm']\n"
     ]
    }
   ],
   "source": [
    "print(data[:,0])\n",
    "print(data)\n",
    "print(states)\n",
    "print(genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/brfss/brfss_agg.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last minute cleaning. Will put chunk below into cleaning file soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      state    age     sex  year        bmi\n",
      "0        AL  18-24  female  1993  21.704250\n",
      "1        AL  18-24  female  1994  23.100608\n",
      "2        AL  18-24  female  1995  23.313510\n",
      "3        AL  18-24  female  1996  24.502406\n",
      "4        AL  18-24  female  1997  23.347746\n",
      "...     ...    ...     ...   ...        ...\n",
      "38849    WY    80+    male  2017  27.069832\n",
      "38850    WY    80+    male  2018  26.646026\n",
      "38851    WY    80+    male  2019  26.365848\n",
      "38852    WY    80+    male  2020  26.726692\n",
      "38853    WY    80+    male  2021  26.220133\n",
      "\n",
      "[37570 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# removing missing - should add this to cleaning dataset in the future\n",
    "index_missing = df[ (df['sex'] == '7')].index\n",
    "df.drop(index_missing, inplace=True)\n",
    "\n",
    "# Mapping from FIPS code to state abbreviation\n",
    "fips_to_abbreviation = {\n",
    "    1: 'AL', 2: 'AK', 4: 'AZ', 5: 'AR', 6: 'CA', 8: 'CO', 9: 'CT', 10: 'DE', 12: 'FL',\n",
    "    13: 'GA', 15: 'HI', 16: 'ID', 17: 'IL', 18: 'IN', 19: 'IA', 20: 'KS', 21: 'KY',\n",
    "    22: 'LA', 23: 'ME', 24: 'MD', 25: 'MA', 26: 'MI', 27: 'MN', 28: 'MS', 29: 'MO',\n",
    "    30: 'MT', 31: 'NE', 32: 'NV', 33: 'NH', 34: 'NJ', 35: 'NM', 36: 'NY', 37: 'NC',\n",
    "    38: 'ND', 39: 'OH', 40: 'OK', 41: 'OR', 42: 'PA', 44: 'RI', 45: 'SC', 46: 'SD',\n",
    "    47: 'TN', 48: 'TX', 49: 'UT', 50: 'VT', 51: 'VA', 53: 'WA', 54: 'WV', 55: 'WI',\n",
    "    56: 'WY'\n",
    "}\n",
    "\n",
    "# Convert FIPS codes to state abbreviations\n",
    "df['state'] = df['state'].map(fips_to_abbreviation)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state       int64\n",
      "age      category\n",
      "sex         int64\n",
      "year        int64\n",
      "bmi       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "df['state'] = df['state'].astype('category')\n",
    "df['state'] = df['state'].apply(lambda x: states.index(x))\n",
    "df['state'] = df['state'].astype('int64')\n",
    "df['age'] = df['age'].astype('category')\n",
    "df['sex'] = df['sex'].map({'female': 0, 'male': 1})\n",
    "print(df.dtypes)\n",
    "\n",
    "health_data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train no covariate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106600, 5)\n"
     ]
    }
   ],
   "source": [
    "# training and test sets \n",
    "training_index = np.logical_and(data[:, 2] >= 1998, data[:, 2] <= 2010)\n",
    "training_data = data[training_index, :]\n",
    "print(training_data.shape)\n",
    "\n",
    "test_index = np.logical_and(data[:, 2] > 2010, data[:, 2] <= 2015)\n",
    "test_data = data[test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = tf.convert_to_tensor(training_data)\n",
    "test_data = tf.convert_to_tensor(test_data)\n",
    "# cast tensor to type float32\n",
    "training_data = tf.cast(training_data, tf.float32)\n",
    "test_data = tf.cast(test_data, tf.float32)\n",
    "num_train = training_data.shape[0]\n",
    "num_test = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to fetch and process data entries from training or test data \n",
    "def get_data(index, mode):\n",
    "    if mode == \"train\":\n",
    "        # randomly selects index from training data between 0 and num_train\n",
    "        rand_index = tf.random.uniform([],minval=0, maxval=num_train, dtype=tf.int32) \n",
    "        entry = training_data[rand_index, :]\n",
    "    elif mode == \"not_random\":\n",
    "        # selects specified index from test data \n",
    "        entry = test_data[index, :]\n",
    "    else: \n",
    "        # for any other value of mode, randomly selects index from test\n",
    "        rand_index = tf.random.uniform([],minval=0, maxval=num_test, dtype=tf.int32)\n",
    "        entry = test_data[rand_index, :]\n",
    "    state, gender, year, age, rate = entry[0], entry[1], entry[2], entry[3], entry[4]\n",
    "    year = (year - 1998)/21\n",
    "    age = tf.cast(age, tf.int32)\n",
    "    state = tf.cast(state, tf.int32)\n",
    "    gender = tf.cast(gender, tf.int32)\n",
    "    year = tf.reshape(year, [1])\n",
    "    age = tf.reshape(age, [1])\n",
    "    state = tf.reshape(state, [1])\n",
    "    gender = tf.reshape(gender, [1])\n",
    "    rate = tf.reshape(rate, [1])\n",
    "    return (year, age, state, gender), rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_data function to set up training and test tensorflow datasets \n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(np.arange(10000))\n",
    "dataset_train = dataset_train.repeat()\n",
    "dataset_train = dataset_train.map(lambda x: get_data(x, mode=\"train\"), num_parallel_calls=4)\n",
    "dataset_train = dataset_train.batch(256)\n",
    "dataset_train = dataset_train.prefetch(buffer_size=512)\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices(np.arange(10000))\n",
    "dataset_test = dataset_test.repeat()\n",
    "dataset_test = dataset_test.map(lambda x: get_data(x, mode=\"test\"), num_parallel_calls=4)\n",
    "dataset_test = dataset_test.batch(256)\n",
    "dataset_test = dataset_test.prefetch(buffer_size=512)\n",
    "\n",
    "dataset_test2 = tf.data.Dataset.from_tensor_slices(np.arange(68000))\n",
    "dataset_test2 = dataset_test2.map(lambda x: get_data(x, mode=\"not_random\"), num_parallel_calls=4)\n",
    "dataset_test2 = dataset_test2.batch(256)\n",
    "dataset_test2 = dataset_test2.prefetch(buffer_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining inputs \n",
    "year = tfkl.Input(shape=(1,), dtype='float32', name='Year')\n",
    "age =  tfkl.Input(shape=(1,), dtype='int32', name='Age')\n",
    "state = tfkl.Input(shape=(1,), dtype='int32', name='State')\n",
    "gender = tfkl.Input(shape=(1,), dtype='int32', name='Gender')\n",
    "\n",
    "# defining embedding layers \n",
    "age_embed = tfkl.Embedding(input_dim=100, output_dim=5, input_length=1, name='Age_embed')(age)\n",
    "age_embed = tfkl.Flatten()(age_embed)\n",
    "\n",
    "gender_embed = tfkl.Embedding(input_dim=2, output_dim=5, input_length=1, name='Gender_embed')(gender)\n",
    "gender_embed = tfkl.Flatten()(gender_embed)\n",
    "\n",
    "state_embed = tfkl.Embedding(input_dim=50, output_dim=5, input_length=1, name='State_embed')(state)\n",
    "state_embed = tfkl.Flatten()(state_embed)\n",
    "\n",
    "# create feature vector that concatenates all inputs \n",
    "x = tfkl.Concatenate()([year, age_embed, gender_embed, state_embed])\n",
    "x1 = x\n",
    "\n",
    "# setting up middle layers \n",
    "x = tfkl.Dense(128, activation='tanh')(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "x = tfkl.Dense(128, activation='tanh')(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "x = tfkl.Dense(128, activation='tanh')(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "x = tfkl.Dense(128, activation='tanh')(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "# setting up output layer \n",
    "x = tfkl.Concatenate()([x1, x])\n",
    "x = tfkl.Dense(128, activation='tanh')(x)\n",
    "x = tfkl.BatchNormalization()(x)\n",
    "x = tfkl.Dropout(0.05)(x)\n",
    "x = tfkl.Dense(1, activation='sigmoid', name='final')(x)\n",
    "\n",
    "# creating the model \n",
    "model = tf.keras.Model(inputs=[year, age, state, gender], outputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 - 7s - loss: 0.0130 - val_loss: 1.8223e-04 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 2/30\n",
      "1000/1000 - 5s - loss: 6.7502e-04 - val_loss: 9.1453e-05 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "1000/1000 - 5s - loss: 3.0912e-04 - val_loss: 5.0198e-05 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "1000/1000 - 6s - loss: 1.9711e-04 - val_loss: 2.9219e-04 - lr: 0.0010 - 6s/epoch - 6ms/step\n",
      "Epoch 5/30\n",
      "1000/1000 - 6s - loss: 1.4292e-04 - val_loss: 4.2452e-05 - lr: 0.0010 - 6s/epoch - 6ms/step\n",
      "Epoch 6/30\n",
      "1000/1000 - 7s - loss: 1.2533e-04 - val_loss: 7.4637e-05 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "Epoch 7/30\n",
      "1000/1000 - 6s - loss: 1.0603e-04 - val_loss: 3.9180e-05 - lr: 0.0010 - 6s/epoch - 6ms/step\n",
      "Epoch 8/30\n",
      "1000/1000 - 6s - loss: 8.1768e-05 - val_loss: 3.8040e-05 - lr: 0.0010 - 6s/epoch - 6ms/step\n",
      "Epoch 9/30\n",
      "1000/1000 - 5s - loss: 7.5266e-05 - val_loss: 4.5999e-05 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "1000/1000 - 5s - loss: 6.8111e-05 - val_loss: 4.8371e-05 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 11/30\n",
      "1000/1000 - 5s - loss: 5.8262e-05 - val_loss: 7.2768e-05 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "1000/1000 - 5s - loss: 4.5134e-05 - val_loss: 3.2038e-05 - lr: 2.5000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "1000/1000 - 5s - loss: 4.3127e-05 - val_loss: 3.4725e-05 - lr: 2.5000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "1000/1000 - 5s - loss: 4.2331e-05 - val_loss: 2.8335e-05 - lr: 2.5000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "1000/1000 - 5s - loss: 4.1124e-05 - val_loss: 2.9579e-05 - lr: 2.5000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "1000/1000 - 5s - loss: 4.1440e-05 - val_loss: 3.2754e-05 - lr: 2.5000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "1000/1000 - 5s - loss: 4.0120e-05 - val_loss: 3.2351e-05 - lr: 2.5000e-04 - 5s/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "1000/1000 - 5s - loss: 3.7135e-05 - val_loss: 3.1478e-05 - lr: 6.2500e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "1000/1000 - 5s - loss: 3.6333e-05 - val_loss: 3.0658e-05 - lr: 6.2500e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "1000/1000 - 5s - loss: 3.5827e-05 - val_loss: 3.2033e-05 - lr: 6.2500e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "1000/1000 - 5s - loss: 3.5647e-05 - val_loss: 3.0954e-05 - lr: 1.5625e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1000/1000 - 6s - loss: 3.4733e-05 - val_loss: 3.2052e-05 - lr: 1.5625e-05 - 6s/epoch - 6ms/step\n",
      "Epoch 23/30\n",
      "1000/1000 - 5s - loss: 3.5679e-05 - val_loss: 3.0546e-05 - lr: 1.5625e-05 - 5s/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "1000/1000 - 5s - loss: 3.5123e-05 - val_loss: 3.0538e-05 - lr: 3.9063e-06 - 5s/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "1000/1000 - 5s - loss: 3.5232e-05 - val_loss: 3.2613e-05 - lr: 3.9063e-06 - 5s/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "1000/1000 - 5s - loss: 3.5125e-05 - val_loss: 3.1802e-05 - lr: 3.9063e-06 - 5s/epoch - 5ms/step\n",
      "Epoch 27/30\n",
      "1000/1000 - 5s - loss: 3.4404e-05 - val_loss: 3.0985e-05 - lr: 9.7656e-07 - 5s/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "1000/1000 - 5s - loss: 3.4683e-05 - val_loss: 3.1875e-05 - lr: 9.7656e-07 - 5s/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "1000/1000 - 5s - loss: 3.4647e-05 - val_loss: 3.0560e-05 - lr: 9.7656e-07 - 5s/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "1000/1000 - 5s - loss: 3.5489e-05 - val_loss: 3.0721e-05 - lr: 2.4414e-07 - 5s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x292a3c110>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, patience=3, verbose=0, mode=\"auto\", min_delta=1e-8, cooldown=0, min_lr=0.0)]\n",
    "model.fit(dataset_train, steps_per_epoch=1000, validation_data=dataset_test, validation_steps=500, epochs=30, verbose=2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train covariate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge health and mortality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data to make state, age, gender, and year indexable\n",
    "\n",
    "age_groups = []\n",
    "states = []\n",
    "years = []\n",
    "shaped_data = np.empty((50, 13, 2, 29))\n",
    "shaped_data[:, :, :, :] = np.nan\n",
    "for row in health_data:\n",
    "    state = row[0]\n",
    "    age = row[1]\n",
    "    gender = row[2]\n",
    "    year = row[3]\n",
    "    bmi = row[4]\n",
    "\n",
    "    if not state in states:\n",
    "        states.append(state)\n",
    "    state = states.index(state)\n",
    "\n",
    "    if not age in age_groups:\n",
    "        age_groups.append(age)\n",
    "    age = age_groups.index(age)\n",
    "\n",
    "    if not year in years:\n",
    "        years.append(year)\n",
    "    year = years.index(year)\n",
    "\n",
    "    shaped_data[state, age, gender, year] = bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values using the mean of all states\n",
    "\n",
    "imputed_data = shaped_data.copy()\n",
    "matching = np.isnan(shaped_data)\n",
    "mean_values = np.repeat(np.nanmean(shaped_data, axis=0)[np.newaxis, :, :, :], 50, 0)\n",
    "imputed_data[matching] = mean_values[matching]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229600, 6)\n"
     ]
    }
   ],
   "source": [
    "combined_data = []\n",
    "for i, row in enumerate(data):\n",
    "    state = row[0]\n",
    "    gender = row[1]\n",
    "    year = row[2]\n",
    "    age = row[3]\n",
    "    rate = row[4]\n",
    "    \n",
    "    age_index = (age - 20) // 5\n",
    "    if age_index == -1:\n",
    "        age_index = 0\n",
    "    if age_index > 12:\n",
    "        age_index = 12\n",
    "\n",
    "    state_index = states.index(int(state))\n",
    "\n",
    "    year_index = years.index(year)\n",
    "\n",
    "    bmi = imputed_data[state_index, int(age_index), int(gender), year_index]\n",
    "\n",
    "    combined_data.append([state, gender, year , age, bmi, rate])\n",
    "\n",
    "\n",
    "combined_data = np.array(combined_data)\n",
    "print(combined_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Covariate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the bmi variable\n",
    "combined_data[:, 4] = (combined_data[:, 4] - np.min(combined_data[:, 4])) / (np.max(combined_data[:, 4]) - np.min(combined_data[:, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106600, 6)\n"
     ]
    }
   ],
   "source": [
    "# training and test sets \n",
    "training_index = np.logical_and(combined_data[:, 2] >= 1998, combined_data[:, 2] <= 2010)\n",
    "training_data = combined_data[training_index, :]\n",
    "print(training_data.shape)\n",
    "\n",
    "test_index = np.logical_and(combined_data[:, 2] > 2010, combined_data[:, 2] <= 2015)\n",
    "test_data = combined_data[test_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = tf.convert_to_tensor(training_data)\n",
    "test_data = tf.convert_to_tensor(test_data)\n",
    "# cast tensor to type float32\n",
    "training_data = tf.cast(training_data, tf.float32)\n",
    "test_data = tf.cast(test_data, tf.float32)\n",
    "num_train = training_data.shape[0]\n",
    "num_test = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to fetch and process data entries from training or test data \n",
    "def get_data(index, mode):\n",
    "    if mode == \"train\":\n",
    "        # randomly selects index from training data between 0 and num_train\n",
    "        rand_index = tf.random.uniform([],minval=0, maxval=num_train, dtype=tf.int32) \n",
    "        entry = training_data[rand_index, :]\n",
    "    elif mode == \"not_random\":\n",
    "        # selects specified index from test data \n",
    "        entry = test_data[index, :]\n",
    "    else: \n",
    "        # for any other value of mode, randomly selects index from test\n",
    "        rand_index = tf.random.uniform([],minval=0, maxval=num_test, dtype=tf.int32)\n",
    "        entry = test_data[rand_index, :]\n",
    "    state, gender, year, age, bmi, rate = entry[0], entry[1], entry[2], entry[3], entry[4], entry[5]\n",
    "    year = (year - 1998)/21\n",
    "    age = tf.cast(age, tf.int32)\n",
    "    state = tf.cast(state, tf.int32)\n",
    "    gender = tf.cast(gender, tf.int32)\n",
    "    year = tf.reshape(year, [1])\n",
    "    age = tf.reshape(age, [1])\n",
    "    state = tf.reshape(state, [1])\n",
    "    gender = tf.reshape(gender, [1])\n",
    "    bmi = tf.reshape(bmi, [1])\n",
    "    rate = tf.reshape(rate, [1])\n",
    "    # return (year, age, state, gender, bmi), rate\n",
    "    return (year, age, gender, bmi), rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_data function to set up training and test tensorflow datasets \n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(np.arange(10000))\n",
    "dataset_train = dataset_train.repeat()\n",
    "dataset_train = dataset_train.map(lambda x: get_data(x, mode=\"train\"), num_parallel_calls=4)\n",
    "dataset_train = dataset_train.batch(256)\n",
    "dataset_train = dataset_train.prefetch(buffer_size=512)\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices(np.arange(10000))\n",
    "dataset_test = dataset_test.repeat()\n",
    "dataset_test = dataset_test.map(lambda x: get_data(x, mode=\"test\"), num_parallel_calls=4)\n",
    "dataset_test = dataset_test.batch(256)\n",
    "dataset_test = dataset_test.prefetch(buffer_size=512)\n",
    "\n",
    "dataset_test2 = tf.data.Dataset.from_tensor_slices(np.arange(68000))\n",
    "dataset_test2 = dataset_test2.map(lambda x: get_data(x, mode=\"not_random\"), num_parallel_calls=4)\n",
    "dataset_test2 = dataset_test2.batch(256)\n",
    "dataset_test2 = dataset_test2.prefetch(buffer_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redefine_model():\n",
    "    # defining inputs \n",
    "    year = tfkl.Input(shape=(1,), dtype='float32', name='Year')\n",
    "    age =  tfkl.Input(shape=(1,), dtype='int32', name='Age')\n",
    "    # state = tfkl.Input(shape=(1,), dtype='int32', name='State')\n",
    "    gender = tfkl.Input(shape=(1,), dtype='int32', name='Gender')\n",
    "    bmi = tfkl.Input(shape=(1,), dtype='float32', name='Bmi')\n",
    "\n",
    "    # defining embedding layers \n",
    "    age_embed = tfkl.Embedding(input_dim=100, output_dim=5, input_length=1, name='Age_embed')(age)\n",
    "    age_embed = tfkl.Flatten()(age_embed)\n",
    "\n",
    "    gender_embed = tfkl.Embedding(input_dim=2, output_dim=5, input_length=1, name='Gender_embed')(gender)\n",
    "    gender_embed = tfkl.Flatten()(gender_embed)\n",
    "\n",
    "    # state_embed = tfkl.Embedding(input_dim=50, output_dim=5, input_length=1, name='State_embed')(state)\n",
    "    # state_embed = tfkl.Flatten()(state_embed)\n",
    "\n",
    "    # create feature vector that concatenates all inputs \n",
    "    # x = tfkl.Concatenate()([year, age_embed, gender_embed, state_embed, bmi])\n",
    "    x = tfkl.Concatenate()([year, age_embed, gender_embed, bmi])\n",
    "    x1 = x\n",
    "\n",
    "    # setting up middle layers \n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "\n",
    "    # setting up output layer \n",
    "    x = tfkl.Concatenate()([x1, x])\n",
    "    x = tfkl.Dense(128, activation='tanh')(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(0.05)(x)\n",
    "    x = tfkl.Dense(1, activation='sigmoid', name='final')(x)\n",
    "\n",
    "    # creating the model \n",
    "    # model = tf.keras.Model(inputs=[year, age, state, gender, bmi], outputs=[x])\n",
    "    model = tf.keras.Model(inputs=[year, age, gender, bmi], outputs=[x])\n",
    "\n",
    "    # compiling the model\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 - 7s - loss: 0.0135 - val_loss: 8.1785e-04 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "1000/1000 - 7s - loss: 0.0134 - val_loss: 5.2251e-04 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "1000/1000 - 7s - loss: 0.0132 - val_loss: 7.0224e-04 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "1000/1000 - 7s - loss: 0.0129 - val_loss: 5.5572e-04 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "1000/1000 - 7s - loss: 0.0129 - val_loss: 2.9547e-04 - lr: 0.0010 - 7s/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "val_loss = []\n",
    "for i in range(5):\n",
    "    model = redefine_model()\n",
    "    callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.25, patience=3, verbose=0, mode=\"auto\", min_delta=1e-8, cooldown=0, min_lr=0.0)]\n",
    "    history = model.fit(dataset_train, steps_per_epoch=1000, validation_data=dataset_test, validation_steps=500, epochs=1, verbose=2, callbacks=callbacks)\n",
    "    loss.append(history.history['loss'][-1])\n",
    "    val_loss.append(history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013184536993503571\n",
      "0.0005787564790807664\n"
     ]
    }
   ],
   "source": [
    "loss = np.array(loss)\n",
    "val_loss = np.array(val_loss)\n",
    "loss = np.mean(loss)\n",
    "val_loss = np.mean(val_loss)\n",
    "print(loss)\n",
    "print(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BMI 1st run: loss: 6.5036e-05 - val_loss: 7.7524e-05 \n",
    "BMI 2nd run: loss: 7.0120e-05 - val_loss: 5.9770e-05\n",
    "BMI no lag: loss: 6.7715e-05 - val_loss: 5.2124e-05\n",
    "No State No BMI: loss: 6.5259e-05 - val_loss: 5.4376e-05\n",
    "State No BMI: loss: 3.5489e-05 - val_loss: 3.0721e-05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
